{"0": {
    "doc": "Getting Started with Obsidian",
    "title": "Getting Started with Obsidian",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Obsidian_Materials/00-getting-started.html",
    "relUrl": "/Obsidian_Materials/00-getting-started.html"
  },"1": {
    "doc": "Getting Started with Obsidian",
    "title": "About Obsidian",
    "content": "Obsidian is a knowledge base, and a second brain. This platform works from a local folder of plain text files on your computer, called a vault and it allows you the ability to connect and customize your own collection of notes. Using Obsidian should be a personal and unique experience. There are countless ways to make your vault perfect for you, and there’s no wrong way to use it! The best way to figure out how to enhance your Obsidian experience is to just open it up and start writing. Along the way, you will find your own workflow with plugins that make writing your notes seemless. However, it is nice to see examples of some of the basic things you can do, and that’s the purpose of this workshop. ",
    "url": "http://localhost:4000/portfolio_workshop/Obsidian_Materials/00-getting-started.html#about-obsidian",
    "relUrl": "/Obsidian_Materials/00-getting-started.html#about-obsidian"
  },"2": {
    "doc": "Getting Started with Obsidian",
    "title": "Download Obsidian",
    "content": "If you haven’t already, please download Obsidian. It is available for desktop on Windows, Mac, and Linux, and it’s available for mobile devices. ",
    "url": "http://localhost:4000/portfolio_workshop/Obsidian_Materials/00-getting-started.html#download-obsidian",
    "relUrl": "/Obsidian_Materials/00-getting-started.html#download-obsidian"
  },"3": {
    "doc": "Getting Started with Obsidian",
    "title": "Create a Vault",
    "content": "Once you have Obisdian installed, open it and create your first vault! . There are several options to open a vault. For new users, it is recommended to create a new vault in an empty folder on your computer. There is also an option to open a vault from an existing folder of Markdown files. Create an new vault . Select the option to “Create new vault” and in the next window, give a name and location for your vault. This will create a folder of the same name in the chosen location on your computer. Open folder as vault . As you become more comfortable with Obsidian, you may have reasons to create and access multiple vaults. At any time you can open a vault from any existing folder. Obsidian recognizes many files types, but Markdown files are most versitale for editting and formatting. Sync your vault in the cloud . If you want to access your vaults across different devices, you have several options. If you prefer to store your files on a cloud-based storage platform like Google Drive or Dropbox, you can easily create a vault from a folder in those locations. Just make sure to sync any folder that contains a vault to your device. ",
    "url": "http://localhost:4000/portfolio_workshop/Obsidian_Materials/00-getting-started.html#create-a-vault",
    "relUrl": "/Obsidian_Materials/00-getting-started.html#create-a-vault"
  },"4": {
    "doc": "Getting Started with Obsidian",
    "title": "Customize Your Vault’s Theme and Appearance",
    "content": "Obsidian is highly customizable! Now that you have a vault, you can make it look most appealing to your taste. | Select the Settings option (gear icon) in the bottom left corner of the window | Choose the Appearance tab | Choose a Base color scheme between Light or Dark | Choose an Accent color | Finally, you can explore Community Themes by selecting “Manage” under Theme. There are tons of options for you to personalize your vault, but some community themes may drastically change your interface. We recommend that you wait to install community theme after reviewing this tutorial, so that visuals are consistent while you learn. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Obsidian_Materials/00-getting-started.html#customize-your-vaults-theme-and-appearance",
    "relUrl": "/Obsidian_Materials/00-getting-started.html#customize-your-vaults-theme-and-appearance"
  },"5": {
    "doc": "Automated Version Control",
    "title": "Automated Version Control",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/01-basics.html",
    "relUrl": "/Git_Materials/01-basics.html"
  },"6": {
    "doc": "Automated Version Control",
    "title": "Objectives",
    "content": ". | Understand the benefits of an automated version control system. | Understand the basics of how automated version control systems work. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/01-basics.html#objectives",
    "relUrl": "/Git_Materials/01-basics.html#objectives"
  },"7": {
    "doc": "Automated Version Control",
    "title": "Questions",
    "content": ". | What is version control and why should I use it? | . We’ll start by exploring how version control can be used to keep track of what one person did and when. Even if you aren’t collaborating with other people, automated version control is much better than this situation: . We’ve all been in this situation before: it seems unnecessary to have multiple nearly-identical versions of the same document. Some word processors let us deal with this a little better, such as Microsoft Word’s Track Changes, Google Docs’ version history, or LibreOffice’s Recording and Displaying Changes. Version control systems start with a base version of the document and then record changes you make each step of the way. You can think of it as a recording of your progress: you can rewind to start at the base document and play back each change you made, eventually arriving at your more recent version. Once you think of changes as separate from the document itself, you can then think about “playing back” different sets of changes on the base document, ultimately resulting in different versions of that document. For example, two users can make independent sets of changes on the same document. Unless multiple users make changes to the same section of the document - a conflict - you can incorporate two sets of changes into the same base document. A version control system is a tool that keeps track of these changes for us, effectively creating different versions of our files. It allows us to decide which changes will be made to the next version (each record of these changes is called a commit), and keeps useful metadata about them. The complete history of commits for a particular project and their metadata make up a repository. Repositories can be kept in sync across different computers, facilitating collaboration among different people. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/01-basics.html#questions",
    "relUrl": "/Git_Materials/01-basics.html#questions"
  },"8": {
    "doc": "Automated Version Control",
    "title": "The Long History of Version Control Systems",
    "content": "Automated version control systems are nothing new. Tools like RCS, CVS, or Subversion have been around since the early 1980s and are used by many large companies. However, many of these are now considered legacy systems (i.e., outdated) due to various limitations in their capabilities. More modern systems, such as Git and Mercurial, are distributed, meaning that they do not need a centralized server to host the repository. These modern systems also include powerful merging tools that make it possible for multiple authors to work on the same files concurrently. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/01-basics.html#the-long-history-of-version-control-systems",
    "relUrl": "/Git_Materials/01-basics.html#the-long-history-of-version-control-systems"
  },"9": {
    "doc": "Automated Version Control",
    "title": "Paper Writing",
    "content": ". | Imagine you drafted an excellent paragraph for a paper you are writing, but later ruin it. How would you retrieve the excellent version of your conclusion? Is it even possible? . | Imagine you have 5 co-authors. How would you manage the changes and comments they make to your paper? If you use LibreOffice Writer or Microsoft Word, what happens if you accept changes made using the Track Changes option? Do you have a history of those changes? . | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/01-basics.html#paper-writing",
    "relUrl": "/Git_Materials/01-basics.html#paper-writing"
  },"10": {
    "doc": "Automated Version Control",
    "title": "Solution",
    "content": ". | Recovering the excellent version is only possible if you created a copy of the old version of the paper. The danger of losing good versions often leads to the problematic workflow illustrated in the PhD Comics cartoon at the top of this page. | Collaborative writing with traditional word processors is cumbersome. Either every collaborator has to work on a document sequentially (slowing down the process of writing), or you have to send out a version to all collaborators and manually merge their comments into your document. The ‘track changes’ or ‘record changes’ option can highlight changes for you and simplifies merging, but as soon as you accept changes you will lose their history. You will then no longer know who suggested that change, why it was suggested, or when it was merged into the rest of the document. Even online word processors like Google Docs or Microsoft Office Online do not fully resolve these problems. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/01-basics.html#solution",
    "relUrl": "/Git_Materials/01-basics.html#solution"
  },"11": {
    "doc": "Automated Version Control",
    "title": "Keypoints",
    "content": ". | Version control is like an unlimited ‘undo’. | Version control also allows many people to work in parallel. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/01-basics.html#keypoints",
    "relUrl": "/Git_Materials/01-basics.html#keypoints"
  },"12": {
    "doc": "Creating and Formatting Notes",
    "title": "Creating and Formatting Notes",
    "content": "Now that your vault is setup, it’s time to start filling it up with notes! . Creating Folders . | Select the New Folder icon under the Files tab on the left side of the window | Name the folder “Learning” | Notice that the folder has a drop-down icon, which will expand/collapse your view of all files in the folder | . Creating Notes . There are several options to create a note: . | Press Ctrl+N for Windows or Cmd+N for macOS on your keyboard | Select the New Note icon in the upper left corner | Right-Click on an existing folder and select the New Note option | . Practice making a few notes using each of these methods. Be sure to give each note a name! You may notice that once a new note is created, it’s opened showing the title highlighted at the top. The title will appear at the top of each note, which makes it very easy to update. For the next section, make a new note in the “Learning” folder, and name it “Markdown Practice”. You will use this note to practice formatting text by writing Markdown. [!Note] ### Organizing Notes It is very easy to organize your notes in the file manager. Notes are displayed in alphabetical order by default, but you can change this by selecting the sort icon at the top. If you want to move notes in and out of folders, you can simply click and drag them to the desired destination. ",
    "url": "http://localhost:4000/portfolio_workshop/Obsidian_Materials/01-creating-notes.html",
    "relUrl": "/Obsidian_Materials/01-creating-notes.html"
  },"13": {
    "doc": "Creating and Formatting Notes",
    "title": "Formatting Notes with Markdown",
    "content": "Notes are useful as long as they contain information that is important to you. However, a reasonable amount of formatting could help convery this information and help you review your notes more efficiently. This section will outline several formats you can add to your notes with simple Markdown syntax. Write these examples in the note Markdown Practice, and notice that the formatting renders immediately. Headings . # Heading 1 ## Heading 2 ### Heading 3 #### Heading 4 . ",
    "url": "http://localhost:4000/portfolio_workshop/Obsidian_Materials/01-creating-notes.html#formatting-notes-with-markdown",
    "relUrl": "/Obsidian_Materials/01-creating-notes.html#formatting-notes-with-markdown"
  },"14": {
    "doc": "Creating and Formatting Notes",
    "title": "Heading 1",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Obsidian_Materials/01-creating-notes.html#heading-1",
    "relUrl": "/Obsidian_Materials/01-creating-notes.html#heading-1"
  },"15": {
    "doc": "Creating and Formatting Notes",
    "title": "Heading 2",
    "content": "Heading 3 . Heading 4 . Emphasis . *This text is italic* **This text is bold** . This text is italic This text is bold . Lists . Bullet List . - item 1 - item 2 - item 3 - item 3a - item 3b . | item 1 | item 2 | item 3 . | item 3a | item 3b | . | . Numbered List . 1. item 1 2. item 2 3. item 3 1. item 3a 2. item 3b . | item 1 | item 2 | item 3 . | item 3a | item 3b | . | . External Links . Format text in your note to have links: . [Obsidian](http://obsidian.md) . Obsidian . Here is a sentence that tells you to learn more tools on our [Workshop Website](https://cmu-lib.github.io/portfolio_workshop/)! . Here is a sentence that tells you to learn more tools on our Workshop Website! . Embed Images . Image from a URL . ![Fred Rogers](https://upload.wikimedia.org/wikipedia/commons/3/36/Fred_Rogers%2C_late_1960s.jpg) . Image from your vault . ![[obsidian-logo.png]] . Resizing an image . ![[obsidian-logo.png|100]] . Blockquotes . &gt; \"As human beings, our job in life is to help people realize how rare and valuable each one of us really is, that each of us has something that no one else has- or ever will have- something inside that is unique to all time. It's our job to encourage each other to discover that uniqueness and to provide ways of developing its expression\" &gt; &gt; - Fred Rogers . “As human beings, our job in life is to help people realize how rare and valuable each one of us really is, that each of us has something that no one else has- or ever will have- something inside that is unique to all time. It’s our job to encourage each other to discover that uniqueness and to provide ways of developing its expression” . | Fred Rogers | . Displaying Code . It is very simple to display examples of code in a variety of languages. You can even display Markdown. Code can be displayed either inline with your text or as a code block. Inline Code . Inline code is displayed like this: `display.inline(type = \"code\")` . Inline code is displayed like this: display.inline(type = \"code\") . Code Blocks . message = \"Hello World\" print(message) . message = \"Hello World\" print(message) . Task Lists . Create an interactive task list in your note, which lets you check off completed tasks: . - [x] done task - [?] task done but still want to view - [ ] not done . | done task | [?] task done but still want to view | not done | . Tables . Column 1|Column 2|Column 3 ---|---|--- Item 1a|Item 2a|Item 3a Item 1b|Item 2b|Item 3b . | Column 1 | Column 2 | Column 3 | . | Item 1a | Item 2a | Item 3a | . | Item 1b | Item 2b | Item 3b | . Tables can sometimes be tedious to make. In the section about Plugins, we will discuss a community plugin that helps streamline making tables. Displaying Equations . Markdown allows you to easily display equations written with $\\LaTeX$. Inline Equations . Provide an equation like $e^{2i\\pi} = 1$ in line with your text. Provide an equation like $e^{2i\\pi} = 1$ in line with your text. Equation Blocks . $$ \\begin{vmatrix}a &amp; b\\\\ c &amp; d \\end{vmatrix}=ad-bc $$ . \\[\\begin{vmatrix}a &amp; b\\\\ c &amp; d \\end{vmatrix}=ad-bc\\] Callouts . Display a callout to emphasize a section of information: . &gt;[!Info] Callouts &gt;You can type `info`, `notes`, `tip`, and other things in the brackets &gt; . [!Info] Callouts You can type info, notes, tip, and other things in the brackets . Embedding Files . Easily embed files in your vault like PDFs: . ![[open-science-for-grad-students.pdf]] . ",
    "url": "http://localhost:4000/portfolio_workshop/Obsidian_Materials/01-creating-notes.html#heading-2",
    "relUrl": "/Obsidian_Materials/01-creating-notes.html#heading-2"
  },"16": {
    "doc": "Running and Quitting",
    "title": "Running and Quitting",
    "content": "Many software developers will often use an integrated development environment (IDE) or a text editor to create and edit their Python programs which can be executed through the IDE or command line directly. While this is a common approach, we are going to use the Jupyter Notebook via JupyterLab for the remainder of this workshop. This has several advantages: . | You can easily type, edit, and copy and paste blocks of code. | Tab complete allows you to easily access the names of things you are using and learn more about them. | It allows you to annotate your code with links, different sized text, bullets, etc. to make it more accessible to you and your collaborators. | It allows you to display figures next to the code that produces them to tell a complete story of the analysis. | . Each notebook contains one or more cells that contain code, text, or images. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html"
  },"17": {
    "doc": "Running and Quitting",
    "title": "Getting Started with JupyterLab",
    "content": "JupyterLab is an application with a web-based user interface from Project Jupyter that enables one to work with documents and activities such as Jupyter notebooks, text editors, terminals, and even custom components in a flexible, integrated, and extensible manner. JupyterLab requires a reasonably up-to-date browser (ideally a current version of Chrome, Safari, or Firefox); Internet Explorer versions 9 and below are not supported. JupyterLab is included as part of the Anaconda Python distribution. If you have not already installed the Anaconda Python distribution, see the setup instructions for installation instructions. Even though JupyterLab is a web-based application, JupyterLab runs locally on your machine and does not require an internet connection. | The JupyterLab server sends messages to your web browser. | The JupyterLab server does the work and the web browser renders the result. | You will type code into the browser and see the result when the web page talks to the JupyterLab server. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#getting-started-with-jupyterlab",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#getting-started-with-jupyterlab"
  },"18": {
    "doc": "Running and Quitting",
    "title": "JupyterLab? What about Jupyter notebooks?",
    "content": "JupyterLab is the next stage in the evolution of the Jupyter Notebook. If you have prior experience working with Jupyter notebooks, then you will have a good idea of what to expect from JupyterLab. Experienced users of Jupyter notebooks interested in a more detailed discussion of the similarities and differences between the JupyterLab and Jupyter notebook user interfaces can find more information in the JupyterLab user interface documentation. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#jupyterlab-what-about-jupyter-notebooks",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#jupyterlab-what-about-jupyter-notebooks"
  },"19": {
    "doc": "Running and Quitting",
    "title": "Starting JupyterLab",
    "content": "You can start the JupyterLab server through the command line or through an application called Anaconda Navigator. Anaconda Navigator is included as part of the Anaconda Python distribution. macOS - Command Line . To start the JupyterLab server you will need to access the command line through the Terminal. There are two ways to open Terminal on Mac. | In your Applications folder, open Utilities and double-click on Terminal | Press Command + spacebar to launch Spotlight. Type Terminal and then double-click the search result or hit Enter | . After you have launched Terminal, type the command to launch the JupyterLab server. $ jupyter lab . Windows Users - Command Line . To start the JupyterLab server you will need to access the Anaconda Prompt. Press Windows Logo Key and search for Anaconda Prompt, click the result or press enter. After you have launched the Anaconda Prompt, type the command: . $ jupyter lab . Anaconda Navigator . To start a JupyterLab server from Anaconda Navigator you must first start Anaconda Navigator (click for detailed instructions on macOS, Windows, and Linux). You can search for Anaconda Navigator via Spotlight on macOS (Command + spacebar), the Windows search function (Windows Logo Key) or opening a terminal shell and executing the anaconda-navigator executable from the command line. After you have launched Anaconda Navigator, click the Launch button under JupyterLab. You may need to scroll down to find it. Here is a screenshot of an Anaconda Navigator page similar to the one that should open on either macOS or Windows. And here is a screenshot of a JupyterLab landing page that should be similar to the one that opens in your default web browser after starting the JupyterLab server on either macOS or Windows. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#starting-jupyterlab",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#starting-jupyterlab"
  },"20": {
    "doc": "Running and Quitting",
    "title": "The JupyterLab Interface",
    "content": "JupyterLab has many features found in traditional integrated development environments (IDEs) but is focused on providing flexible building blocks for interactive, exploratory computing. The JupyterLab Interface consists of the Menu Bar, a collapsable Left Side Bar, and the Main Work Area which contains tabs of documents and activities. Menu Bar . The Menu Bar at the top of JupyterLab has the top-level menus that expose various actions available in JupyterLab along with their keyboard shortcuts (where applicable). The following menus are included by default. | File: Actions related to files and directories such as New, Open, Close, Save, etc. The File menu also includes the Shut Down action used to shutdown the JupyterLab server. | Edit: Actions related to editing documents and other activities such as Undo, Cut, Copy, Paste, etc. | View: Actions that alter the appearance of JupyterLab. | Run: Actions for running code in different activities such as notebooks and code consoles (discussed below). | Kernel: Actions for managing kernels. Kernels in Jupyter will be explained in more detail below. | Tabs: A list of the open documents and activities in the main work area. | Settings: Common JupyterLab settings can be configured using this menu. There is also an Advanced Settings Editor option in the dropdown menu that provides more fine-grained control of JupyterLab settings and configuration options. | Help: A list of JupyterLab and kernel help links. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#the-jupyterlab-interface",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#the-jupyterlab-interface"
  },"21": {
    "doc": "Running and Quitting",
    "title": "Kernels",
    "content": "The JupyterLab docs define kernels as “separate processes started by the server that run your code in different programming languages and environments.” When we open a Jupyter Notebook, that starts a kernel - a process - that is going to run the code. In this lesson, we’ll be using the Jupyter ipython kernel which lets us run Python 3 code interactively. Using other Jupyter kernels for other programming languages would let us write and execute code in other programming languages in the same JupyterLab interface, like R, Java, Julia, Ruby, JavaScript, Fortran, etc. A screenshot of the default Menu Bar is provided below. Left Sidebar . The left sidebar contains a number of commonly used tabs, such as a file browser (showing the contents of the directory where the JupyterLab server was launched), a list of running kernels and terminals, the command palette, and a list of open tabs in the main work area. A screenshot of the default Left Side Bar is provided below. The left sidebar can be collapsed or expanded by selecting “Show Left Sidebar” in the View menu or by clicking on the active sidebar tab. Main Work Area . The main work area in JupyterLab enables you to arrange documents (notebooks, text files, etc.) and other activities (terminals, code consoles, etc.) into panels of tabs that can be resized or subdivided. A screenshot of the default Main Work Area is provided below. Drag a tab to the center of a tab panel to move the tab to the panel. Subdivide a tab panel by dragging a tab to the left, right, top, or bottom of the panel. The work area has a single current activity. The tab for the current activity is marked with a colored top border (blue by default). ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#kernels",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#kernels"
  },"22": {
    "doc": "Running and Quitting",
    "title": "Creating a Python script",
    "content": ". | To start writing a new Python program click the Text File icon under the Other header in the Launcher tab of the Main Work Area. | You can also create a new plain text file by selecting the New -&gt; Text File from the File menu in the Menu Bar. | . | To convert this plain text file to a Python program, select the Save File As action from the File menu in the Menu Bar and give your new text file a name that ends with the .py extension. | The .py extension lets everyone (including the operating system) know that this text file is a Python program. | This is convention, not a requirement. | . | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#creating-a-python-script",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#creating-a-python-script"
  },"23": {
    "doc": "Running and Quitting",
    "title": "Creating a Jupyter Notebook",
    "content": "To open a new notebook click the Python 3 icon under the Notebook header in the Launcher tab in the main work area. You can also create a new notebook by selecting New -&gt; Notebook from the File menu in the Menu Bar. Additional notes on Jupyter notebooks. | Notebook files have the extension .ipynb to distinguish them from plain-text Python programs. | Notebooks can be exported as Python scripts that can be run from the command line. | . Below is a screenshot of a Jupyter notebook running inside JupyterLab. If you are interested in more details, then see the official notebook documentation. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#creating-a-jupyter-notebook",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#creating-a-jupyter-notebook"
  },"24": {
    "doc": "Running and Quitting",
    "title": "How It’s Stored",
    "content": ". | The notebook file is stored in a format called JSON. | Just like a webpage, what’s saved looks different from what you see in your browser. | But this format allows Jupyter to mix source code, text, and images, all in one file. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#how-its-stored",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#how-its-stored"
  },"25": {
    "doc": "Running and Quitting",
    "title": "Arranging Documents into Panels of Tabs",
    "content": "In the JupyterLab Main Work Area you can arrange documents into panels of tabs. Here is an example from the official documentation. First, create a text file, Python console, and terminal window and arrange them into three panels in the main work area. Next, create a notebook, terminal window, and text file and arrange them into three panels in the main work area. Finally, create your own combination of panels and tabs. What combination of panels and tabs do you think will be most useful for your workflow? . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#arranging-documents-into-panels-of-tabs",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#arranging-documents-into-panels-of-tabs"
  },"26": {
    "doc": "Running and Quitting",
    "title": "Solution",
    "content": "After creating the necessary tabs, you can drag one of the tabs to the center of a panel to move the tab to the panel; next you can subdivide a tab panel by dragging a tab to the left, right, top, or bottom of the panel. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#solution",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#solution"
  },"27": {
    "doc": "Running and Quitting",
    "title": "Code vs. Text",
    "content": "Jupyter mixes code and text in different types of blocks, called cells. We often use the term “code” to mean “the source code of software written in a language such as Python”. A “code cell” in a Notebook is a cell that contains software; a “text cell” is one that contains ordinary prose written for human beings. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#code-vs-text",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#code-vs-text"
  },"28": {
    "doc": "Running and Quitting",
    "title": "The Notebook has Command and Edit modes.",
    "content": ". | If you press Esc and Return alternately, the outer border of your code cell will change from gray to blue. | These are the Command (gray) and Edit (blue) modes of your notebook. | Command mode allows you to edit notebook-level features, and Edit mode changes the content of cells. | When in Command mode (esc/gray), . | The b key will make a new cell below the currently selected cell. | The a key will make one above. | The x key will delete the current cell. | The z key will undo your last cell operation (which could be a deletion, creation, etc). | . | All actions can be done using the menus, but there are lots of keyboard shortcuts to speed things up. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#the-notebook-has-command-and-edit-modes",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#the-notebook-has-command-and-edit-modes"
  },"29": {
    "doc": "Running and Quitting",
    "title": "Command Vs. Edit",
    "content": "In the Jupyter notebook page are you currently in Command or Edit mode? Switch between the modes. Use the shortcuts to generate a new cell. Use the shortcuts to delete a cell. Use the shortcuts to undo the last cell operation you performed. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#command-vs-edit",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#command-vs-edit"
  },"30": {
    "doc": "Running and Quitting",
    "title": "Solution",
    "content": "Command mode has a grey border and Edit mode has a blue border. Use Esc and Return to switch between modes. You need to be in Command mode (Press Esc if your cell is blue). Type b or a. You need to be in Command mode (Press Esc if your cell is blue). Type x. You need to be in Command mode (Press Esc if your cell is blue). Type z. Use the keyboard and mouse to select and edit cells. | Pressing the Return key turns the border blue and engages Edit mode, which allows you to type within the cell. | Because we want to be able to write many lines of code in a single cell, pressing the Return key when in Edit mode (blue) moves the cursor to the next line in the cell just like in a text editor. | We need some other way to tell the Notebook we want to run what’s in the cell. | Pressing Shift+Return together will execute the contents of the cell. | Notice that the Return and Shift keys on the right of the keyboard are right next to each other. | . The Notebook will turn Markdown into pretty-printed documentation. | Notebooks can also render Markdown. | A simple plain-text format for writing lists, links, and other things that might go into a web page. | Equivalently, a subset of HTML that looks like what you’d send in an old-fashioned email. | . | Turn the current cell into a Markdown cell by entering the Command mode (Esc/gray) and press the M key. | In [ ]: will disappear to show it is no longer a code cell and you will be able to write in Markdown. | Turn the current cell into a Code cell by entering the Command mode (Esc/gray) and press the y key. | . Markdown does most of what HTML does. * Use asterisks * to create * bullet lists. | Use asterisks | to create | bullet lists. | . 1. Use numbers 1. to create 1. numbered lists. | Use numbers | to create | numbered lists. | . * You can use indents * To create sublists * of the same type * Or sublists 1. Of different 1. types . | You can use indents . | To create sublists | of the same type | . | Or sublists . | Of different | types | . | . # A Level-1 Heading . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#solution-1",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#solution-1"
  },"31": {
    "doc": "Running and Quitting",
    "title": "A Level-1 Heading",
    "content": "## A Level-2 Heading (etc.) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#a-level-1-heading",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#a-level-1-heading"
  },"32": {
    "doc": "Running and Quitting",
    "title": "A Level-2 Heading (etc.)",
    "content": "Line breaks don't matter. But blank lines create new paragraphs. Line breaks don’t matter. But blank lines create new paragraphs. [Create links](http://software-carpentry.org) with `[...](...)`. Or use [named links][data_carpentry]. [data_carpentry]: http://datacarpentry.org . Create links with [...](...). Or use named links. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#a-level-2-heading-etc",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#a-level-2-heading-etc"
  },"33": {
    "doc": "Running and Quitting",
    "title": "Creating Lists in Markdown",
    "content": "Create a nested list in a Markdown cell in a notebook that looks like this: . | Get funding. | Do work. | Design experiment. | Collect data. | Analyze. | . | Write up. | Publish. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#creating-lists-in-markdown",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#creating-lists-in-markdown"
  },"34": {
    "doc": "Running and Quitting",
    "title": "Solution",
    "content": "This challenge integrates both the numbered list and bullet list. Note that the bullet list is indented 2 spaces so that it is inline with the items of the numbered list. 1. Get funding. 2. Do work. * Design experiment. * Collect data. * Analyze. 3. Write up. 4. Publish. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#solution-2",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#solution-2"
  },"35": {
    "doc": "Running and Quitting",
    "title": "More Math",
    "content": "What is displayed when a Python cell in a notebook that contains several calculations is executed? For example, what happens when this cell is executed? . 7 * 3 2 + 1 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#more-math",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#more-math"
  },"36": {
    "doc": "Running and Quitting",
    "title": "Solution",
    "content": "Python returns the output of the last calculation. 3 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#solution-3",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#solution-3"
  },"37": {
    "doc": "Running and Quitting",
    "title": "Change an Existing Cell from Code to Markdown",
    "content": "What happens if you write some Python in a code cell and then you switch it to a Markdown cell? For example, put the following in a code cell: . x = 6 * 7 + 12 print(x) . And then run it with Shift+Return to be sure that it works as a code cell. Now go back to the cell and use Esc then m to switch the cell to Markdown and “run” it with Shift+Return. What happened and how might this be useful? . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#change-an-existing-cell-from-code-to-markdown",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#change-an-existing-cell-from-code-to-markdown"
  },"38": {
    "doc": "Running and Quitting",
    "title": "Solution",
    "content": "The Python code gets treated like Markdown text. The lines appear as if they are part of one contiguous paragraph. This could be useful to temporarily turn on and off cells in notebooks that get used for multiple purposes. x = 6 * 7 + 12 print(x) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#solution-4",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#solution-4"
  },"39": {
    "doc": "Running and Quitting",
    "title": "Equations",
    "content": "Standard Markdown (such as we’re using for these notes) won’t render equations, but the Notebook will. Create a new Markdown cell and enter the following: . $\\sum_{i=1}^{N} 2^{-i} \\approx 1$ . (It’s probably easier to copy and paste.) What does it display? What do you think the underscore, _, circumflex, ^, and dollar sign, $, do? . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#equations",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#equations"
  },"40": {
    "doc": "Running and Quitting",
    "title": "Solution",
    "content": "The notebook shows the equation as it would be rendered from LaTeX equation syntax. The dollar sign, $, is used to tell Markdown that the text in between is a LaTeX equation. If you’re not familiar with LaTeX, underscore, _, is used for subscripts and circumflex, ^, is used for superscripts. A pair of curly braces, { and }, is used to group text together so that the statement i=1 becomes the subscript and N becomes the superscript. Similarly, -i is in curly braces to make the whole statement the superscript for 2. \\sum and \\approx are LaTeX commands for “sum over” and “approximate” symbols. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#solution-5",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#solution-5"
  },"41": {
    "doc": "Running and Quitting",
    "title": "Closing JupyterLab",
    "content": ". | From the Menu Bar select the “File” menu and then choose “Shut Down” at the bottom of the dropdown menu. You will be prompted to confirm that you wish to shutdown the JupyterLab server (don’t forget to save your work!). Click “Shut Down” to shutdown the JupyterLab server. | To restart the JupyterLab server you will need to re-run the following command from a shell. | . $ jupyter lab . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#closing-jupyterlab",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#closing-jupyterlab"
  },"42": {
    "doc": "Running and Quitting",
    "title": "Closing JupyterLab",
    "content": "Practice closing and restarting the JupyterLab server. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/01-run-quit.html#closing-jupyterlab-1",
    "relUrl": "/Python_Series_Materials/part_1/01-run-quit.html#closing-jupyterlab-1"
  },"43": {
    "doc": "Part 2 Advanced Data Cleaning with Citizen Science Data",
    "title": "Citizen Science Lesson: Advanced Data Cleaning",
    "content": "In this activity set, we will be: . | Create a new project from the citizen science dataset and use the clustering feature | Split and concatenate various columns in the dataset | Restructure the dataset by removing columns and rows, and then work with Undo/Redo to roll those changes back | Export a JSON script to perform the same process on another dataset | Shutting down OpenRefine | . If you haven’t already, download the workshop files and save them in a folder on your desktop. Make sure to extract the files from the zip file. Let’s get started! . ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt2_citizen_science/01_citizensci_exercises.html#citizen-science-lesson-advanced-data-cleaning",
    "relUrl": "/OpenRefine_Materials/pt2_citizen_science/01_citizensci_exercises.html#citizen-science-lesson-advanced-data-cleaning"
  },"44": {
    "doc": "Part 2 Advanced Data Cleaning with Citizen Science Data",
    "title": "Part 2 Advanced Data Cleaning with Citizen Science Data",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt2_citizen_science/01_citizensci_exercises.html",
    "relUrl": "/OpenRefine_Materials/pt2_citizen_science/01_citizensci_exercises.html"
  },"45": {
    "doc": "Part 1 OpenRefine Basics with Personal Consumption Expeditures Data",
    "title": "Part 1: OpenRefine Basics with Personal Consumption Expeditures Data",
    "content": "In this activity set, we will be: . | Importing a spreadsheet of data into OpenRefine | Performing basic clean-up functions like trimming whitespace and deleting columns | Filtering and faceting data | Transposing data from wide to long format | Exporting a dataset from OpenRefine | . If you haven’t already, download the workshop files and save them in a folder on your desktop. Make sure to extract the files from the zip file. Let’s get started! . ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt1_expenditure/01_expenditures_exercises.html#part-1-openrefine-basics-with-personal-consumption-expeditures-data",
    "relUrl": "/OpenRefine_Materials/pt1_expenditure/01_expenditures_exercises.html#part-1-openrefine-basics-with-personal-consumption-expeditures-data"
  },"46": {
    "doc": "Part 1 OpenRefine Basics with Personal Consumption Expeditures Data",
    "title": "Part 1 OpenRefine Basics with Personal Consumption Expeditures Data",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt1_expenditure/01_expenditures_exercises.html",
    "relUrl": "/OpenRefine_Materials/pt1_expenditure/01_expenditures_exercises.html"
  },"47": {
    "doc": "Workshop Exercises",
    "title": "Workshop Exercises",
    "content": "In set of exercises, we will be: . | Creating and collaborating on OSF projects | Using project templates | Uploading files from your desktop | Connecting external platforms like Google Drive, Mendeley, and GitHub | Understanding version control in OSF | . If you haven’t already, download the workshop files and save them in a folder on your desktop. Make sure to extract the files from the zip file. Exercise 1 Copy a template from an existing project . | Once you’ve signed into your account, choose Search from the menu at the top of the page and search for “CMU Getting Started with OSF Demo”. | Click on the project from the search results. Find the ‘fork’ button in the upper righthand corner and choose ‘Duplicate template’ from the drop-down menu. | Click ‘Create’ when prompted. You should now have a clean template of the project in your own account without any files or add-ons. | If you’d like, change the name of the project by clicking on the project name. | . Exercise 2 Add contributors to your project . | Add your neighbor as a contributor by clicking on Contributors from the menu at the top of the project page and then the green “+ Add” button. | Search for them by name or user profile information. | Click the green plus sign next to their name and choose their permissions from the drop-down menu. Click Next. | Add them as contributors to all components in the project by clicking on Select All in the window that appears. Click Add. | . Exercise 3 Create a new component . | Return to the project’s home page by clicking on the project name in the upper left. | In the components section, click ‘Add Component’. | Call this component “Survey Instruments” and check the box next to “Add contributors…”. Choose the ‘Methods and Measures’ category from the drop-down menu at the bottom of the window (which appears when you click on More). | Click Create and go to the new component. Is the component private or public by default? | . Exercise 4 Add files to a component . | Click on OSF Storage in the files section of the Survey Instrument component. Click on ’+ Create Folder’ to add a new folder. | Name this folder ‘Surveys’, then click the green plus + to add the new file. | Click on the folder and add the file ‘Survey-Instrument_RDM-Practices-in-MRI_VanGulick_Borghi.pdf’ from the workshop files that you downloaded before today’s session. You can either drag and drop the file to the Survey folder or click ‘Upload’ and browse to the file. | Now try adding the files ‘Borghi_VanGulick_2018_data.csv’ and ‘Borghi_VanGulick_2018_datadictionary.csv’ to the Data component. | . Exercise 5 Change the privacy settings . | Go to the Data component. | Click on the “Make Public” button in the upper righthand corner and confirm. | Navigate back to the project home page. Notice that there is no longer a lock symbol next to the Data component. | . Exercise 6 Make changes and access previous version . | Open the file ‘Borghi_VanGulick_2018_data.csv’ from your Workshop Files folder on your computer. | Delete the first two columns and save without changing the file name. | Replace the file in your data component with the new version by dragging and dropping or uploading to the Data component OSF storage, where the previous version is located. | Click on the file to view in the project window. Note this is now version 2. | Click on the clock with an arrow on the righthand side under the ‘i’. Download version 1 to your computer. | . Exercise 7 Wiki add and delete pages . | Click the arrow on the right side in the ‘Wiki’ box located on your project homepage or click the Wiki button in the navigation bar. | To add a new page to the Wiki click the +New button on the left sidebar. | An ‘Add new wiki page’ will pop up. Enter the the title, then click Add. The page will be added to your Wiki. | To delete a page, click on the page that you want to delete. | Click the Delete button above the left sidebar. | . Exercise 8 Connect an add-on of your choice . | OSF allows you to connect with multiple add-on tools for storage and citation management such as GitHub, Google Drive and Mendeley. | Go to https://osf.io/rfw3q/addons/. Choose an add-on from the list that you typically use and follow OSF’s step-by-step instructions to connect it to the project. | We’ll be on hand to troubleshoot as you work through the steps. | . ",
    "url": "http://localhost:4000/portfolio_workshop/OSF_Materials/exercises/01_osf_exercises.html",
    "relUrl": "/OSF_Materials/exercises/01_osf_exercises.html"
  },"48": {
    "doc": "Linking Notes and Visualizing Connections",
    "title": "Linking Notes and Visualizing Connections",
    "content": "Our thoughts, ideas, and work are all interconnected, so why can’t our notes be as well? Obsidian makes it incredibly easy to connect our notes and search for notes based on related concepts. Internal Links . Now let’s make more notes and see how we can make connections. | Create a new folder in your vault called Reflection | Open a new note in this folder called entry-01 | Type some text about your experience learning Markdown, and make a reference to the note Markdown Practice like this: | . In the prior lesson, I learned how to make lists, embed images, and other useful formats. I practiced writing Markdown in my [[Markdown Practice]] note, inside my vault. Notice that a link to Markdown Practice forms. Now you can quickly access this note by selecting the link. This feature is very helpful and convinient, and that’s not the only benefit. Now these two notes have a relationship that Obsidian uses to help you visualize and find notes. ",
    "url": "http://localhost:4000/portfolio_workshop/Obsidian_Materials/02-linking-notes.html",
    "relUrl": "/Obsidian_Materials/02-linking-notes.html"
  },"49": {
    "doc": "Linking Notes and Visualizing Connections",
    "title": "Graph View",
    "content": "Graph view let’s you visualize the relationships between your notes in your vault. To access this feature, select the graph view icon that is second from the top on the left pane: . A window should open that looks like this: . This is the Graph View in Obsidian. You will see circles (or nodes) that represent your notes. There should be two nodes for Markdown Practice and entry-01. Notice that these two nodes are connected by a line. Connecting lines represent internal links between notes. Since you made a reference to Markdown Practice in entry-01, a connection was created in this graph. As you create more notes, and make more internal links, this network will expand with more nodes and connections branching out along your vault. As a note develops more connections, the node size will increase. This will make it very easy to visualize what notes, or ideas, are more prominent in your vault. Eventually, your graph may look something like this (taken from here): . Customizing your graph . There are several tools in the Graph View window that lets you customize the appearance and layout of your graph. Take a few minutes to play with these tools. ",
    "url": "http://localhost:4000/portfolio_workshop/Obsidian_Materials/02-linking-notes.html#graph-view",
    "relUrl": "/Obsidian_Materials/02-linking-notes.html#graph-view"
  },"50": {
    "doc": "Linking Notes and Visualizing Connections",
    "title": "Tags",
    "content": "You can also add #tags to your notes! Tag your notes with certain subjects or themes that you anticipate will come up often. Just type # and add a brief, but descriptive name for your tag. That’s can go anywhere, like the middle of a sentence, in a heading, or simply at the top of your note. Let’s tag your existing notes: . | Start with Markdown Practice. Since this note is obviously about markdown, add #markdown to the top of the note | Next, in entry-01, also add #markdown since markdown was also mentioned here | Finally, add one more tag to entry-01. Since you created your first internal link in this note, also add #internal-links | . Finding notes with tags . So what are these tags good for? Click on one to find out! (Hint: click on #markdown in entry-01) . When you select a tag, the search tab will open with a tag search string populated in the search bar (eg. tag:#markdown). Underneath, the results show a list of each note that contains the tag and shows a preview of where the tag is located in the note. This function can be extremely useful when you have hundreds of notes, and you want to find a past note that mentions a specific topic. Tags in graph view . Now go back to the graph view window and see how tags can enhance this experience. Open up Filters and turn on the toggle switch for Tags. Now graph view should look like this: . You can now visualize the connectivity between your notes and the tags within those notes. Even with few notes in your vault, you can already see intricate connections. #markdown is connected to both notes, since it was written in each, however, #internal-links is only connected to one note. Let’s make your vault, and the connections within your vault, a little more interesting. Create a new note in your Reflection folder called “entry-02” and add the following text: . In my next lesson, I learned about #internal-links, #graph-view, and #tags. Now you’ve added a couple more tags, and referenced an existing one. Graph view should now look even more different than before. Now entry-02 is included in your network of notes, and it’s connected to three tags. This note doesn’t contain internal links to other notes, so no connections were drawn. However, entry-01 and entry-02 are both connected to #internal-links! Although there wasn’t an internal link explicitly made between these two notes, their shared relationship with a tag shows an indirect connection! Visualizing connections in this way may help you identify common themes between your notes that you may not have realized. So now that your vault has new tags, you may be wondering how you can keep track of them all. Open up the right pane of your Obisidian and select the Tags tab. This will display a list of all existing tags in order of most to least frequently used. Notice that a count is shown next to each tag. You can also change the sort order if you prefer alphabetical. You can select a tag from this list to search notes containing the tag, exactly like the results shown earlier in this lesson. ",
    "url": "http://localhost:4000/portfolio_workshop/Obsidian_Materials/02-linking-notes.html#tags",
    "relUrl": "/Obsidian_Materials/02-linking-notes.html#tags"
  },"51": {
    "doc": "Setting Up Git",
    "title": "Setting Up Git",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/02-setup.html",
    "relUrl": "/Git_Materials/02-setup.html"
  },"52": {
    "doc": "Setting Up Git",
    "title": "Objectives",
    "content": ". | Configure git the first time it is used on a computer. | Understand the meaning of the --global configuration flag. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/02-setup.html#objectives",
    "relUrl": "/Git_Materials/02-setup.html#objectives"
  },"53": {
    "doc": "Setting Up Git",
    "title": "Questions",
    "content": ". | How do I get set up to use Git? | . When we use Git on a new computer for the first time, we need to configure a few things. Below are a few examples of configurations we will set as we get started with Git: . | our name and email address, | what our preferred text editor is, | and that we want to use these settings globally (i.e. for every project). | . On a command line, Git commands are written as git verb options, where verb is what we actually want to do and options is additional optional information which may be needed for the verb. So here is how Dracula sets up his new laptop: . $ git config --global user.name \"Vlad Dracula\" $ git config --global user.email \"vlad@tran.sylvan.ia\" . Please use your own name and email address instead of Dracula’s. This user name and email will be associated with your subsequent Git activity, which means that any changes pushed to GitHub, BitBucket, GitLab or another Git host server after this lesson will include this information. For this lesson, we will be interacting with GitHub and so the email address used should be the same as the one used when setting up your GitHub account. If you are concerned about privacy, please review GitHub’s instructions for keeping your email address private. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/02-setup.html#questions",
    "relUrl": "/Git_Materials/02-setup.html#questions"
  },"54": {
    "doc": "Setting Up Git",
    "title": "Keeping your email private",
    "content": "If you elect to use a private email address with GitHub, then use that same email address for the user.email value, e.g. username@users.noreply.github.com replacing username with your GitHub one. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/02-setup.html#keeping-your-email-private",
    "relUrl": "/Git_Materials/02-setup.html#keeping-your-email-private"
  },"55": {
    "doc": "Setting Up Git",
    "title": "Line Endings",
    "content": "As with other keys, when you hit Enter or ↵ or on Macs, Return on your keyboard, your computer encodes this input as a character. Different operating systems use different character(s) to represent the end of a line. (You may also hear these referred to as newlines or line breaks.) Because Git uses these characters to compare files, it may cause unexpected issues when editing a file on different machines. Though it is beyond the scope of this lesson, you can read more about this issue in the Pro Git book. You can change the way Git recognizes and encodes line endings using the core.autocrlf command to git config. The following settings are recommended: . On macOS and Linux: . $ git config --global core.autocrlf input . And on Windows: . $ git config --global core.autocrlf false . Dracula also has to set his favorite text editor, following this table: . | Editor | Configuration command | . | Atom | $ git config --global core.editor \"atom --wait\" | . | nano | $ git config --global core.editor \"nano -w\" | . | BBEdit (Mac, with command line tools) | $ git config --global core.editor \"bbedit -w\" | . | Sublime Text (Mac) | $ git config --global core.editor \"/Applications/Sublime\\ Text.app/Contents/SharedSupport/bin/subl -n -w\" | . | Sublime Text (Win, 32-bit install) | $ git config --global core.editor \"'c:/program files (x86)/sublime text 3/sublime_text.exe' -w\" | . | Sublime Text (Win, 64-bit install) | $ git config --global core.editor \"'c:/program files/sublime text 3/sublime_text.exe' -w\" | . | Notepad (Win) | $ git config --global core.editor \"c:/Windows/System32/notepad.exe\" | . | Notepad++ (Win, 32-bit install) | $ git config --global core.editor \"'c:/program files (x86)/Notepad++/notepad++.exe' -multiInst -notabbar -nosession -noPlugin\" | . | Notepad++ (Win, 64-bit install) | $ git config --global core.editor \"'c:/program files/Notepad++/notepad++.exe' -multiInst -notabbar -nosession -noPlugin\" | . | Kate (Linux) | $ git config --global core.editor \"kate\" | . | Gedit (Linux) | $ git config --global core.editor \"gedit --wait --new-window\" | . | Scratch (Linux) | $ git config --global core.editor \"scratch-text-editor\" | . | Emacs | $ git config --global core.editor \"emacs\" | . | Vim | $ git config --global core.editor \"vim\" | . | VS Code | $ git config --global core.editor \"code --wait\" | . It is possible to reconfigure the text editor for Git whenever you want to change it. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/02-setup.html#line-endings",
    "relUrl": "/Git_Materials/02-setup.html#line-endings"
  },"56": {
    "doc": "Setting Up Git",
    "title": "Exiting Vim",
    "content": "Note that Vim is the default editor for many programs. If you haven’t used Vim before and wish to exit a session without saving your changes, press Esc then type :q! and hit Enter or ↵ or on Macs, Return. If you want to save your changes and quit, press Esc then type :wq and hit Enter or ↵ or on Macs, Return. Git (2.28+) allows configuration of the name of the branch created when you initialize any new repository. Dracula decides to use that feature to set it to main so it matches the cloud service he will eventually use. $ git config --global init.defaultBranch main . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/02-setup.html#exiting-vim",
    "relUrl": "/Git_Materials/02-setup.html#exiting-vim"
  },"57": {
    "doc": "Setting Up Git",
    "title": "Default Git branch naming",
    "content": "Source file changes are associated with a “branch.” For new learners in this lesson, it’s enough to know that branches exist, and this lesson uses one branch. By default, Git will create a branch called master when you create a new repository with git init (as explained in the next Episode). This term evokes the racist practice of human slavery and the software development community has moved to adopt more inclusive language. In 2020, most Git code hosting services transitioned to using main as the default branch. As an example, any new repository that is opened in GitHub and GitLab default to main. However, Git has not yet made the same change. As a result, local repositories must be manually configured have the same main branch name as most cloud services. For versions of Git prior to 2.28, the change can be made on an individual repository level. The command for this is in the next episode. Note that if this value is unset in your local Git configuration, the init.defaultBranch value defaults to master. The five commands we just ran above only need to be run once: the flag --global tells Git to use the settings for every project, in your user account, on this computer. Let’s review those settings and test our core.editor right away: . $ git config --global --edit . Let’s close the file without making any additional changes. Remember, since typos in the config file will cause issues, it’s safer to view the configuration with: . $ git config --list . And if necessary, change your configuration using the same commands to choose another editor or update your email address. This can be done as many times as you want. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/02-setup.html#default-git-branch-naming",
    "relUrl": "/Git_Materials/02-setup.html#default-git-branch-naming"
  },"58": {
    "doc": "Setting Up Git",
    "title": "Proxy",
    "content": "In some networks you need to use a proxy. If this is the case, you may also need to tell Git about the proxy: . $ git config --global http.proxy proxy-url $ git config --global https.proxy proxy-url . To disable the proxy, use . $ git config --global --unset http.proxy $ git config --global --unset https.proxy . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/02-setup.html#proxy",
    "relUrl": "/Git_Materials/02-setup.html#proxy"
  },"59": {
    "doc": "Setting Up Git",
    "title": "Git Help and Manual",
    "content": "Always remember that if you forget the subcommands or options of a git command, you can access the relevant list of options typing git &lt;command&gt; -h or access the corresponding Git manual by typing git &lt;command&gt; --help, e.g.: . $ git config -h $ git config --help . While viewing the manual, remember the : is a prompt waiting for commands and you can press Q to exit the manual. More generally, you can get the list of available git commands and further resources of the Git manual typing: . $ git help . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/02-setup.html#git-help-and-manual",
    "relUrl": "/Git_Materials/02-setup.html#git-help-and-manual"
  },"60": {
    "doc": "Setting Up Git",
    "title": "Keypoints",
    "content": ". | Use git config with the --global option to configure a user name, email address, editor, and other preferences once per machine. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/02-setup.html#keypoints",
    "relUrl": "/Git_Materials/02-setup.html#keypoints"
  },"61": {
    "doc": "Variables and Assignment",
    "title": "Variables and Assignment",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/02-variables.html",
    "relUrl": "/Python_Series_Materials/part_1/02-variables.html"
  },"62": {
    "doc": "Variables and Assignment",
    "title": "Use variables to store values.",
    "content": ". | Variables are names for values. | In Python the = symbol assigns the value on the right to the name on the left. | The variable is created when a value is assigned to it. | Here, Python assigns an age to a variable age and a name in quotes to a variable first_name. age = 42 first_name = 'Ahmed' . | Variable names . | can only contain letters, digits, and underscore _ (typically used to separate words in long variable names) | cannot start with a digit | are case sensitive (age, Age and AGE are three different variables) | . | Variable names that start with underscores like __alistairs_real_age have a special meaning so we won’t do that until we understand the convention. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/02-variables.html#use-variables-to-store-values",
    "relUrl": "/Python_Series_Materials/part_1/02-variables.html#use-variables-to-store-values"
  },"63": {
    "doc": "Variables and Assignment",
    "title": "Use print to display values.",
    "content": ". | Python has a built-in function called print that prints things as text. | Call the function (i.e., tell Python to run it) by using its name. | Provide values to the function (i.e., the things to print) in parentheses. | To add a string to the printout, wrap the string in single or double quotes. | The values passed to the function are called arguments | . print(first_name, 'is', age, 'years old') . Ahmed is 42 years old . | print automatically puts a single space between items to separate them. | And wraps around to a new line at the end. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/02-variables.html#use-print-to-display-values",
    "relUrl": "/Python_Series_Materials/part_1/02-variables.html#use-print-to-display-values"
  },"64": {
    "doc": "Variables and Assignment",
    "title": "Variables must be created before they are used.",
    "content": ". | If a variable doesn’t exist yet, or if the name has been mis-spelled, Python reports an error. (Unlike some languages, which “guess” a default value.) | . print(last_name) . --------------------------------------------------------------------------- NameError Traceback (most recent call last) &lt;ipython-input-1-c1fbb4e96102&gt; in &lt;module&gt;() ----&gt; 1 print(last_name) NameError: name 'last_name' is not defined . | The last line of an error message is usually the most informative. | We will look at error messages in detail later. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/02-variables.html#variables-must-be-created-before-they-are-used",
    "relUrl": "/Python_Series_Materials/part_1/02-variables.html#variables-must-be-created-before-they-are-used"
  },"65": {
    "doc": "Variables and Assignment",
    "title": "Variables Persist Between Cells",
    "content": "Be aware that it is the order of execution of cells that is important in a Jupyter notebook, not the order in which they appear. Python will remember all the code that was run previously, including any variables you have defined, irrespective of the order in the notebook. Therefore if you define variables lower down the notebook and then (re)run cells further up, those defined further down will still be present. As an example, create two cells with the following content, in this order: . print(myval) . myval = 1 . If you execute this in order, the first cell will give an error. However, if you run the first cell after the second cell it will print out 1. To prevent confusion, it can be helpful to use the Kernel -&gt; Restart &amp; Run All option which clears the interpreter and runs everything from a clean slate going top to bottom. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/02-variables.html#variables-persist-between-cells",
    "relUrl": "/Python_Series_Materials/part_1/02-variables.html#variables-persist-between-cells"
  },"66": {
    "doc": "Variables and Assignment",
    "title": "Variables can be used in calculations.",
    "content": ". | We can use variables in calculations just as if they were values. | Remember, we assigned the value 42 to age a few lines ago. | . | . age = age + 3 print('Age in three years:', age) . Age in three years: 45 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/02-variables.html#variables-can-be-used-in-calculations",
    "relUrl": "/Python_Series_Materials/part_1/02-variables.html#variables-can-be-used-in-calculations"
  },"67": {
    "doc": "Variables and Assignment",
    "title": "Use an index to get a single character from a string.",
    "content": ". | The characters (individual letters, numbers, and so on) in a string are ordered. For example, the string 'AB' is not the same as 'BA'. Because of this ordering, we can treat the string as a list of characters. | Each position in the string (first, second, etc.) is given a number. This number is called an index or sometimes a subscript. | Indices are numbered from 0. | Use the position’s index in square brackets to get the character at that position. | . atom_name = 'helium' print(atom_name[0]) . h . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/02-variables.html#use-an-index-to-get-a-single-character-from-a-string",
    "relUrl": "/Python_Series_Materials/part_1/02-variables.html#use-an-index-to-get-a-single-character-from-a-string"
  },"68": {
    "doc": "Variables and Assignment",
    "title": "Use a slice to get a substring.",
    "content": ". | A part of a string is called a substring. A substring can be as short as a single character. | An item in a list is called an element. Whenever we treat a string as if it were a list, the string’s elements are its individual characters. | A slice is a part of a string (or, more generally, a part of any list-like thing). | We take a slice with the notation [start:stop], where start is the integer index of the first element we want and stop is the integer index of the element just after the last element we want. | The difference between stop and start is the slice’s length. | Taking a slice does not change the contents of the original string. Instead, taking a slice returns a copy of part of the original string. | . atom_name = 'sodium' print(atom_name[0:3]) . sod . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/02-variables.html#use-a-slice-to-get-a-substring",
    "relUrl": "/Python_Series_Materials/part_1/02-variables.html#use-a-slice-to-get-a-substring"
  },"69": {
    "doc": "Variables and Assignment",
    "title": "Use the built-in function len to find the length of a string.",
    "content": "print(len('helium')) . 6 . | Nested functions are evaluated from the inside out, like in mathematics. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/02-variables.html#use-the-built-in-function-len-to-find-the-length-of-a-string",
    "relUrl": "/Python_Series_Materials/part_1/02-variables.html#use-the-built-in-function-len-to-find-the-length-of-a-string"
  },"70": {
    "doc": "Variables and Assignment",
    "title": "Python is case-sensitive.",
    "content": ". | Python thinks that upper- and lower-case letters are different, so Name and name are different variables. | There are conventions for using upper-case letters at the start of variable names so we will use lower-case letters for now. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/02-variables.html#python-is-case-sensitive",
    "relUrl": "/Python_Series_Materials/part_1/02-variables.html#python-is-case-sensitive"
  },"71": {
    "doc": "Variables and Assignment",
    "title": "Use meaningful variable names.",
    "content": ". | Python doesn’t care what you call variables as long as they obey the rules (alphanumeric characters and the underscore). | . flabadab = 42 ewr_422_yY = 'Ahmed' print(ewr_422_yY, 'is', flabadab, 'years old') . | Use meaningful variable names to help other people understand what the program does. | The most important “other person” is your future self. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/02-variables.html#use-meaningful-variable-names",
    "relUrl": "/Python_Series_Materials/part_1/02-variables.html#use-meaningful-variable-names"
  },"72": {
    "doc": "Variables and Assignment",
    "title": "Swapping Values",
    "content": "Fill the table showing the values of the variables in this program after each statement is executed. # Command # Value of x # Value of y # Value of swap # x = 1.0 # # # # y = 3.0 # # # # swap = x # # # # x = y # # # # y = swap # # # # . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/02-variables.html#swapping-values",
    "relUrl": "/Python_Series_Materials/part_1/02-variables.html#swapping-values"
  },"73": {
    "doc": "Variables and Assignment",
    "title": "Solution",
    "content": "# Command # Value of x # Value of y # Value of swap # x = 1.0 # 1.0 # not defined # not defined # y = 3.0 # 1.0 # 3.0 # not defined # swap = x # 1.0 # 3.0 # 1.0 # x = y # 3.0 # 3.0 # 1.0 # y = swap # 3.0 # 1.0 # 1.0 # . These three lines exchange the values in x and y using the swap variable for temporary storage. This is a fairly common programming idiom. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/02-variables.html#solution",
    "relUrl": "/Python_Series_Materials/part_1/02-variables.html#solution"
  },"74": {
    "doc": "Variables and Assignment",
    "title": "Predicting Values",
    "content": "What is the final value of position in the program below? (Try to predict the value without running the program, then check your prediction.) . initial = 'left' position = initial initial = 'right' . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/02-variables.html#predicting-values",
    "relUrl": "/Python_Series_Materials/part_1/02-variables.html#predicting-values"
  },"75": {
    "doc": "Variables and Assignment",
    "title": "Solution",
    "content": "print(position) . left . The initial variable is assigned the value 'left'. In the second line, the position variable also receives the string value 'left'. In third line, the initial variable is given the value 'right', but the position variable retains its string value of 'left'. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/02-variables.html#solution-1",
    "relUrl": "/Python_Series_Materials/part_1/02-variables.html#solution-1"
  },"76": {
    "doc": "Variables and Assignment",
    "title": "Challenge",
    "content": "If you assign a = 123, what happens if you try to get the second digit of a via a[1]? . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/02-variables.html#challenge",
    "relUrl": "/Python_Series_Materials/part_1/02-variables.html#challenge"
  },"77": {
    "doc": "Variables and Assignment",
    "title": "Solution",
    "content": "Numbers are not strings or sequences and Python will raise an error if you try to perform an index operation on a number. In the next lesson on types and type conversion we will learn more about types and how to convert between different types. If you want the Nth digit of a number you can convert it into a string using the str built-in function and then perform an index operation on that string. a = 123 print(a[1]) . TypeError: 'int' object is not subscriptable . a = str(123) print(a[1]) . 2 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/02-variables.html#solution-2",
    "relUrl": "/Python_Series_Materials/part_1/02-variables.html#solution-2"
  },"78": {
    "doc": "Variables and Assignment",
    "title": "Choosing a Name",
    "content": "Which is a better variable name, m, min, or minutes? Why? Hint: think about which code you would rather inherit from someone who is leaving the lab: . | ts = m * 60 + s | tot_sec = min * 60 + sec | total_seconds = minutes * 60 + seconds | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/02-variables.html#choosing-a-name",
    "relUrl": "/Python_Series_Materials/part_1/02-variables.html#choosing-a-name"
  },"79": {
    "doc": "Variables and Assignment",
    "title": "Solution",
    "content": "minutes is better because min might mean something like “minimum” (and actually is an existing built-in function in Python that we will cover later). ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/02-variables.html#solution-3",
    "relUrl": "/Python_Series_Materials/part_1/02-variables.html#solution-3"
  },"80": {
    "doc": "Variables and Assignment",
    "title": "Slicing practice",
    "content": "What does the following program print? . atom_name = 'carbon' print('atom_name[1:3] is:', atom_name[1:3]) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/02-variables.html#slicing-practice",
    "relUrl": "/Python_Series_Materials/part_1/02-variables.html#slicing-practice"
  },"81": {
    "doc": "Variables and Assignment",
    "title": "Solution",
    "content": "atom_name[1:3] is: ar . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/02-variables.html#solution-4",
    "relUrl": "/Python_Series_Materials/part_1/02-variables.html#solution-4"
  },"82": {
    "doc": "Variables and Assignment",
    "title": "Slicing concepts",
    "content": "Given the following string: . species_name = \"Acacia buxifolia\" . What would these expressions return? . | species_name[2:8] | species_name[11:] (without a value after the colon) | species_name[:4] (without a value before the colon) | species_name[:] (just a colon) | species_name[11:-3] | species_name[-5:-3] | What happens when you choose a stop value which is out of range? (i.e., try species_name[0:20] or species_name[:103]) | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/02-variables.html#slicing-concepts",
    "relUrl": "/Python_Series_Materials/part_1/02-variables.html#slicing-concepts"
  },"83": {
    "doc": "Variables and Assignment",
    "title": "Solutions",
    "content": ". | species_name[2:8] returns the substring 'acia b' | species_name[11:] returns the substring 'folia', from position 11 until the end | species_name[:4] returns the substring 'Acac', from the start up to but not including position 4 | species_name[:] returns the entire string 'Acacia buxifolia' | species_name[11:-3] returns the substring 'fo', from the 11th position to the third last position | species_name[-5:-3] also returns the substring 'fo', from the fifth last position to the third last | If a part of the slice is out of range, the operation does not fail. species_name[0:20] gives the same result as species_name[0:], and species_name[:103] gives the same result as species_name[:] | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/02-variables.html#solutions",
    "relUrl": "/Python_Series_Materials/part_1/02-variables.html#solutions"
  },"84": {
    "doc": "Clustering",
    "title": "Create a new project from the citizen science dataset",
    "content": ". | Start a new project: Start up OpenRefine (if it isn’t running) or click on the OpenRefine logo on the top left to go to the main screen. Note: If you were working with another project, it has been automatically saved in OpenRefine and the files are stored locally on your computer. You can see your project listed here and can use Open Projects to go back to it later. | Import your dataset: Click on Create Project and import the citizenscience.csv file. Maintain the default settings, rename your project and click Create Project. You should see that there are 1991 records in our dataset. Click on show 50 rows to show more rows displayed in the window. | . ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt2_citizen_science/02_clustering.html#create-a-new-project-from-the-citizen-science-dataset",
    "relUrl": "/OpenRefine_Materials/pt2_citizen_science/02_clustering.html#create-a-new-project-from-the-citizen-science-dataset"
  },"85": {
    "doc": "Clustering",
    "title": "Use the clustering feature to make your data consistent",
    "content": ". | Create a text facet: Go to the species_guess column (where our citizen scientists have made a guess as to what species they have observed). From the species_guess column pull down menu, select Facet-&gt;Text facet. | Examine your data: You’ll see that some of them are a bit unusual, and in those cases, you may want to edit them; however, in other cases, you’ll see that there are two facets that look very similar, but just have different capitalization, such as American Pokeweed. When we have facets that look similar, we can use OpenRefine’s clustering features to help improve the consistency of the values in that column. Click on the Cluster button at the top of the facet window. | Set your clustering algorithm: At the top of the screen, you’ll see that there are different methods and keying functions you can choose from to find clusters. They roughly go from more strict/unforgiving to looser. Let’s keep the default for now. Note: In this case, you should see that the column values are just variations in capitalization, but clustering can also catch typos, plural vs singular and other small differences as well. | Cluster similar values: You can see that it has found entries that it thinks are all referring to the same thing and suggests merging them under one recommended facet. You can put a check mark next to the ones you agree with, and edit the heading that you want to merge them into–or just click on the name you want to use. Go through and merge the entries found into new terms that have only the first word capitalized by adding a check mark under Merge? and adjusting the New Cell Value. When done, click on Merge Selected &amp; Re-Cluster. You might’ve noticed that as you did a merge, it flashed at the top of the screen how many rows were affected/mass edited. | . Activity 2 . Try a different clustering algorithm and see if you can clean up the species_guess column more. Try different clustering algorithms and see if you can clean up the species_guess column more. You can ‘Select All’ and quickly scan the suggestions to merge in bulk. After cleaning up the column, can you identify what the most common bird species is in the dataset? . Bonus activity . Find all of the blank cells in the common_name column and rename them to N/A. Bonus activity . In the coordinates_obscured column, change all ‘false’ values to ‘0’ and all ‘true’ values to ‘1’. ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt2_citizen_science/02_clustering.html#use-the-clustering-feature-to-make-your-data-consistent",
    "relUrl": "/OpenRefine_Materials/pt2_citizen_science/02_clustering.html#use-the-clustering-feature-to-make-your-data-consistent"
  },"86": {
    "doc": "Clustering",
    "title": "Clustering",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt2_citizen_science/02_clustering.html",
    "relUrl": "/OpenRefine_Materials/pt2_citizen_science/02_clustering.html"
  },"87": {
    "doc": "Exploring Files and Directories",
    "title": "Exploring Files and Directories",
    "content": "What is Command Line? . Command line interface, command prompt, command screen, terminal, text interface, and shell are all instances that refer to an environment that receives commands from a user in the form of text. Using the command line interface is an alternative method for interacting with your computer than the commonly known approach, using a mouse to point and click on a computers graphical user interface (gui). Why use Command Line? . Because it makes it easier to automate tasks and often it requires fewer steps to implement! As with everything, there is a small learning curve but there are online manuals for users to reference and a help option to review details of a command. General Syntax . Let’s get started! When the shell is first opened, you are presented with a $ prompt, indicating that the shell is waiting for input. Shell typically uses $ as the prompt. Print Working Directory . At anytime to find out where you are in your command line interface, you can type pwd. pwd stands for print working directory and can be thought of as places. Commands mostly read and write files in the current working directory, i.e. ‘here’, so knowing where you are before running a command is important. I’m currently in my home directory. Your home directory might be different depending on your operating system: . For Linux users it may look like: . $ /home/lbeltran . And for Microsoft users it may look like: . $ C:\\Documents \\Settings\\lbeltran . or even this: . $ C:\\Users\\lbeltran . Understanding File Directories . Let’s take a quick tour of what a filesystem looks like: . / character represents the root directory on its own. So this is the leading slash in my /Users/lbeltran . In the image above you’ll see there are four directories below the root directory which are: bin, data, Users, and tmp . To see the directories in your root directory you can write the following command: . $ cd / . We know our current working directory /Users/lbeltran is stored within the /Users directory and that the /Users is stored inside the root directory because it begins with / . As you can see that bash depends on your files being organized in a Hierarchical system. You can put tons of files on your home directory but this is equivalent to putting a ton of papers on your desk. Lists . Let’s try our first command,ls. ls is short for list. This command will give you a list of all your contents in your current working directory. After typing in ls press enter or return and you’ll get a list of your contents. If you are not sure if a content is a directory or a file you can type ls -F and if it has a trailing / then it’s a directory. other markers @ indicates a link * indicates an executable . Getting help . You can learn more about a command by using the --help command or using the man command. Again, depending on which operating system you are using one of these may not be supported. For example --help is not supported on my MacOS, but if I type help it is and so is man. Let’s take a look. $ --help . $ help . $ man ls . Tips for navigating man pages You can navigate through the man pages in a number of ways: . 1. Move line by line ↓ and ↑ . 2. Skip up and down by full page b and Spacebar . 3. To search for a character or word / followed by the character or word . If search results in multiple hits you can mov between hits using n (to move forward) and shift+ n (to move backward) . Press q to quit the man pages . Exploring other Directories . To list and explore other directories without actually moving to that directory you can use ls command, -F option and an argument Desktop . Moving down the directory tree . We can change our location to a different directory to go down the directory tree by using the cd command - which stands for change directories - following the directory name you want to change your working directory to. You can think of cd as double clicking a folder on your desktop or file explorer to get into that folder. So for example, if we want to get to the exercise folder, on our desktop, we can go down the directory tree to get there doing the following: . An alternative method of moving down is cd - which will move you back to the previous directory you were in. Tip: if you do cd - twice it will take you back to the starting directory. Moving up the directory tree . Thecd command will let you see sub-directories inside your current working directory, but cd won’t allow you to see directories above our current location. A couple of strategies to move up one directory are: . $ cd .. $ cd ~ . ",
    "url": "http://localhost:4000/portfolio_workshop/cli/02_files_direc.html",
    "relUrl": "/cli/02_files_direc.html"
  },"88": {
    "doc": "Importing data",
    "title": "Review the dataset and load it into OpenRefine",
    "content": ". | Open the file expenditures_by_state.xlsx in Excel and take a look at it. This is a freely available dataset from the Bureau of Economic Analysis, which provides average expenditures on a wide range of goods and services. Notice the following: . | The data file has been formatted for reading rather than analysis. It has a blank column A. It has some rows at the top containing descriptive information that is not part of the data table. We can also see that each state is only listed once, which is fine for viewing, but will mess things up if we try to sort the data in order to analyze it. | The “Expenditure” column has leading spaces in it. | . | Close the Excel file. Next, start up OpenRefine. | Ensure that Create Project is selected. Click on Choose Files. Browse to the file expenditures_by_state.xlsx. Click Open. Then, click the Next button. | You are now viewing the dataset in Preview view. Here you can see what data will look like when loaded, and make some changes to the dataset. Notice the following: . | The descriptive text at the top of the Excel worksheet is showing in the preview, and is messing up OpenRefine’s ability to identify the column headings. We can instruct OpenRefine to ignore these rows that aren’t part of the data table. Select the check box beside Ignore first, and type 6 in the box to ignore the first 6 lines at the beginning of the file. | Numbers are displayed in green–this means OpenRefine has recognized these columns as containing numeric data | . | In the Project name box, give the project a name of your choice. Click Create Project. | Your data has now been loaded into OpenRefine. Note that it has stored a copy of this data with the OpenRefine installation files on your computer. When you make edits using OpenRefine, you are not editing the original data file you uploaded, all edits are made to the copy OpenRefine has created. | . ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt1_expenditure/02_import.html#review-the-dataset-and-load-it-into-openrefine",
    "relUrl": "/OpenRefine_Materials/pt1_expenditure/02_import.html#review-the-dataset-and-load-it-into-openrefine"
  },"89": {
    "doc": "Importing data",
    "title": "Importing data",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt1_expenditure/02_import.html",
    "relUrl": "/OpenRefine_Materials/pt1_expenditure/02_import.html"
  },"90": {
    "doc": "Creating a Repository",
    "title": "Creating a Repository",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/03-create.html",
    "relUrl": "/Git_Materials/03-create.html"
  },"91": {
    "doc": "Creating a Repository",
    "title": "Objectives",
    "content": ". | Create a local Git repository. | Describe the purpose of the .git directory. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/03-create.html#objectives",
    "relUrl": "/Git_Materials/03-create.html#objectives"
  },"92": {
    "doc": "Creating a Repository",
    "title": "Questions",
    "content": ". | Where does Git store information? | . Once Git is configured, we can start using it. We will continue with the story of Wolfman and Dracula who are investigating if it is possible to send a planetary lander to Mars. Werewolf vs dracula by b-maze / Deviant Art. Mars by European Space Agency / CC-BY-SA 3.0 IGO. Pluto / Courtesy NASA/JPL-Caltech. Mummy © Gilad Fried / The Noun Project / CC BY 3.0. Moon © Luc Viatour / https://lucnix.be / CC BY-SA 3.0. First, let’s create a new directory in the Desktop folder for our work and then change the current working directory to the newly created one: . $ cd ~/Desktop $ mkdir planets $ cd planets . Then we tell Git to make planets a repository -- a place where Git can store versions of our files: . $ git init . It is important to note that git init will create a repository that can include subdirectories and their files—there is no need to create separate repositories nested within the planets repository, whether subdirectories are present from the beginning or added later. Also, note that the creation of the planets directory and its initialization as a repository are completely separate processes. If we use ls to show the directory’s contents, it appears that nothing has changed: . $ ls . But if we add the -a flag to show everything, we can see that Git has created a hidden directory within planets called .git: . $ ls -a ..git . Git uses this special subdirectory to store all the information about the project, including the tracked files and sub-directories located within the project’s directory. If we ever delete the .git subdirectory, we will lose the project’s history. Next, we will change the default branch to be called main. This might be the default branch depending on your settings and version of git. See the setup episode for more information on this change. $ git checkout -b main . Switched to a new branch 'main' . We can check that everything is set up correctly by asking Git to tell us the status of our project: . $ git status . On branch main No commits yet nothing to commit (create/copy files and use \"git add\" to track) . If you are using a different version of git, the exact wording of the output might be slightly different. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/03-create.html#questions",
    "relUrl": "/Git_Materials/03-create.html#questions"
  },"93": {
    "doc": "Creating a Repository",
    "title": "Places to Create Git Repositories",
    "content": "Along with tracking information about planets (the project we have already created), Dracula would also like to track information about moons. Despite Wolfman’s concerns, Dracula creates a moons project inside his planets project with the following sequence of commands: . $ cd ~/Desktop # return to Desktop directory $ cd planets # go into planets directory, which is already a Git repository $ ls -a # ensure the .git subdirectory is still present in the planets directory $ mkdir moons # make a subdirectory planets/moons $ cd moons # go into moons subdirectory $ git init # make the moons subdirectory a Git repository $ ls -a # ensure the .git subdirectory is present indicating we have created a new Git repository . Is the git init command, run inside the moons subdirectory, required for tracking files stored in the moons subdirectory? . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/03-create.html#places-to-create-git-repositories",
    "relUrl": "/Git_Materials/03-create.html#places-to-create-git-repositories"
  },"94": {
    "doc": "Creating a Repository",
    "title": "Solution",
    "content": "No. Dracula does not need to make the moons subdirectory a Git repository because the planets repository can track any files, sub-directories, and subdirectory files under the planets directory. Thus, in order to track all information about moons, Dracula only needed to add the moons subdirectory to the planets directory. Additionally, Git repositories can interfere with each other if they are “nested”: the outer repository will try to version-control the inner repository. Therefore, it’s best to create each new Git repository in a separate directory. To be sure that there is no conflicting repository in the directory, check the output of git status. If it looks like the following, you are good to go to create a new repository as shown above: . $ git status . fatal: Not a git repository (or any of the parent directories): .git . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/03-create.html#solution",
    "relUrl": "/Git_Materials/03-create.html#solution"
  },"95": {
    "doc": "Creating a Repository",
    "title": "Correcting git init Mistakes",
    "content": "Wolfman explains to Dracula how a nested repository is redundant and may cause confusion down the road. Dracula would like to remove the nested repository. How can Dracula undo his last git init in the moons subdirectory? . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/03-create.html#correcting-git-init-mistakes",
    "relUrl": "/Git_Materials/03-create.html#correcting-git-init-mistakes"
  },"96": {
    "doc": "Creating a Repository",
    "title": "Solution – USE WITH CAUTION!",
    "content": "Background . Removing files from a Git repository needs to be done with caution. But we have not learned yet how to tell Git to track a particular file; we will learn this in the next episode. Files that are not tracked by Git can easily be removed like any other “ordinary” files with . $ rm filename . Similarly a directory can be removed using rm -r dirname or rm -rf dirname. If the files or folder being removed in this fashion are tracked by Git, then their removal becomes another change that we will need to track, as we will see in the next episode. Solution . Git keeps all of its files in the .git directory. To recover from this little mistake, Dracula can just remove the .git folder in the moons subdirectory by running the following command from inside the planets directory: . $ rm -rf moons/.git . But be careful! Running this command in the wrong directory will remove the entire Git history of a project you might want to keep. Therefore, always check your current directory using the command pwd. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/03-create.html#solution--use-with-caution",
    "relUrl": "/Git_Materials/03-create.html#solution--use-with-caution"
  },"97": {
    "doc": "Creating a Repository",
    "title": "Keypoints",
    "content": ". | git init initializes a repository. | Git stores all of its repository data in the .git directory. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/03-create.html#keypoints",
    "relUrl": "/Git_Materials/03-create.html#keypoints"
  },"98": {
    "doc": "Pipes & Filters",
    "title": "Pipes &amp; Filters",
    "content": "Combining commands . Word Count . wc is the ‘word count’ command: it counts the number of lines, words, and characters in files (returning the values in that order from left to right). If we run the command wc *.pdb, the * in *.pdb matches zero or more characters, so the shell turns *.pdb into a list of all .pdb files in the current directory: . The above command *.pdb will show the total number of all lines in the last line of the output. To show only the number of lines per file you can type: . $ wc -l *.pdb . Other commands using wc . To show only the number of characters: . $ wc -l *.pdb . To show only the number of words . $ wc -w *.pdb . Filtering outputs . Sort . The sort function will print the output of a file in a specific order, which is helpful when reading the data. By default the sort command sorts files assuming the contents are in ASCII, but there are many options, like -n that can be used with the command to sort the data in a particular way. A few options include: . -n uses the numerical value to sort . $ sort -n . -r reverses the sorting order . $ sort -r . -b ignores blanks at the start of the line . $ sort -b . Capturing outputs . Redirects . If you want to see which of your files contains the fewest lines you can run the command &gt;. This tells the shell to redirect the command’s output to a file instead of printing it to the screen. Let’s try it out by typing the following command: . $ wc -l *.pdb &gt; lengths.txt . In the command we used the &gt; to redirect the content that the wc command would have printed to a new file named lengths.txt. To check the file exists type ls lengths.txt command. Note: . When using the redirect command, if the file doesn’t already exist, then shell will create the file and put the content into the new file. However, if a file does exists, then it will be overwritten, which could lead to data loss. It’s not a good idea to redirect the output of a command that operates on a file to the same file as it could lead to incorrect results and/or delete the contents in the file. For example, best practice is to avoid doing something like the following: . $ sort -n lengths.txt &gt; lengths.txt . Joining and Printing outputs . Use cat, short for concatenate, to join and print the contents of files one after another. For example: . $ cat lengths.txt . Passing output using pipes You can use a vertical bar |, called a pipe between two commands to tell shell you want to use the output of the command on the left as the input to the command on the right. This looks like: . Combining multiple commands We can also use the pipe command to consecutively chain pipes, which makes the need for intermediate files unnecessary. In the following example, we are asking shell to send the output of wc word count directly to sort, and then send the resulting output to head. Let’s break it down. Tip: you can think of it like nesting functions in mathematics! . ",
    "url": "http://localhost:4000/portfolio_workshop/cli/03-pipes-filters.html#pipes--filters",
    "relUrl": "/cli/03-pipes-filters.html#pipes--filters"
  },"99": {
    "doc": "Pipes & Filters",
    "title": "Pipes & Filters",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/cli/03-pipes-filters.html",
    "relUrl": "/cli/03-pipes-filters.html"
  },"100": {
    "doc": "Enhancing Your Vault with Plugins",
    "title": "Enhancing Your Obsidian Vault with Plugins",
    "content": "The next piece that makes Obsidian super powerful and customizable is the vasy selection of plugins! There are two types of plugins: core and community. Core Plugins . These are plugins that come pre-installed with Obsidian. With newer versions, it’s likely that this list of plugins will continue to grow. Many are already enabled in your vault. You can view what you have and control their settings by opening the Settings window and selecting the Core plugins tab. Take a moment to explore these plugins! See how to use them and find out what happens when they become enabled. Community Plugins . Obsidian is community-driven. With this platform, you aren’t subjected to the basic tools that come with your initial install. Tons of other Obsidian users are creating their own plugins that you can easily install (you could even create your own plugin!). To get started, open the Settings window and selecting the Community plugins tab. First, you will have to turn on Community Plugins by exisitng Restricted Mode in Obsidian. With all public products we access from the internet, there is a risk to our the security and privacy of our data and usage. Obsidian makes it’s best effort to review and monitor the integrity of all community plugins. This is assuring to know as you browse plugins, but always use your best judgement before installing a plugin and make sure that the documentation is detailed and transparent about what the plugin does. Once you turn on Community Plugins, you will see the following options under this tab. Notice that you can turn Restricted mode on at any time. You can start browsing community plugins by selecting Browse. This list will likely be overwhelming! Don’t think that you need to install a ton of plugins right away. It’s best to work with Obisidian with limited modifications and when you reach a point where you’re telling yourself, “I wish I had a better way to do this,” then it’s time to look for a plugin! It’s very likely that someone encountered the same problem and wrote their own plugin. But rest assured, here’s a short list of some helpful plugins that may help you get started: . Advanced Tables . Writing tables in Markdown can be somewhat tedious, especially if you wish to create a large table. This plugin makes it much easier to create a table and offers many tools and functionalities found in Microsoft Excel. These include: . | Navigating between rows and columns with tab/enter | Aligning text in cells | Sorting rows based off of a column | Entering formulas | . Calendar . Obsidian has a tool on the left panel that lets you Open today’s daily note. This automatically creates a note titled with the today’s date (YYYY-MM-DD). Once the note is created, you can select the tool again to open today’s daily note at any time. The Calendar plugin helps you manage your daily notes further. This plugin provides a calendar that you can display on a side bar in your Obisidian window. This offers you a visual to see where you have created daily notes, and you can select any date to access or create the daily note for that day (you can even create notes for future dates). This calendar will also help show you how much you wrote each day. The number of “dots” that appear under a date will tell you how many words you wrote in your daily note. Dictionary . This plugin offers you a dictionary immediately at your disposal. Use this tool to open on your side bar a dictionary entry for a word with pronunciation. This tools offers several dictionaries and multiple languages. Additionally, you can enable a feature that lets you receive suggestions for synonyms of highlighted words. Pandoc . This plugin lets you export your Markdown notes in Obisidan to a variety of formats. Some of these formats include: PDF, HTML, LaTeX, Word Document, and even Jupyter Notebook. To export a note, open the command pallete with Ctrl+p/Cmd+p and type “pandoc.” From there, you can choose your export format, and the export file will be in your vault! . Create a note: . Call Pandoc: . Find the exported file in your vault: . ",
    "url": "http://localhost:4000/portfolio_workshop/Obsidian_Materials/03-plugins.html#enhancing-your-obsidian-vault-with-plugins",
    "relUrl": "/Obsidian_Materials/03-plugins.html#enhancing-your-obsidian-vault-with-plugins"
  },"101": {
    "doc": "Enhancing Your Vault with Plugins",
    "title": "Enhancing Your Vault with Plugins",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Obsidian_Materials/03-plugins.html",
    "relUrl": "/Obsidian_Materials/03-plugins.html"
  },"102": {
    "doc": "Data Types and Type Conversion",
    "title": "Data Types and Type Conversion",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/03-types-conversion.html",
    "relUrl": "/Python_Series_Materials/part_1/03-types-conversion.html"
  },"103": {
    "doc": "Data Types and Type Conversion",
    "title": "Every value has a type.",
    "content": ". | Every value in a program has a specific type. | Integer (int): represents positive or negative whole numbers like 3 or -512. | Floating point number (float): represents real numbers like 3.14159 or -2.5. | Character string (usually called “string”, str): text. | Written in either single quotes or double quotes (as long as they match). | The quote marks aren’t printed when the string is displayed. | . | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/03-types-conversion.html#every-value-has-a-type",
    "relUrl": "/Python_Series_Materials/part_1/03-types-conversion.html#every-value-has-a-type"
  },"104": {
    "doc": "Data Types and Type Conversion",
    "title": "Use the built-in function type to find the type of a value.",
    "content": ". | Use the built-in function type to find out what type a value has. | Works on variables as well. | But remember: the value has the type — the variable is just a label. | . | . print(type(52)) . &lt;class 'int'&gt; . fitness = 'average' print(type(fitness)) . &lt;class 'str'&gt; . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/03-types-conversion.html#use-the-built-in-function-type-to-find-the-type-of-a-value",
    "relUrl": "/Python_Series_Materials/part_1/03-types-conversion.html#use-the-built-in-function-type-to-find-the-type-of-a-value"
  },"105": {
    "doc": "Data Types and Type Conversion",
    "title": "Types control what operations (or methods) can be performed on a given value.",
    "content": ". | A value’s type determines what the program can do to it. | . print(5 - 3) . 2 . print('hello' - 'h') . --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-2-67f5626a1e07&gt; in &lt;module&gt;() ----&gt; 1 print('hello' - 'h') TypeError: unsupported operand type(s) for -: 'str' and 'str' . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/03-types-conversion.html#types-control-what-operations-or-methods-can-be-performed-on-a-given-value",
    "relUrl": "/Python_Series_Materials/part_1/03-types-conversion.html#types-control-what-operations-or-methods-can-be-performed-on-a-given-value"
  },"106": {
    "doc": "Data Types and Type Conversion",
    "title": "You can use the “+” and “*” operators on strings.",
    "content": ". | “Adding” character strings concatenates them. | . full_name = 'Ahmed' + ' ' + 'Walsh' print(full_name) . Ahmed Walsh . | Multiplying a character string by an integer N creates a new string that consists of that character string repeated N times. | Since multiplication is repeated addition. | . | . separator = '=' * 10 print(separator) . ========== . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/03-types-conversion.html#you-can-use-the--and--operators-on-strings",
    "relUrl": "/Python_Series_Materials/part_1/03-types-conversion.html#you-can-use-the--and--operators-on-strings"
  },"107": {
    "doc": "Data Types and Type Conversion",
    "title": "Strings have a length (but numbers don’t).",
    "content": ". | The built-in function len counts the number of characters in a string. | . print(len(full_name)) . 11 . | But numbers don’t have a length (not even zero). | . print(len(52)) . --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-3-f769e8e8097d&gt; in &lt;module&gt;() ----&gt; 1 print(len(52)) TypeError: object of type 'int' has no len() . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/03-types-conversion.html#strings-have-a-length-but-numbers-dont",
    "relUrl": "/Python_Series_Materials/part_1/03-types-conversion.html#strings-have-a-length-but-numbers-dont"
  },"108": {
    "doc": "Data Types and Type Conversion",
    "title": " Must convert numbers to strings or vice versa when operating on them.",
    "content": ". | Cannot add numbers and strings. | . print(1 + '2') . --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-4-fe4f54a023c6&gt; in &lt;module&gt;() ----&gt; 1 print(1 + '2') TypeError: unsupported operand type(s) for +: 'int' and 'str' . | Not allowed because it’s ambiguous: should 1 + '2' be 3 or '12'? | Some types can be converted to other types by using the type name as a function. | . print(1 + int('2')) print(str(1) + '2') . 3 12 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/03-types-conversion.html#-must-convert-numbers-to-strings-or-vice-versa-when-operating-on-them",
    "relUrl": "/Python_Series_Materials/part_1/03-types-conversion.html#-must-convert-numbers-to-strings-or-vice-versa-when-operating-on-them"
  },"109": {
    "doc": "Data Types and Type Conversion",
    "title": "Can mix integers and floats freely in operations.",
    "content": ". | Integers and floating-point numbers can be mixed in arithmetic. | Python 3 automatically converts integers to floats as needed. | . | . print('half is', 1 / 2.0) print('three squared is', 3.0 ** 2) . half is 0.5 three squared is 9.0 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/03-types-conversion.html#can-mix-integers-and-floats-freely-in-operations",
    "relUrl": "/Python_Series_Materials/part_1/03-types-conversion.html#can-mix-integers-and-floats-freely-in-operations"
  },"110": {
    "doc": "Data Types and Type Conversion",
    "title": "Variables only change value when something is assigned to them.",
    "content": ". | If we make one cell in a spreadsheet depend on another, and update the latter, the former updates automatically. | This does not happen in programming languages. | . variable_one = 1 variable_two = 5 * variable_one variable_one = 2 print('first is', variable_one, 'and second is', variable_two) . first is 2 and second is 5 . | The computer reads the value of first when doing the multiplication, creates a new value, and assigns it to second. | After that, second does not remember where it came from. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/03-types-conversion.html#variables-only-change-value-when-something-is-assigned-to-them",
    "relUrl": "/Python_Series_Materials/part_1/03-types-conversion.html#variables-only-change-value-when-something-is-assigned-to-them"
  },"111": {
    "doc": "Data Types and Type Conversion",
    "title": "Fractions",
    "content": "What type of value is 3.4? How can you find out? . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/03-types-conversion.html#fractions",
    "relUrl": "/Python_Series_Materials/part_1/03-types-conversion.html#fractions"
  },"112": {
    "doc": "Data Types and Type Conversion",
    "title": "Solution",
    "content": "It is a floating-point number (often abbreviated “float”). It is possible to find out by using the built-in function type(). print(type(3.4)) . &lt;class 'float'&gt; . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/03-types-conversion.html#solution",
    "relUrl": "/Python_Series_Materials/part_1/03-types-conversion.html#solution"
  },"113": {
    "doc": "Data Types and Type Conversion",
    "title": "Automatic Type Conversion",
    "content": "What type of value is 3.25 + 4? . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/03-types-conversion.html#automatic-type-conversion",
    "relUrl": "/Python_Series_Materials/part_1/03-types-conversion.html#automatic-type-conversion"
  },"114": {
    "doc": "Data Types and Type Conversion",
    "title": "Solution",
    "content": "It is a float: integers are automatically converted to floats as necessary. result = 3.25 + 4 print(result, 'is', type(result)) . 7.25 is &lt;class 'float'&gt; . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/03-types-conversion.html#solution-1",
    "relUrl": "/Python_Series_Materials/part_1/03-types-conversion.html#solution-1"
  },"115": {
    "doc": "Data Types and Type Conversion",
    "title": "Choose a Type",
    "content": "What type of value (integer, floating point number, or character string) would you use to represent each of the following? Try to come up with more than one good answer for each problem. For example, in # 1, when would counting days with a floating point variable make more sense than using an integer? . | Number of days since the start of the year. | Time elapsed from the start of the year until now in days. | Serial number of a piece of lab equipment. | A lab specimen’s age | Current population of a city. | Average population of a city over time. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/03-types-conversion.html#choose-a-type",
    "relUrl": "/Python_Series_Materials/part_1/03-types-conversion.html#choose-a-type"
  },"116": {
    "doc": "Data Types and Type Conversion",
    "title": "Solution",
    "content": "The answers to the questions are: . | Integer, since the number of days would lie between 1 and 365. | Floating point, since fractional days are required | Character string if serial number contains letters and numbers, otherwise integer if the serial number consists only of numerals | This will vary! How do you define a specimen’s age? whole days since collection (integer)? date and time (string)? | Choose floating point to represent population as large aggregates (eg millions), or integer to represent population in units of individuals. | Floating point number, since an average is likely to have a fractional part. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/03-types-conversion.html#solution-2",
    "relUrl": "/Python_Series_Materials/part_1/03-types-conversion.html#solution-2"
  },"117": {
    "doc": "Data Types and Type Conversion",
    "title": "Division Types",
    "content": "In Python 3, the // operator performs integer (whole-number) floor division, the / operator performs floating-point division, and the % (or modulo) operator calculates and returns the remainder from integer division: . print('5 // 3:', 5 // 3) print('5 / 3:', 5 / 3) print('5 % 3:', 5 % 3) . 5 // 3: 1 5 / 3: 1.6666666666666667 5 % 3: 2 . If num_subjects is the number of subjects taking part in a study, and num_per_survey is the number that can take part in a single survey, write an expression that calculates the number of surveys needed to reach everyone once. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/03-types-conversion.html#division-types",
    "relUrl": "/Python_Series_Materials/part_1/03-types-conversion.html#division-types"
  },"118": {
    "doc": "Data Types and Type Conversion",
    "title": "Solution",
    "content": "We want the minimum number of surveys that reaches everyone once, which is the rounded up value of num_subjects/ num_per_survey. This is equivalent to performing a floor division with // and adding 1. Before the division we need to subtract 1 from the number of subjects to deal with the case where num_subjects is evenly divisible by num_per_survey. num_subjects = 600 num_per_survey = 42 num_surveys = (num_subjects - 1) // num_per_survey + 1 print(num_subjects, 'subjects,', num_per_survey, 'per survey:', num_surveys) . 600 subjects, 42 per survey: 15 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/03-types-conversion.html#solution-3",
    "relUrl": "/Python_Series_Materials/part_1/03-types-conversion.html#solution-3"
  },"119": {
    "doc": "Data Types and Type Conversion",
    "title": "Strings to Numbers",
    "content": "Where reasonable, float() will convert a string to a floating point number, and int() will convert a floating point number to an integer: . print(\"string to float:\", float(\"3.4\")) print(\"float to int:\", int(3.4)) . string to float: 3.4 float to int: 3 . If the conversion doesn’t make sense, however, an error message will occur. print(\"string to float:\", float(\"Hello world!\")) . --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-5-df3b790bf0a2&gt; in &lt;module&gt; ----&gt; 1 print(\"string to float:\", float(\"Hello world!\")) ValueError: could not convert string to float: 'Hello world!' . Given this information, what do you expect the following program to do? . What does it actually do? . Why do you think it does that? . print(\"fractional string to int:\", int(\"3.4\")) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/03-types-conversion.html#strings-to-numbers",
    "relUrl": "/Python_Series_Materials/part_1/03-types-conversion.html#strings-to-numbers"
  },"120": {
    "doc": "Data Types and Type Conversion",
    "title": "Solution",
    "content": "What do you expect this program to do? It would not be so unreasonable to expect the Python 3 int command to convert the string “3.4” to 3.4 and an additional type conversion to 3. After all, Python 3 performs a lot of other magic - isn’t that part of its charm? . int(\"3.4\") . --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-2-ec6729dfccdc&gt; in &lt;module&gt; ----&gt; 1 int(\"3.4\") ValueError: invalid literal for int() with base 10: '3.4' . However, Python 3 throws an error. Why? To be consistent, possibly. If you ask Python to perform two consecutive typecasts, you must convert it explicitly in code. int(float(\"3.4\")) . 3 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/03-types-conversion.html#solution-4",
    "relUrl": "/Python_Series_Materials/part_1/03-types-conversion.html#solution-4"
  },"121": {
    "doc": "Data Types and Type Conversion",
    "title": "Arithmetic with Different Types",
    "content": "Which of the following will return the floating point number 2.0? Note: there may be more than one right answer. first = 1.0 second = \"1\" third = \"1.1\" . | first + float(second) | float(second) + float(third) | first + int(third) | first + int(float(third)) | int(first) + int(float(third)) | 2.0 * second | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/03-types-conversion.html#arithmetic-with-different-types",
    "relUrl": "/Python_Series_Materials/part_1/03-types-conversion.html#arithmetic-with-different-types"
  },"122": {
    "doc": "Data Types and Type Conversion",
    "title": "Solution",
    "content": "Answer: 1 and 4 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/03-types-conversion.html#solution-5",
    "relUrl": "/Python_Series_Materials/part_1/03-types-conversion.html#solution-5"
  },"123": {
    "doc": "Data Types and Type Conversion",
    "title": "Complex Numbers",
    "content": "Python provides complex numbers, which are written as 1.0+2.0j. If val is a complex number, its real and imaginary parts can be accessed using dot notation as val.real and val.imag. a_complex_number = 6 + 2j print(a_complex_number.real) print(a_complex_number.imag) . 6.0 2.0 . | Why do you think Python uses j instead of i for the imaginary part? | What do you expect 1 + 2j + 3 to produce? | What do you expect 4j to be? What about 4 j or 4 + j? | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/03-types-conversion.html#complex-numbers",
    "relUrl": "/Python_Series_Materials/part_1/03-types-conversion.html#complex-numbers"
  },"124": {
    "doc": "Data Types and Type Conversion",
    "title": "Solution",
    "content": ". | Standard mathematics treatments typically use i to denote an imaginary number. However, from media reports it was an early convention established from electrical engineering that now presents a technically expensive area to change. Stack Overflow provides additional explanation and discussion. | (4+2j) | 4j and Syntax Error: invalid syntax. In the latter cases, j is considered a variable and the statement depends on if j is defined and if so, its assigned value. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/03-types-conversion.html#solution-6",
    "relUrl": "/Python_Series_Materials/part_1/03-types-conversion.html#solution-6"
  },"125": {
    "doc": "Basic data cleanup",
    "title": "Perform some basic data cleanup",
    "content": ". | In the top toolbar, select 50 in order to show more rows on the screen at once. | Remove the blank columns:. Look for the pull down menu for the column named “Column”. From the pull down menu, select Edit Column -&gt; Remove this Column. | Change a column name: Click on the pull down menu for the column name “GeoName”. Under Edit Column, choose Rename this Column. Rename the column to “State” and click OK. | Fill down data: We want to fill the entries down in the State column so that all rows have a state associated with them. From the State column pull down menu, select Edit Cells -&gt; Fill Down. In the top toolbar, click next a few times in order to look at a few pages of results. Verify that the fill operation seems to have worked. | Delete leading whitespace: Hover your cursor over a cell in the Expenditure column and click edit. You’ll see that there are leading whitespaces that could cause problems down the road. Click ‘Cancel’ to close the Edit window. From the Expenditure column pull down menu, select Edit cells -&gt; Common transforms -&gt; Trim leading and trailing white space. Check a cell to verify that the leading spaces are gone. | . ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt1_expenditure/03_basic_clean.html#perform-some-basic-data-cleanup",
    "relUrl": "/OpenRefine_Materials/pt1_expenditure/03_basic_clean.html#perform-some-basic-data-cleanup"
  },"126": {
    "doc": "Basic data cleanup",
    "title": "Basic data cleanup",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt1_expenditure/03_basic_clean.html",
    "relUrl": "/OpenRefine_Materials/pt1_expenditure/03_basic_clean.html"
  },"127": {
    "doc": "Splitting and concatenating",
    "title": "Split columns in the dataset",
    "content": ". | Split the scienctific name colunm into two: We have a column called scientific_name. With scientific names, the first part is the genus name and the second part is the specific name. So let’s split this column so we can see how many of a particular genus were identified. From the scientific_name column pull down menu, select Edit column–&gt;Split into several columns. For the separator, put a space, split into 2 columns at most, and uncheck Remove this column because we want to keep it. Then click on OK. | Edit column names: From each new column’s pull down menu, select Edit column–&gt;Rename this column. For the first one, call it genus. For the second one, call it specific. You could use text facets on the genus column to see how many of each genus were identified. From the genus column pull down menu, select Facet–&gt;Text facet In the facet window, click on Sort by count to sort the facets and see which genus comes out on top. | . ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt2_citizen_science/03_split-concatenate.html#split-columns-in-the-dataset",
    "relUrl": "/OpenRefine_Materials/pt2_citizen_science/03_split-concatenate.html#split-columns-in-the-dataset"
  },"128": {
    "doc": "Splitting and concatenating",
    "title": "Concatenate columns in the dataset",
    "content": ". | Add a new column based on an existing column: You can concatenate (join) strings and/or values from two or more columns together. Let’s say that we wanted to combine the information on the user id and login into one column with the format username (user id). For this example, we’re going to create a new column to store this information using the Add column based on this column feature. From the user_id column pull down menu, select Edit column–&gt;Add column based on this column. Give the new column the name User. | Use GREL to define a format: OpenRefine’s scripting language is called GREL (Google Refine Expression Language). We can use it to define combinations of characters, strings, and numbers. In our expression to define a new column, value refers to the value of the current column. If we want to refer to another column in our expression we use the term cells. and then the name of a column then .value So for the expression in this case, type cells.user_login.value + “ (“ + value + “)” The plus sign is used to join the different values or strings together into one long string. So we’re creating a string that is the user login, a space, and then the user id in parentheses. | You’ll notice that when you type in the expression, the preview at the bottom changes to show you what the resulting value will be. This preview is extremely helpful when writing GREL expressions! For more help with regular expressions, see http://www.rexegg.com/regex-quickstart.html and https://regex101.com/. | . | . Actvity 3 . Concatenate the scientific_name column with the common_name in parentheses into a new column called Descriptive Name. The format should be &lt;scientific_name&gt; (&lt;common_name&gt;). ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt2_citizen_science/03_split-concatenate.html#concatenate-columns-in-the-dataset",
    "relUrl": "/OpenRefine_Materials/pt2_citizen_science/03_split-concatenate.html#concatenate-columns-in-the-dataset"
  },"129": {
    "doc": "Splitting and concatenating",
    "title": "Splitting and concatenating",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt2_citizen_science/03_split-concatenate.html",
    "relUrl": "/OpenRefine_Materials/pt2_citizen_science/03_split-concatenate.html"
  },"130": {
    "doc": "Built-in Functions and Help",
    "title": "Built-in Functions and Help",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/04-built-in.html",
    "relUrl": "/Python_Series_Materials/part_1/04-built-in.html"
  },"131": {
    "doc": "Built-in Functions and Help",
    "title": "Use comments to add documentation to programs.",
    "content": "# This sentence isn't executed by Python. adjustment = 0.5 # Neither is this - anything after '#' is ignored. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/04-built-in.html#use-comments-to-add-documentation-to-programs",
    "relUrl": "/Python_Series_Materials/part_1/04-built-in.html#use-comments-to-add-documentation-to-programs"
  },"132": {
    "doc": "Built-in Functions and Help",
    "title": "A function may take zero or more arguments.",
    "content": ". | We have seen some functions already — now let’s take a closer look. | An argument is a value passed into a function. | len takes exactly one. | int, str, and float create a new value from an existing one. | print takes zero or more. | print with no arguments prints a blank line. | Must always use parentheses, even if they’re empty, so that Python knows a function is being called. | . | . print('before') print() print('after') . before after . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/04-built-in.html#a-function-may-take-zero-or-more-arguments",
    "relUrl": "/Python_Series_Materials/part_1/04-built-in.html#a-function-may-take-zero-or-more-arguments"
  },"133": {
    "doc": "Built-in Functions and Help",
    "title": "Every function returns something.",
    "content": ". | Every function call produces some result. | If the function doesn’t have a useful result to return, it usually returns the special value None. None is a Python object that stands in anytime there is no value. | . result = print('example') print('result of print is', result) . example result of print is None . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/04-built-in.html#every-function-returns-something",
    "relUrl": "/Python_Series_Materials/part_1/04-built-in.html#every-function-returns-something"
  },"134": {
    "doc": "Built-in Functions and Help",
    "title": "Commonly-used built-in functions include max, min, and round.",
    "content": ". | Use max to find the largest value of one or more values. | Use min to find the smallest. | Both work on character strings as well as numbers. | “Larger” and “smaller” use (0-9, A-Z, a-z) to compare letters. | . | . print(max(1, 2, 3)) print(min('a', 'A', '0')) . 3 0 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/04-built-in.html#commonly-used-built-in-functions-include-max-min-and-round",
    "relUrl": "/Python_Series_Materials/part_1/04-built-in.html#commonly-used-built-in-functions-include-max-min-and-round"
  },"135": {
    "doc": "Built-in Functions and Help",
    "title": "Functions may only work for certain (combinations of) arguments.",
    "content": ". | max and min must be given at least one argument. | “Largest of the empty set” is a meaningless question. | . | And they must be given things that can meaningfully be compared. | . print(max(1, 'a')) . TypeError Traceback (most recent call last) &lt;ipython-input-52-3f049acf3762&gt; in &lt;module&gt; ----&gt; 1 print(max(1, 'a')) TypeError: '&gt;' not supported between instances of 'str' and 'int' . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/04-built-in.html#functions-may-only-work-for-certain-combinations-of-arguments",
    "relUrl": "/Python_Series_Materials/part_1/04-built-in.html#functions-may-only-work-for-certain-combinations-of-arguments"
  },"136": {
    "doc": "Built-in Functions and Help",
    "title": "Functions may have default values for some arguments.",
    "content": ". | round will round off a floating-point number. | By default, rounds to zero decimal places. | . round(3.712) . 4 . | We can specify the number of decimal places we want. | . round(3.712, 1) . 3.7 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/04-built-in.html#functions-may-have-default-values-for-some-arguments",
    "relUrl": "/Python_Series_Materials/part_1/04-built-in.html#functions-may-have-default-values-for-some-arguments"
  },"137": {
    "doc": "Built-in Functions and Help",
    "title": "Functions attached to objects are called methods",
    "content": ". | Functions take another form that will be common in the pandas episodes. | Methods have parentheses like functions, but come after the variable. | Some methods are used for internal Python operations, and are marked with double underlines. | . my_string = 'Hello world!' # creation of a string object print(len(my_string)) # the len function takes a string as an argument and returns the length of the string print(my_string.swapcase()) # calling the swapcase method on the my_string object print(my_string.__len__()) # calling the internal __len__ method on the my_string object, used by len(my_string) . 12 hELLO WORLD! 12 . | You might even see them chained together. They operate left to right. | . print(my_string.isupper()) # Not all the letters are uppercase print(my_string.upper()) # This capitalizes all the letters print(my_string.upper().isupper()) # Now all the letters are uppercase . False HELLO WORLD True . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/04-built-in.html#functions-attached-to-objects-are-called-methods",
    "relUrl": "/Python_Series_Materials/part_1/04-built-in.html#functions-attached-to-objects-are-called-methods"
  },"138": {
    "doc": "Built-in Functions and Help",
    "title": "Use the built-in function help to get help for a function.",
    "content": ". | Every built-in function has online documentation. | . help(round) . Help on built-in function round in module builtins: round(number, ndigits=None) Round a number to a given precision in decimal digits. The return value is an integer if ndigits is omitted or None. Otherwise the return value has the same type as the number. ndigits may be negative. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/04-built-in.html#use-the-built-in-function-help-to-get-help-for-a-function",
    "relUrl": "/Python_Series_Materials/part_1/04-built-in.html#use-the-built-in-function-help-to-get-help-for-a-function"
  },"139": {
    "doc": "Built-in Functions and Help",
    "title": "The Jupyter Notebook has two ways to get help.",
    "content": ". | Option 1: Place the cursor near where the function is invoked in a cell (i.e., the function name or its parameters), . | Hold down Shift, and press Tab. | Do this several times to expand the information returned. | . | Option 2: Type the function name in a cell with a question mark after it. Then run the cell. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/04-built-in.html#the-jupyter-notebook-has-two-ways-to-get-help",
    "relUrl": "/Python_Series_Materials/part_1/04-built-in.html#the-jupyter-notebook-has-two-ways-to-get-help"
  },"140": {
    "doc": "Built-in Functions and Help",
    "title": "Python reports a syntax error when it can’t understand the source of a program.",
    "content": ". | Won’t even try to run the program if it can’t be parsed. | . # Forgot to close the quote marks around the string. name = 'Feng . File \"&lt;ipython-input-56-f42768451d55&gt;\", line 2 name = 'Feng ^ SyntaxError: EOL while scanning string literal . # An extra '=' in the assignment. age = = 52 . File \"&lt;ipython-input-57-ccc3df3cf902&gt;\", line 2 age = = 52 ^ SyntaxError: invalid syntax . | Look more closely at the error message: | . print(\"hello world\" . File \"&lt;ipython-input-6-d1cc229bf815&gt;\", line 1 print (\"hello world\" ^ SyntaxError: unexpected EOF while parsing . | The message indicates a problem on first line of the input (“line 1”). | In this case the “ipython-input” section of the file name tells us that we are working with input into IPython, the Python interpreter used by the Jupyter Notebook. | . | The -6- part of the filename indicates that the error occurred in cell 6 of our Notebook. | Next is the problematic line of code, indicating the problem with a ^ pointer. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/04-built-in.html#python-reports-a-syntax-error-when-it-cant-understand-the-source-of-a-program",
    "relUrl": "/Python_Series_Materials/part_1/04-built-in.html#python-reports-a-syntax-error-when-it-cant-understand-the-source-of-a-program"
  },"141": {
    "doc": "Built-in Functions and Help",
    "title": " Python reports a runtime error when something goes wrong while a program is executing.",
    "content": "age = 53 remaining = 100 - aege # mis-spelled 'age' . NameError Traceback (most recent call last) &lt;ipython-input-59-1214fb6c55fc&gt; in &lt;module&gt; 1 age = 53 ----&gt; 2 remaining = 100 - aege # mis-spelled 'age' NameError: name 'aege' is not defined . | Fix syntax errors by reading the source and runtime errors by tracing execution. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/04-built-in.html#-python-reports-a-runtime-error-when-something-goes-wrong-while-a-program-is-executing",
    "relUrl": "/Python_Series_Materials/part_1/04-built-in.html#-python-reports-a-runtime-error-when-something-goes-wrong-while-a-program-is-executing"
  },"142": {
    "doc": "Built-in Functions and Help",
    "title": "What Happens When",
    "content": ". | Explain in simple terms the order of operations in the following program: when does the addition happen, when does the subtraction happen, when is each function called, etc. | What is the final value of radiance? | . radiance = 1.0 radiance = max(2.1, 2.0 + min(radiance, 1.1 * radiance - 0.5)) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/04-built-in.html#what-happens-when",
    "relUrl": "/Python_Series_Materials/part_1/04-built-in.html#what-happens-when"
  },"143": {
    "doc": "Built-in Functions and Help",
    "title": "Solution",
    "content": ". | Order of operations: . | 1.1 * radiance = 1.1 | 1.1 - 0.5 = 0.6 | min(radiance, 0.6) = 0.6 | 2.0 + 0.6 = 2.6 | max(2.1, 2.6) = 2.6 | . | At the end, radiance = 2.6 | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/04-built-in.html#solution",
    "relUrl": "/Python_Series_Materials/part_1/04-built-in.html#solution"
  },"144": {
    "doc": "Built-in Functions and Help",
    "title": "Spot the Difference",
    "content": ". | Predict what each of the print statements in the program below will print. | Does max(len(rich), poor) run or produce an error message? If it runs, does its result make any sense? | . easy_string = \"abc\" print(max(easy_string)) rich = \"gold\" poor = \"tin\" print(max(rich, poor)) print(max(len(rich), len(poor))) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/04-built-in.html#spot-the-difference",
    "relUrl": "/Python_Series_Materials/part_1/04-built-in.html#spot-the-difference"
  },"145": {
    "doc": "Built-in Functions and Help",
    "title": "Solution",
    "content": "print(max(easy_string)) . c . print(max(rich, poor)) . tin . print(max(len(rich), len(poor))) . 4 . max(len(rich), poor) throws a TypeError. This turns into max(4, 'tin') and as we discussed earlier a string and integer cannot meaningfully be compared. TypeError Traceback (most recent call last) &lt;ipython-input-65-bc82ad05177a&gt; in &lt;module&gt; ----&gt; 1 max(len(rich), poor) TypeError: '&gt;' not supported between instances of 'str' and 'int' . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/04-built-in.html#solution-1",
    "relUrl": "/Python_Series_Materials/part_1/04-built-in.html#solution-1"
  },"146": {
    "doc": "Built-in Functions and Help",
    "title": "Why Not?",
    "content": "Why is it that max and min do not return None when they are called with no arguments? . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/04-built-in.html#why-not",
    "relUrl": "/Python_Series_Materials/part_1/04-built-in.html#why-not"
  },"147": {
    "doc": "Built-in Functions and Help",
    "title": "Solution",
    "content": "max and min return TypeErrors in this case because the correct number of parameters was not supplied. If it just returned None, the error would be much harder to trace as it would likely be stored into a variable and used later in the program, only to likely throw a runtime error. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/04-built-in.html#solution-2",
    "relUrl": "/Python_Series_Materials/part_1/04-built-in.html#solution-2"
  },"148": {
    "doc": "Built-in Functions and Help",
    "title": "Last Character of a String",
    "content": "If Python starts counting from zero, and len returns the number of characters in a string, what index expression will get the last character in the string name? (Note: we will see a simpler way to do this in a later episode.) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/04-built-in.html#last-character-of-a-string",
    "relUrl": "/Python_Series_Materials/part_1/04-built-in.html#last-character-of-a-string"
  },"149": {
    "doc": "Built-in Functions and Help",
    "title": "Solution",
    "content": "name[len(name) - 1] . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/04-built-in.html#solution-3",
    "relUrl": "/Python_Series_Materials/part_1/04-built-in.html#solution-3"
  },"150": {
    "doc": "Built-in Functions and Help",
    "title": "Explore the Python docs!",
    "content": "The official Python documentation is arguably the most complete source of information about the language. It is available in different languages and contains a lot of useful resources. The Built-in Functions page contains a catalogue of all of these functions, including the ones that we’ve covered in this lesson. Some of these are more advanced and unnecessary at the moment, but others are very simple and useful. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/04-built-in.html#explore-the-python-docs",
    "relUrl": "/Python_Series_Materials/part_1/04-built-in.html#explore-the-python-docs"
  },"151": {
    "doc": "Tracking Changes",
    "title": "Tracking Changes",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/04-changes.html",
    "relUrl": "/Git_Materials/04-changes.html"
  },"152": {
    "doc": "Tracking Changes",
    "title": "Objectives",
    "content": ". | Go through the modify-add-commit cycle for one or more files. | Explain where information is stored at each stage of that cycle. | Distinguish between descriptive and non-descriptive commit messages. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/04-changes.html#objectives",
    "relUrl": "/Git_Materials/04-changes.html#objectives"
  },"153": {
    "doc": "Tracking Changes",
    "title": "Questions",
    "content": ". | How do I record changes in Git? | How do I check the status of my version control repository? | How do I record notes about what changes I made and why? | . First let’s make sure we’re still in the right directory. You should be in the planets directory. $ cd ~/Desktop/planets . Let’s create a file called mars.txt that contains some notes about the Red Planet’s suitability as a base. We’ll use nano to edit the file; you can use whatever editor you like. In particular, this does not have to be the core.editor you set globally earlier. But remember, the bash command to create or edit a new file will depend on the editor you choose (it might not be nano). For a refresher on text editors, check out “Which Editor?” in The Unix Shell lesson. $ nano mars.txt . Type the text below into the mars.txt file: . Cold and dry, but everything is my favorite color . Let’s first verify that the file was properly created by running the list command (ls): . $ ls . mars.txt . mars.txt contains a single line, which we can see by running: . $ cat mars.txt . Cold and dry, but everything is my favorite color . If we check the status of our project again, Git tells us that it’s noticed the new file: . $ git status . On branch main No commits yet Untracked files: (use \"git add &lt;file&gt;...\" to include in what will be committed) mars.txt nothing added to commit but untracked files present (use \"git add\" to track) . The “untracked files” message means that there’s a file in the directory that Git isn’t keeping track of. We can tell Git to track a file using git add: . $ git add mars.txt . and then check that the right thing happened: . $ git status . On branch main No commits yet Changes to be committed: (use \"git rm --cached &lt;file&gt;...\" to unstage) new file: mars.txt . Git now knows that it’s supposed to keep track of mars.txt, but it hasn’t recorded these changes as a commit yet. To get it to do that, we need to run one more command: . $ git commit -m \"Start notes on Mars as a base\" . [main (root-commit) f22b25e] Start notes on Mars as a base 1 file changed, 1 insertion(+) create mode 100644 mars.txt . When we run git commit, Git takes everything we have told it to save by using git add and stores a copy permanently inside the special .git directory. This permanent copy is called a commit (or revision) and its short identifier is f22b25e. Your commit may have another identifier. We use the -m flag (for “message”) to record a short, descriptive, and specific comment that will help us remember later on what we did and why. If we just run git commit without the -m option, Git will launch nano (or whatever other editor we configured as core.editor) so that we can write a longer message. Good commit messages start with a brief (&lt;50 characters) statement about the changes made in the commit. Generally, the message should complete the sentence “If applied, this commit will” {commit message here}. If you want to go into more detail, add a blank line between the summary line and your additional notes. Use this additional space to explain why you made changes and/or what their impact will be. If we run git status now: . $ git status . On branch main nothing to commit, working tree clean . it tells us everything is up to date. If we want to know what we’ve done recently, we can ask Git to show us the project’s history using git log: . $ git log . commit f22b25e3233b4645dabd0d81e651fe074bd8e73b Author: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt; Date: Thu Aug 22 09:51:46 2013 -0400 Start notes on Mars as a base . git log lists all commits made to a repository in reverse chronological order. The listing for each commit includes the commit’s full identifier (which starts with the same characters as the short identifier printed by the git commit command earlier), the commit’s author, when it was created, and the log message Git was given when the commit was created. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/04-changes.html#questions",
    "relUrl": "/Git_Materials/04-changes.html#questions"
  },"154": {
    "doc": "Tracking Changes",
    "title": "Where Are My Changes?",
    "content": "If we run ls at this point, we will still see just one file called mars.txt. That’s because Git saves information about files’ history in the special .git directory mentioned earlier so that our filesystem doesn’t become cluttered (and so that we can’t accidentally edit or delete an old version). Now suppose Dracula adds more information to the file. (Again, we’ll edit with nano and then cat the file to show its contents; you may use a different editor, and don’t need to cat.) . $ nano mars.txt $ cat mars.txt . Cold and dry, but everything is my favorite color The two moons may be a problem for Wolfman . When we run git status now, it tells us that a file it already knows about has been modified: . $ git status . On branch main Changes not staged for commit: (use \"git add &lt;file&gt;...\" to update what will be committed) (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory) modified: mars.txt no changes added to commit (use \"git add\" and/or \"git commit -a\") . The last line is the key phrase: “no changes added to commit”. We have changed this file, but we haven’t told Git we will want to save those changes (which we do with git add) nor have we saved them (which we do with git commit). So let’s do that now. It is good practice to always review our changes before saving them. We do this using git diff. This shows us the differences between the current state of the file and the most recently saved version: . $ git diff . diff --git a/mars.txt b/mars.txt index df0654a..315bf3a 100644 --- a/mars.txt +++ b/mars.txt @@ -1 +1,2 @@ Cold and dry, but everything is my favorite color +The two moons may be a problem for Wolfman . The output is cryptic because it is actually a series of commands for tools like editors and patch telling them how to reconstruct one file given the other. If we break it down into pieces: . | The first line tells us that Git is producing output similar to the Unix diff command comparing the old and new versions of the file. | The second line tells exactly which versions of the file Git is comparing; df0654a and 315bf3a are unique computer-generated labels for those versions. | The third and fourth lines once again show the name of the file being changed. | The remaining lines are the most interesting, they show us the actual differences and the lines on which they occur. In particular, the + marker in the first column shows where we added a line. | . After reviewing our change, it’s time to commit it: . $ git commit -m \"Add concerns about effects of Mars' moons on Wolfman\" . On branch main Changes not staged for commit: (use \"git add &lt;file&gt;...\" to update what will be committed) (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory) modified: mars.txt no changes added to commit (use \"git add\" and/or \"git commit -a\") . Whoops: Git won’t commit because we didn’t use git add first. Let’s fix that: . $ git add mars.txt $ git commit -m \"Add concerns about effects of Mars' moons on Wolfman\" . [main 34961b1] Add concerns about effects of Mars' moons on Wolfman 1 file changed, 1 insertion(+) . Git insists that we add files to the set we want to commit before actually committing anything. This allows us to commit our changes in stages and capture changes in logical portions rather than only large batches. For example, suppose we’re adding a few citations to relevant research to our thesis. We might want to commit those additions, and the corresponding bibliography entries, but not commit some of our work drafting the conclusion (which we haven’t finished yet). To allow for this, Git has a special staging area where it keeps track of things that have been added to the current changeset but not yet committed. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/04-changes.html#where-are-my-changes",
    "relUrl": "/Git_Materials/04-changes.html#where-are-my-changes"
  },"155": {
    "doc": "Tracking Changes",
    "title": "Staging Area",
    "content": "If you think of Git as taking snapshots of changes over the life of a project, git add specifies what will go in a snapshot (putting things in the staging area), and git commit then actually takes the snapshot, and makes a permanent record of it (as a commit). If you don’t have anything staged when you type git commit, Git will prompt you to use git commit -a or git commit --all, which is kind of like gathering everyone to take a group photo! However, it’s almost always better to explicitly add things to the staging area, because you might commit changes you forgot you made. (Going back to the group photo simile, you might get an extra with incomplete makeup walking on the stage for the picture because you used -a!) Try to stage things manually, or you might find yourself searching for “git undo commit” more than you would like! . Let’s watch as our changes to a file move from our editor to the staging area and into long-term storage. First, we’ll add another line to the file: . $ nano mars.txt $ cat mars.txt . Cold and dry, but everything is my favorite color The two moons may be a problem for Wolfman But the Mummy will appreciate the lack of humidity . $ git diff . diff --git a/mars.txt b/mars.txt index 315bf3a..b36abfd 100644 --- a/mars.txt +++ b/mars.txt @@ -1,2 +1,3 @@ Cold and dry, but everything is my favorite color The two moons may be a problem for Wolfman +But the Mummy will appreciate the lack of humidity . So far, so good: we’ve added one line to the end of the file (shown with a + in the first column). Now let’s put that change in the staging area and see what git diff reports: . $ git add mars.txt $ git diff . There is no output: as far as Git can tell, there’s no difference between what it’s been asked to save permanently and what’s currently in the directory. However, if we do this: . $ git diff --staged . diff --git a/mars.txt b/mars.txt index 315bf3a..b36abfd 100644 --- a/mars.txt +++ b/mars.txt @@ -1,2 +1,3 @@ Cold and dry, but everything is my favorite color The two moons may be a problem for Wolfman +But the Mummy will appreciate the lack of humidity . it shows us the difference between the last committed change and what’s in the staging area. Let’s save our changes: . $ git commit -m \"Discuss concerns about Mars' climate for Mummy\" . [main 005937f] Discuss concerns about Mars' climate for Mummy 1 file changed, 1 insertion(+) . check our status: . $ git status . On branch main nothing to commit, working tree clean . and look at the history of what we’ve done so far: . $ git log . commit 005937fbe2a98fb83f0ade869025dc2636b4dad5 (HEAD -&gt; main) Author: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt; Date: Thu Aug 22 10:14:07 2013 -0400 Discuss concerns about Mars' climate for Mummy commit 34961b159c27df3b475cfe4415d94a6d1fcd064d Author: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt; Date: Thu Aug 22 10:07:21 2013 -0400 Add concerns about effects of Mars' moons on Wolfman commit f22b25e3233b4645dabd0d81e651fe074bd8e73b Author: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt; Date: Thu Aug 22 09:51:46 2013 -0400 Start notes on Mars as a base . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/04-changes.html#staging-area",
    "relUrl": "/Git_Materials/04-changes.html#staging-area"
  },"156": {
    "doc": "Tracking Changes",
    "title": "Word-based diffing",
    "content": "Sometimes, e.g. in the case of the text documents a line-wise diff is too coarse. That is where the --color-words option of git diff comes in very useful as it highlights the changed words using colors. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/04-changes.html#word-based-diffing",
    "relUrl": "/Git_Materials/04-changes.html#word-based-diffing"
  },"157": {
    "doc": "Tracking Changes",
    "title": "Paging the Log",
    "content": "When the output of git log is too long to fit in your screen, git uses a program to split it into pages of the size of your screen. When this “pager” is called, you will notice that the last line in your screen is a :, instead of your usual prompt. | To get out of the pager, press Q. | To move to the next page, press Spacebar. | To search for some_word in all pages, press / and type some_word. Navigate through matches pressing N. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/04-changes.html#paging-the-log",
    "relUrl": "/Git_Materials/04-changes.html#paging-the-log"
  },"158": {
    "doc": "Tracking Changes",
    "title": "Limit Log Size",
    "content": "To avoid having git log cover your entire terminal screen, you can limit the number of commits that Git lists by using -N, where N is the number of commits that you want to view. For example, if you only want information from the last commit you can use: . $ git log -1 . commit 005937fbe2a98fb83f0ade869025dc2636b4dad5 (HEAD -&gt; main) Author: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt; Date: Thu Aug 22 10:14:07 2013 -0400 Discuss concerns about Mars' climate for Mummy . You can also reduce the quantity of information using the --oneline option: . $ git log --oneline . 005937f (HEAD -&gt; main) Discuss concerns about Mars' climate for Mummy 34961b1 Add concerns about effects of Mars' moons on Wolfman f22b25e Start notes on Mars as a base . You can also combine the --oneline option with others. One useful combination adds --graph to display the commit history as a text-based graph and to indicate which commits are associated with the current HEAD, the current branch main, or other Git references: . $ git log --oneline --graph . * 005937f (HEAD -&gt; main) Discuss concerns about Mars' climate for Mummy * 34961b1 Add concerns about effects of Mars' moons on Wolfman * f22b25e Start notes on Mars as a base . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/04-changes.html#limit-log-size",
    "relUrl": "/Git_Materials/04-changes.html#limit-log-size"
  },"159": {
    "doc": "Tracking Changes",
    "title": "Directories",
    "content": "Two important facts you should know about directories in Git. | Git does not track directories on their own, only files within them. Try it for yourself: | . $ mkdir spaceships $ git status $ git add spaceships $ git status . Note, our newly created empty directory spaceships does not appear in the list of untracked files even if we explicitly add it (via git add) to our repository. This is the reason why you will sometimes see .gitkeep files in otherwise empty directories. Unlike .gitignore, these files are not special and their sole purpose is to populate a directory so that Git adds it to the repository. In fact, you can name such files anything you like. | If you create a directory in your Git repository and populate it with files, you can add all files in the directory at once by: | . git add {directory-with-files&gt;} . Try it for yourself: . $ touch spaceships/apollo-11 spaceships/sputnik-1 $ git status $ git add spaceships $ git status . Before moving on, we will commit these changes. $ git commit -m \"Add some initial thoughts on spaceships\" . To recap, when we want to add changes to our repository, we first need to add the changed files to the staging area (git add) and then commit the staged changes to the repository (git commit): . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/04-changes.html#directories",
    "relUrl": "/Git_Materials/04-changes.html#directories"
  },"160": {
    "doc": "Tracking Changes",
    "title": "Choosing a Commit Message",
    "content": "Which of the following commit messages would be most appropriate for the last commit made to mars.txt? . | “Changes” | “Added line ‘But the Mummy will appreciate the lack of humidity’ to mars.txt” | “Discuss effects of Mars’ climate on the Mummy” | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/04-changes.html#choosing-a-commit-message",
    "relUrl": "/Git_Materials/04-changes.html#choosing-a-commit-message"
  },"161": {
    "doc": "Tracking Changes",
    "title": "Solution",
    "content": "Answer 1 is not descriptive enough, and the purpose of the commit is unclear; and answer 2 is redundant to using “git diff” to see what changed in this commit; but answer 3 is good: short, descriptive, and imperative. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/04-changes.html#solution",
    "relUrl": "/Git_Materials/04-changes.html#solution"
  },"162": {
    "doc": "Tracking Changes",
    "title": "Committing Changes to Git",
    "content": "Which command(s) below would save the changes of myfile.txt to my local Git repository? . 1. $ git commit -m \"my recent changes\" . 2. $ git init myfile.txt $ git commit -m \"my recent changes\" . 3. $ git add myfile.txt $ git commit -m \"my recent changes\" . 4. $ git commit -m myfile.txt \"my recent changes\" . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/04-changes.html#committing-changes-to-git",
    "relUrl": "/Git_Materials/04-changes.html#committing-changes-to-git"
  },"163": {
    "doc": "Tracking Changes",
    "title": "Solution",
    "content": ". | Would only create a commit if files have already been staged. | Would try to create a new repository. | Is correct: first add the file to the staging area, then commit. | Would try to commit a file “my recent changes” with the message myfile.txt. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/04-changes.html#solution-1",
    "relUrl": "/Git_Materials/04-changes.html#solution-1"
  },"164": {
    "doc": "Tracking Changes",
    "title": "Committing Multiple Files",
    "content": "The staging area can hold changes from any number of files that you want to commit as a single snapshot. | Add some text to mars.txt noting your decision to consider Venus as a base | Create a new file venus.txt with your initial thoughts about Venus as a base for you and your friends | Add changes from both files to the staging area, and commit those changes. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/04-changes.html#committing-multiple-files",
    "relUrl": "/Git_Materials/04-changes.html#committing-multiple-files"
  },"165": {
    "doc": "Tracking Changes",
    "title": "Solution",
    "content": "The output below from cat mars.txt reflects only content added during this exercise. Your output may vary. First we make our changes to the mars.txt and venus.txt files: . $ nano mars.txt $ cat mars.txt . Maybe I should start with a base on Venus. $ nano venus.txt $ cat venus.txt . Venus is a nice planet and I definitely should consider it as a base. Now you can add both files to the staging area. We can do that in one line: . $ git add mars.txt venus.txt . Or with multiple commands: . $ git add mars.txt $ git add venus.txt . Now the files are ready to commit. You can check that using git status. If you are ready to commit use: . $ git commit -m \"Write plans to start a base on Venus\" . [main cc127c2] Write plans to start a base on Venus 2 files changed, 2 insertions(+) create mode 100644 venus.txt . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/04-changes.html#solution-2",
    "relUrl": "/Git_Materials/04-changes.html#solution-2"
  },"166": {
    "doc": "Tracking Changes",
    "title": "bio Repository",
    "content": ". | Create a new Git repository on your computer called bio. | Write a three-line biography for yourself in a file called me.txt, commit your changes | Modify one line, add a fourth line | Display the differences between its updated state and its original state. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/04-changes.html#bio-repository",
    "relUrl": "/Git_Materials/04-changes.html#bio-repository"
  },"167": {
    "doc": "Tracking Changes",
    "title": "Solution",
    "content": "If needed, move out of the planets folder: . $ cd .. Create a new folder called bio and ‘move’ into it: . $ mkdir bio $ cd bio . Initialise git: . $ git init . Create your biography file me.txt using nano or another text editor. Once in place, add and commit it to the repository: . $ git add me.txt $ git commit -m \"Add biography file\" . Modify the file as described (modify one line, add a fourth line). To display the differences between its updated state and its original state, use git diff: . $ git diff me.txt . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/04-changes.html#solution-3",
    "relUrl": "/Git_Materials/04-changes.html#solution-3"
  },"168": {
    "doc": "Tracking Changes",
    "title": "Keypoints",
    "content": ". | git status shows the status of a repository. | Files can be stored in a project’s working directory (which users see), the staging area (where the next commit is being built up) and the local repository (where commits are permanently recorded). | git add puts files in the staging area. | git commit saves the staged content as a new commit in the local repository. | Write a commit message that accurately describes your changes. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/04-changes.html#keypoints",
    "relUrl": "/Git_Materials/04-changes.html#keypoints"
  },"169": {
    "doc": "Syncing Your Zotero Collection",
    "title": "Syncing Your Zotero Collection with Obsidian",
    "content": "Now that we’ve discussed how to manage notes and improve your vault with plugins, this lesson will outline a workflow to enhance your process in taking notes for research. When we find ourselves writing documents for research, reference managers help us keep track of the publications we cite in our writing. Over time, you may likely accumualte notes about each publication you read, and it’s possible to find yourself in a mess to keep track of which notes belong to which reference. With the Citations plugin, you can easily create notes that are linked to items in your Zotero collection. With all the other functionalities in Obsidian, you can then link these notes to notes about other references, categorize them with tags, and visualize the connections between your notes with the graph view! . ",
    "url": "http://localhost:4000/portfolio_workshop/Obsidian_Materials/04-syncing-zotero.html#syncing-your-zotero-collection-with-obsidian",
    "relUrl": "/Obsidian_Materials/04-syncing-zotero.html#syncing-your-zotero-collection-with-obsidian"
  },"170": {
    "doc": "Syncing Your Zotero Collection",
    "title": "Setting up Zotero",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Obsidian_Materials/04-syncing-zotero.html#setting-up-zotero",
    "relUrl": "/Obsidian_Materials/04-syncing-zotero.html#setting-up-zotero"
  },"171": {
    "doc": "Syncing Your Zotero Collection",
    "title": "Better BibTeX",
    "content": ". | First, make sure to download Zotero if you have not already | Then follow these instructions to install Better BibTeX. Be sure to restart Zotero so that all changes are applied | In Zotero, go to Preferences (Edit&gt;Preferences). There will be a tab for Better BibTex in this window | With Better BibTeX, you can edit a Citation Key that labels each reference in your library. You will see later in this lesson that this key will be the title for the note that you create for a reference. Here is an example of a citation key formula you can use: authEtal2.lower + year +veryshorttitle. This will produce a citation key with the last name of the first author (plus the second author, if only two authors, or “etal” for larger author lists), the year, and the first word from the title of the publication. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Obsidian_Materials/04-syncing-zotero.html#better-bibtex",
    "relUrl": "/Obsidian_Materials/04-syncing-zotero.html#better-bibtex"
  },"172": {
    "doc": "Syncing Your Zotero Collection",
    "title": "Exporting your library to Obsidian",
    "content": "Now let’s export your Zotero library (via Better BiBLaTeX) to a file in your vault. | Select File &gt; Export Library... and in the Export window, select Better BibLaTeX for the format. | Select Keep updated so that your collection is automatically re-exported each time you make changes | Save your exported file somewhere inside your vault | . ",
    "url": "http://localhost:4000/portfolio_workshop/Obsidian_Materials/04-syncing-zotero.html#exporting-your-library-to-obsidian",
    "relUrl": "/Obsidian_Materials/04-syncing-zotero.html#exporting-your-library-to-obsidian"
  },"173": {
    "doc": "Syncing Your Zotero Collection",
    "title": "Citations Plugin",
    "content": "Now you can install Citations and make notes for articles in Zotero. Once you do, make the following changes in the settings: . | Change the Citation plugin settings to BibLaTeX | Provide the path to the file for your exported library | Specify a folder to store your literature notes. It’s good to have a dedicated folder for these notes so that they don’t clutter your vault | . Now you’re ready to use Citations! The controls are simple: . ",
    "url": "http://localhost:4000/portfolio_workshop/Obsidian_Materials/04-syncing-zotero.html#citations-plugin",
    "relUrl": "/Obsidian_Materials/04-syncing-zotero.html#citations-plugin"
  },"174": {
    "doc": "Syncing Your Zotero Collection",
    "title": "Open or create a literature note",
    "content": ". | Open or create a literature note by pressing Ctrl+Shift+O. | A search bar will open that will let you find the reference in mind. Select the reference to create/open the note. | The name of the note will be the same as the citation key listed in Zotero, and the note will have a preamble with metadata about the reference (eg. Title, Authors, Year) | . ",
    "url": "http://localhost:4000/portfolio_workshop/Obsidian_Materials/04-syncing-zotero.html#open-or-create-a-literature-note",
    "relUrl": "/Obsidian_Materials/04-syncing-zotero.html#open-or-create-a-literature-note"
  },"175": {
    "doc": "Syncing Your Zotero Collection",
    "title": "Link to a literature note",
    "content": ". | Create an internal link to a literature note inside of a different note by typing Ctrl+Shift+E. | Again, a search bar will come up, which you can use to find the reference in mind. | If a literature has not been created yet, it will also be created for you. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Obsidian_Materials/04-syncing-zotero.html#link-to-a-literature-note",
    "relUrl": "/Obsidian_Materials/04-syncing-zotero.html#link-to-a-literature-note"
  },"176": {
    "doc": "Syncing Your Zotero Collection",
    "title": "Organize and categorize your literature notes!",
    "content": "Now that you have literature notes, spend time to go through them, create links to other notes, and give them tags for different topics! . ",
    "url": "http://localhost:4000/portfolio_workshop/Obsidian_Materials/04-syncing-zotero.html#organize-and-categorize-your-literature-notes",
    "relUrl": "/Obsidian_Materials/04-syncing-zotero.html#organize-and-categorize-your-literature-notes"
  },"177": {
    "doc": "Syncing Your Zotero Collection",
    "title": "Syncing Your Zotero Collection",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Obsidian_Materials/04-syncing-zotero.html",
    "relUrl": "/Obsidian_Materials/04-syncing-zotero.html"
  },"178": {
    "doc": "Working with Files and Directories",
    "title": "Working with Files and Directories",
    "content": "Creating directories . There are two ways of creating a directory. The first way is using your computer’s graphical file explorer, and the second creating a directory in the shell. Both methods accomplish the same task. You can create a new directory by using the command mkdir which means ‘make directory’. It’s possible to create a directory with nested subdirectories in a single operation using the option -p with your mkdir command. To be sure the nested subdirectories were created in your directory hierarchy, type ls -FR and directory name. See example below: . Creating text files using a text editor . There are several powerful and flexible text editors, but whichever one you choose to use, it’s good to know where the editor searches and saves files. nano is an editor that works only with plain character data (i.e., no tables, images, etc.) . To create a text file using nano, run the text editor nano and type a filename. This will take you into the nano text editor. Once text has been written press control+ o or Ctrl+o. You will be asked to provide a namefor the file that will contain your text. Then press Return or Enter to accept. Once the file is saved, to quit the editor and return to the shell use control+x or Ctrl+x . Tip: make sure you are in the working directory you want the text file to be created in. Move files and directories . To change a file or directory name you can use the mv command, which is short for move . The first argument thesis/draft.txt tells mv what we are moving, while the second argument thesis/quotes.txt. This is essentially the same as renaming a file. Note: using the mv command will overwrite any existing files with the same name, which can lead to data loss. To cause mv to request a confirmation, add -i option. $ mv -i thesis/draft.txt thesis/quotes.txt . The mv command can also move files to different directories. To change a file or directory name you can use the mv command, which is short for move . Copy files and directories . To create a copy of a file or directory, you can use the cp copy command. The cp command works similarly to mv except that you are creating a copy rather than moving or renaming it. To create a back up of a directory, you can use a recursive option -r. This will create a copy of a directory and all its contents. Remove files and directories . Command Line makes it simple to remove files and tidy up a directories using the rm command, short for remove. To remove directories you can you add the recursive option -r, which would look like -r rm. Note: when you use the rm or rm -r commands it permanently deletes a file or directory. It does not go into a trash bin. To make sure you want to remove a file you can add the interactive option -i. Safely remove a file: . $ rm -i . Safely remove a directory: . $ rm -r -i . Wildcards . Wildcards are special characters * and ? that prompt shell to create a list of matching filenames before running a command. Using wildcards can be helpful when trying to access multiple files at once. * represents zero or more other characters. For example, *ethane.pdb would match both ethane.pdb and methane.pdb . ? represents exactly one character. For example, ?ethane.pdb would match only methane.pdb and not ethane.pdb . ",
    "url": "http://localhost:4000/portfolio_workshop/cli/04_files_direc_working.html",
    "relUrl": "/cli/04_files_direc_working.html"
  },"179": {
    "doc": "Restructuring data",
    "title": "Restructure the dataset by removing columns and rows, and then work with Undo/Redo to roll those changes back",
    "content": ". | Delete columns in bulk: Go to the special All column pull down menu on the far left. From the All column pull down menu, select Edit columns-&gt;Re-order / remove columns… From here you can drag columns from the left to the right to remove them – do this for private latitude and private longitude. We can also reorder columns. Move license, species_guess and quality_grade columns to just under id to move those columns more to the left. Click on OK to make the changes. | Flag or star rows: Click on the flag symbol next to a row of interest – try flagging the first few rows of the dataset. | Use facets to define and flag a subset: From the license column pull down menu, select Facet–&gt;Customized facets–&gt;Facet by blanks. Click on true to show only the rows where that column is blank (i.e., rows where no license has been specified). From the quality_grade column pull down menu, select Facet–&gt;Text facet Select the casual facet. Now we have a subset of rows that have a blank for license and are casual observations. Let’s say that these 18 rows were no good to use. We could flag them (or star them or remove them). From the All column pull down menu, select Edit rows-&gt;Flag rows | Remove flagged rows: Reset all facets by clicking on the Reset All button on the left above the facet windows. Now you should see all the rows in your dataset again, some are flagged and some are not. Later if you decide that you want to remove those flagged rows that you were unsure of, you can. From the All column pull down menu, select Facet–&gt;Facet by flag and then select true from the facet window to show only your flagged rows. You can delete all of them. From the All column pull down menu, select Edit rows–&gt;Remove all matching rows. All the flagged rows should now be removed from the dataset. Reset all facets again by clicking on the Reset All button on the left above the facet windows to see your remaining rows. | Undo and redo actions: Click on the Undo/Redo tab above where the facets show up. You’ll see a number of steps that outlines everything we did to this dataset. It is a great way to keep track of what you’ve done. You can also roll back your changes to a previous version by clicking on the last step you were happy with. Then everything after that has been rolled back. You can go back and forth in time to take a look at the dataset at a particular point. For example, click on the item that says Reorder columns. You’ll see that the steps after that have greyed out, which means they haven’t happened yet. So for this example, those flagged rows have now not be deleted, and you should see them in your dataset. | . | Note: If you go back to a previous step (like we’ve just done), and then start making new changes/transformations - all the subsequent steps will be deleted permanently. | . Bonus: Removing Duplicates A common clean up process is the removal of items that are duplicates based on one or more columns. For a step-by-step guide to using faceting for this purpose, see https://guides.library.illinois.edu/openrefine/duplicates. ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt2_citizen_science/04_restructure.html#restructure-the-dataset-by-removing-columns-and-rows-and-then-work-with-undoredo-to-roll-those-changes-back",
    "relUrl": "/OpenRefine_Materials/pt2_citizen_science/04_restructure.html#restructure-the-dataset-by-removing-columns-and-rows-and-then-work-with-undoredo-to-roll-those-changes-back"
  },"180": {
    "doc": "Restructuring data",
    "title": "Restructuring data",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt2_citizen_science/04_restructure.html",
    "relUrl": "/OpenRefine_Materials/pt2_citizen_science/04_restructure.html"
  },"181": {
    "doc": "Sorting, filtering and faceting",
    "title": "Sort, filter and facet data",
    "content": ". | Sort data on a row: Rows of data are initially loaded in the order they appear in the original data file. In this case, they are grouped by state, with Alabama first. To change the sort, from the State column pull down menu, select Sort… In the Sort window, sort as text, ordered from z-a. Click OK. | Add a secondary sort: From the 2017 column pull down menu, select Sort…, and sort by numbers, from largest first. Notice the “sort by this column alone” option – that only appears when there is already one or more sorts in place. If you don’t check that option, it will keep the original sort and add this as a secondary sort. | Remove a sort: You can remove a sort at any time by pulling down the column’s menu, and choosing Sort -&gt; Remove sort. | Filter the data: Filtering allows us to search for certain information within our dataset. Let’s say we want to display only the Pennsylvania data. From the State column pull down menu, choose Text filter. The text filter appears in the left-hand sidebar, under the “Facet/Filter” tab. Type ‘pennsylvania’ in the search box. OpenRefine automatically removes any rows from the display that don’t match, leaving a total of 24 rows remaining (out of 1227 total). | Add a second filter: We can have text filters on more than one column at a time. From the Expenditure column pull down menu, choose Text filter. Type ‘food’ in the search box for that filter. The two filters are combined, showing us all the food-related expenditure categories for Pennsylvania. | Note that any functions you perform on filtered data will only be performed on the filtered records, not the entire dataset. This is also true of exporting the file–if you have filters applied, only the filtered data will appear in the export. | . | Remove filters: You can remove a filter by clicking on the x in the top left-hand corner of the filter box. Remove both filters now. You should have all 1227 rows displayed again. | Creating a facet: A facet summarizes all the values that appear in the column, and lets you select which data to view, as well as provides ways to edit the data. From the State column pull down menu, choose Facet -&gt; Text facet. The facet appears in the left-hand sidebar, in the same area where the filters were previously. It shows you how many total values there are in this column (50), how many rows contain each value (for this dataset it is the same for each, 24), and allows you to sort the values by name or by count (count won’t be helpful in this case since they all have the same count). | Filter data using facets: Click on Pennsylvania in the value list. This has the same effect as using the text filter to search for Pennsylvania, leaving 24 matching rows. However, from there we can do more than the filter allowed. We can select a second value at the same time. Hover your cursor over West Virginia in the value list and choose include. You can then exclude one or both of the selections at any time. Hover your cursor over Pennsylvania in the value list and choose exclude. Now only West Virginia rows are shown. | Working with numeric facets: From the 2017 column pull down menu, expand Facet, and look at the options. There are some other types of facets available, including numeric facets. If we created a numeric facet now, it would only work for this column, so you would have to facet each year of data separately. Let’s manipulate the data a bit first, and then come back and work with numeric facets. | . Activity 1 . In addition to the text facet on State, add another text facet on the expenditure column. Using the facets, view the Pennsylvania, West Virginia and Ohio data for “Gasoline and other energy goods” expenditures. Which state spent the most per capita in 2017? . Bonus Activity . Remove the above facets. Apply a numeric facet to the 2017 columns and facet to only expenditures over $30,000. Using an additional facet, determine the expenditure category with the most values over $30000. ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt1_expenditure/04_sort-filter-facet.html#sort-filter-and-facet-data",
    "relUrl": "/OpenRefine_Materials/pt1_expenditure/04_sort-filter-facet.html#sort-filter-and-facet-data"
  },"182": {
    "doc": "Sorting, filtering and faceting",
    "title": "Sorting, filtering and faceting",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt1_expenditure/04_sort-filter-facet.html",
    "relUrl": "/OpenRefine_Materials/pt1_expenditure/04_sort-filter-facet.html"
  },"183": {
    "doc": "Exploring History",
    "title": "Exploring History",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/05-history.html",
    "relUrl": "/Git_Materials/05-history.html"
  },"184": {
    "doc": "Exploring History",
    "title": "Objectives",
    "content": ". | Explain what the HEAD of a repository is and how to use it. | Identify and use Git commit numbers. | Compare various versions of tracked files. | Restore old versions of files. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/05-history.html#objectives",
    "relUrl": "/Git_Materials/05-history.html#objectives"
  },"185": {
    "doc": "Exploring History",
    "title": "Questions",
    "content": ". | How can I identify old versions of files? | How do I review my changes? | How can I recover old versions of files? | . As we saw in the previous episode, we can refer to commits by their identifiers. You can refer to the most recent commit of the working directory by using the identifier HEAD. We’ve been adding one line at a time to mars.txt, so it’s easy to track our progress by looking, so let’s do that using our HEADs. Before we start, let’s make a change to mars.txt, adding yet another line. $ nano mars.txt $ cat mars.txt . Cold and dry, but everything is my favorite color The two moons may be a problem for Wolfman But the Mummy will appreciate the lack of humidity An ill-considered change . Now, let’s see what we get. $ git diff HEAD mars.txt . diff --git a/mars.txt b/mars.txt index b36abfd..0848c8d 100644 --- a/mars.txt +++ b/mars.txt @@ -1,3 +1,4 @@ Cold and dry, but everything is my favorite color The two moons may be a problem for Wolfman But the Mummy will appreciate the lack of humidity +An ill-considered change. which is the same as what you would get if you leave out HEAD (try it). The real goodness in all this is when you can refer to previous commits. We do that by adding ~1 (where “~” is “tilde”, pronounced [til-duh]) to refer to the commit one before HEAD. $ git diff HEAD~1 mars.txt . If we want to see the differences between older commits we can use git diff again, but with the notation HEAD~1, HEAD~2, and so on, to refer to them: . $ git diff HEAD~3 mars.txt . diff --git a/mars.txt b/mars.txt index df0654a..b36abfd 100644 --- a/mars.txt +++ b/mars.txt @@ -1 +1,4 @@ Cold and dry, but everything is my favorite color +The two moons may be a problem for Wolfman +But the Mummy will appreciate the lack of humidity +An ill-considered change . We could also use git show which shows us what changes we made at an older commit as well as the commit message, rather than the differences between a commit and our working directory that we see by using git diff. $ git show HEAD~3 mars.txt . commit f22b25e3233b4645dabd0d81e651fe074bd8e73b Author: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt; Date: Thu Aug 22 09:51:46 2013 -0400 Start notes on Mars as a base diff --git a/mars.txt b/mars.txt new file mode 100644 index 0000000..df0654a --- /dev/null +++ b/mars.txt @@ -0,0 +1 @@ +Cold and dry, but everything is my favorite color . In this way, we can build up a chain of commits. The most recent end of the chain is referred to as HEAD; we can refer to previous commits using the ~ notation, so HEAD~1 means “the previous commit”, while HEAD~123 goes back 123 commits from where we are now. We can also refer to commits using those long strings of digits and letters that git log displays. These are unique IDs for the changes, and “unique” really does mean unique: every change to any set of files on any computer has a unique 40-character identifier. Our first commit was given the ID f22b25e3233b4645dabd0d81e651fe074bd8e73b, so let’s try this: . $ git diff f22b25e3233b4645dabd0d81e651fe074bd8e73b mars.txt . diff --git a/mars.txt b/mars.txt index df0654a..93a3e13 100644 --- a/mars.txt +++ b/mars.txt @@ -1 +1,4 @@ Cold and dry, but everything is my favorite color +The two moons may be a problem for Wolfman +But the Mummy will appreciate the lack of humidity +An ill-considered change . That’s the right answer, but typing out random 40-character strings is annoying, so Git lets us use just the first few characters (typically seven for normal size projects): . $ git diff f22b25e mars.txt . diff --git a/mars.txt b/mars.txt index df0654a..93a3e13 100644 --- a/mars.txt +++ b/mars.txt @@ -1 +1,4 @@ Cold and dry, but everything is my favorite color +The two moons may be a problem for Wolfman +But the Mummy will appreciate the lack of humidity +An ill-considered change . All right! So we can save changes to files and see what we’ve changed. Now, how can we restore older versions of things? Let’s suppose we change our mind about the last update to mars.txt (the “ill-considered change”). git status now tells us that the file has been changed, but those changes haven’t been staged: . $ git status . On branch main Changes not staged for commit: (use \"git add &lt;file&gt;...\" to update what will be committed) (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory) modified: mars.txt no changes added to commit (use \"git add\" and/or \"git commit -a\") . We can put things back the way they were by using git checkout: . $ git checkout HEAD mars.txt $ cat mars.txt . Cold and dry, but everything is my favorite color The two moons may be a problem for Wolfman But the Mummy will appreciate the lack of humidity . As you might guess from its name, git checkout checks out (i.e., restores) an old version of a file. In this case, we’re telling Git that we want to recover the version of the file recorded in HEAD, which is the last saved commit. If we want to go back even further, we can use a commit identifier instead: . $ git checkout f22b25e mars.txt . $ cat mars.txt . Cold and dry, but everything is my favorite color . $ git status . On branch main Changes to be committed: (use \"git reset HEAD &lt;file&gt;...\" to unstage) modified: mars.txt . Notice that the changes are currently in the staging area. Again, we can put things back the way they were by using git checkout: . $ git checkout HEAD mars.txt . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/05-history.html#questions",
    "relUrl": "/Git_Materials/05-history.html#questions"
  },"186": {
    "doc": "Exploring History",
    "title": "Don’t Lose Your HEAD",
    "content": "Above we used . $ git checkout f22b25e mars.txt . to revert mars.txt to its state after the commit f22b25e. But be careful! The command checkout has other important functionalities and Git will misunderstand your intentions if you are not accurate with the typing. For example, if you forget mars.txt in the previous command. $ git checkout f22b25e . Note: checking out 'f22b25e'. You are in 'detached HEAD' state. You can look around, make experimental changes and commit them, and you can discard any commits you make in this state without impacting any branches by performing another checkout. If you want to create a new branch to retain commits you create, you may do so (now or later) by using -b with the checkout command again. Example: git checkout -b {new-branch-name} HEAD is now at f22b25e Start notes on Mars as a base . The “detached HEAD” is like “look, but don’t touch” here, so you shouldn’t make any changes in this state. After investigating your repo’s past state, reattach your HEAD with git checkout main. It’s important to remember that we must use the commit number that identifies the state of the repository before the change we’re trying to undo. A common mistake is to use the number of the commit in which we made the change we’re trying to discard. In the example below, we want to retrieve the state from before the most recent commit (HEAD~1), which is commit f22b25e: . So, to put it all together, here’s how Git works in cartoon form: . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/05-history.html#dont-lose-your-head",
    "relUrl": "/Git_Materials/05-history.html#dont-lose-your-head"
  },"187": {
    "doc": "Exploring History",
    "title": "Simplifying the Common Case",
    "content": "If you read the output of git status carefully, you’ll see that it includes this hint: . (use \"git checkout -- {file}...\" to discard changes in working directory) . As it says, git checkout without a version identifier restores files to the state saved in HEAD. The double dash -- is needed to separate the names of the files being recovered from the command itself: without it, Git would try to use the name of the file as the commit identifier. The fact that files can be reverted one by one tends to change the way people organize their work. If everything is in one large document, it’s hard (but not impossible) to undo changes to the introduction without also undoing changes made later to the conclusion. If the introduction and conclusion are stored in separate files, on the other hand, moving backward and forward in time becomes much easier. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/05-history.html#simplifying-the-common-case",
    "relUrl": "/Git_Materials/05-history.html#simplifying-the-common-case"
  },"188": {
    "doc": "Exploring History",
    "title": "Recovering Older Versions of a File",
    "content": "Jennifer has made changes to the Python script that she has been working on for weeks, and the modifications she made this morning “broke” the script and it no longer runs. She has spent ~ 1hr trying to fix it, with no luck… . Luckily, she has been keeping track of her project’s versions using Git! Which commands below will let her recover the last committed version of her Python script called data_cruncher.py? . | $ git checkout HEAD . | $ git checkout HEAD data_cruncher.py . | $ git checkout HEAD~1 data_cruncher.py . | $ git checkout &lt;unique ID of last commit&gt; data_cruncher.py . | Both 2 and 4 . | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/05-history.html#recovering-older-versions-of-a-file",
    "relUrl": "/Git_Materials/05-history.html#recovering-older-versions-of-a-file"
  },"189": {
    "doc": "Exploring History",
    "title": "Solution",
    "content": "The answer is (5)-Both 2 and 4. The checkout command restores files from the repository, overwriting the files in your working directory. Answers 2 and 4 both restore the latest version in the repository of the file data_cruncher.py. Answer 2 uses HEAD to indicate the latest, whereas answer 4 uses the unique ID of the last commit, which is what HEAD means. Answer 3 gets the version of data_cruncher.py from the commit before HEAD, which is NOT what we wanted. Answer 1 can be dangerous! Without a filename, git checkout will restore all files in the current directory (and all directories below it) to their state at the commit specified. This command will restore data_cruncher.py to the latest commit version, but it will also restore any other files that are changed to that version, erasing any changes you may have made to those files! As discussed above, you are left in a detached HEAD state, and you don’t want to be there. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/05-history.html#solution",
    "relUrl": "/Git_Materials/05-history.html#solution"
  },"190": {
    "doc": "Exploring History",
    "title": "Reverting a Commit",
    "content": "Jennifer is collaborating with colleagues on her Python script. She realizes her last commit to the project’s repository contained an error, and wants to undo it. Jennifer wants to undo correctly so everyone in the project’s repository gets the correct change. The command git revert [erroneous commit ID] will create a new commit that reverses the erroneous commit. The command git revert is different from git checkout [commit ID] because git checkout returns the files not yet committed within the local repository to a previous state, whereas git revert reverses changes committed to the local and project repositories. Below are the right steps and explanations for Jennifer to use git revert, what is the missing command? . | ________ # Look at the git history of the project to find the commit ID . | Copy the ID (the first few characters of the ID, e.g. 0b1d055). | git revert [commit ID] . | Type in the new commit message. | Save and close . | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/05-history.html#reverting-a-commit",
    "relUrl": "/Git_Materials/05-history.html#reverting-a-commit"
  },"191": {
    "doc": "Exploring History",
    "title": "Solution",
    "content": "The command git log lists project history with commit IDs. The command git show HEAD shows changes made at the latest commit, and lists the commit ID; however, Jennifer should double-check it is the correct commit, and no one else has committed changes to the repository. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/05-history.html#solution-1",
    "relUrl": "/Git_Materials/05-history.html#solution-1"
  },"192": {
    "doc": "Exploring History",
    "title": "Understanding Workflow and History",
    "content": "What is the output of the last command in . $ cd planets $ echo \"Venus is beautiful and full of love\" &gt; venus.txt $ git add venus.txt $ echo \"Venus is too hot to be suitable as a base\" &gt;&gt; venus.txt $ git commit -m \"Comment on Venus as an unsuitable base\" $ git checkout HEAD venus.txt $ cat venus.txt #this will print the contents of venus.txt to the screen . 1. Venus is too hot to be suitable as a base . 2. Venus is beautiful and full of love . 3. Venus is beautiful and full of love Venus is too hot to be suitable as a base . 4. Error because you have changed venus.txt without committing the changes . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/05-history.html#understanding-workflow-and-history",
    "relUrl": "/Git_Materials/05-history.html#understanding-workflow-and-history"
  },"193": {
    "doc": "Exploring History",
    "title": "Solution",
    "content": "The answer is 2. The command git add venus.txt places the current version of venus.txt into the staging area. The changes to the file from the second echo command are only applied to the working copy, not the version in the staging area. So, when git commit -m \"Comment on Venus as an unsuitable base\" is executed, the version of venus.txt committed to the repository is the one from the staging area and has only one line. At this time, the working copy still has the second line (and git status will show that the file is modified). However, git checkout HEAD venus.txt replaces the working copy with the most recently committed version of venus.txt. So, cat venus.txt will output . Venus is beautiful and full of love. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/05-history.html#solution-2",
    "relUrl": "/Git_Materials/05-history.html#solution-2"
  },"194": {
    "doc": "Exploring History",
    "title": "Checking Understanding of git diff",
    "content": "Consider this command: git diff HEAD~9 mars.txt. What do you predict this command will do if you execute it? What happens when you do execute it? Why? . Try another command, git diff [ID] mars.txt, where [ID] is replaced with the unique identifier for your most recent commit. What do you think will happen, and what does happen? . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/05-history.html#checking-understanding-of-git-diff",
    "relUrl": "/Git_Materials/05-history.html#checking-understanding-of-git-diff"
  },"195": {
    "doc": "Exploring History",
    "title": "Getting Rid of Staged Changes",
    "content": "git checkout can be used to restore a previous commit when unstaged changes have been made, but will it also work for changes that have been staged but not committed? Make a change to mars.txt, add that change using git add, then use git checkout to see if you can remove your change. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/05-history.html#getting-rid-of-staged-changes",
    "relUrl": "/Git_Materials/05-history.html#getting-rid-of-staged-changes"
  },"196": {
    "doc": "Exploring History",
    "title": "Solution",
    "content": "After adding a change, git checkout can not be used directly. Let’s look at the output of git status: . On branch main Changes to be committed: (use \"git reset HEAD {file}...\" to unstage) modified: mars.txt . Note that if you don’t have the same output you may either have forgotten to change the file, or you have added it and committed it. Using the command git checkout -- mars.txt now does not give an error, but it does not restore the file either. Git helpfully tells us that we need to use git reset first to unstage the file: . $ git reset HEAD mars.txt . Unstaged changes after reset: M mars.txt . Now, git status gives us: . $ git status . On branch main Changes not staged for commit: (use \"git add {file}...\" to update what will be committed) (use \"git checkout -- {file}...\" to discard changes in working directory) modified: mars.txt no changes added to commit (use \"git add\" and/or \"git commit -a\") . This means we can now use git checkout to restore the file to the previous commit: . $ git checkout -- mars.txt $ git status . On branch main nothing to commit, working tree clean . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/05-history.html#solution-3",
    "relUrl": "/Git_Materials/05-history.html#solution-3"
  },"197": {
    "doc": "Exploring History",
    "title": "Explore and Summarize Histories",
    "content": "Exploring history is an important part of Git, and often it is a challenge to find the right commit ID, especially if the commit is from several months ago. Imagine the planets project has more than 50 files. You would like to find a commit that modifies some specific text in mars.txt. When you type git log, a very long list appeared. How can you narrow down the search? . Recall that the git diff command allows us to explore one specific file, e.g., git diff mars.txt. We can apply a similar idea here. $ git log mars.txt . Unfortunately some of these commit messages are very ambiguous, e.g., update files. How can you search through these files? . Both git diff and git log are very useful and they summarize a different part of the history for you. Is it possible to combine both? Let’s try the following: . $ git log --patch mars.txt . You should get a long list of output, and you should be able to see both commit messages and the difference between each commit. Question: What does the following command do? . $ git log --patch HEAD~9 *.txt . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/05-history.html#explore-and-summarize-histories",
    "relUrl": "/Git_Materials/05-history.html#explore-and-summarize-histories"
  },"198": {
    "doc": "Exploring History",
    "title": "Keypoints",
    "content": ". | git diff displays differences between commits. | git checkout recovers old versions of files. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/05-history.html#keypoints",
    "relUrl": "/Git_Materials/05-history.html#keypoints"
  },"199": {
    "doc": "Libraries",
    "title": "Libraries",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/05-libraries.html",
    "relUrl": "/Python_Series_Materials/part_2/05-libraries.html"
  },"200": {
    "doc": "Libraries",
    "title": "Most of the power of a programming language is in its libraries.",
    "content": ". | A library is a collection of files (called modules) that contains functions for use by other programs. | May also contain data values (e.g., numerical constants) and other things. | Library’s contents are supposed to be related, but there’s no way to enforce that. | . | The Python standard library is an extensive suite of modules that comes with Python itself. | Many additional libraries are available from PyPI (the Python Package Index). | We will see later how to write new libraries. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/05-libraries.html#most-of-the-power-of-a-programming-language-is-in-its-libraries",
    "relUrl": "/Python_Series_Materials/part_2/05-libraries.html#most-of-the-power-of-a-programming-language-is-in-its-libraries"
  },"201": {
    "doc": "Libraries",
    "title": "Libraries and modules",
    "content": "A library is a collection of modules, but the terms are often used interchangeably, especially since many libraries only consist of a single module, so don’t worry if you mix them. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/05-libraries.html#libraries-and-modules",
    "relUrl": "/Python_Series_Materials/part_2/05-libraries.html#libraries-and-modules"
  },"202": {
    "doc": "Libraries",
    "title": "A program must import a library module before using it.",
    "content": ". | Use import to load a library module into a program’s memory. | Then refer to things from the module as module_name.thing_name. | Python uses . to mean “part of”. | . | Using math, one of the modules in the standard library: | . import math print('pi is', math.pi) print('cos(pi) is', math.cos(math.pi)) . pi is 3.141592653589793 cos(pi) is -1.0 . | Have to refer to each item with the module’s name. | math.cos(pi) won’t work: the reference to pi doesn’t somehow “inherit” the function’s reference to math. | . | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/05-libraries.html#a-program-must-import-a-library-module-before-using-it",
    "relUrl": "/Python_Series_Materials/part_2/05-libraries.html#a-program-must-import-a-library-module-before-using-it"
  },"203": {
    "doc": "Libraries",
    "title": "Use help to learn about the contents of a library module.",
    "content": ". | Works just like help for a function. | . help(math) . Help on module math: NAME math MODULE REFERENCE http://docs.python.org/3/library/math The following documentation is automatically generated from the Python source files. It may be incomplete, incorrect or include features that are considered implementation detail and may vary between Python implementations. When in doubt, consult the module reference at the location listed above. DESCRIPTION This module is always available. It provides access to the mathematical functions defined by the C standard. FUNCTIONS acos(x, /) Return the arc cosine (measured in radians) of x. ⋮ ⋮ ⋮ . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/05-libraries.html#use-help-to-learn-about-the-contents-of-a-library-module",
    "relUrl": "/Python_Series_Materials/part_2/05-libraries.html#use-help-to-learn-about-the-contents-of-a-library-module"
  },"204": {
    "doc": "Libraries",
    "title": "Import specific items from a library module to shorten programs.",
    "content": ". | Use from ... import ... to load only specific items from a library module. | Then refer to them directly without library name as prefix. | . from math import cos, pi print('cos(pi) is', cos(pi)) . cos(pi) is -1.0 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/05-libraries.html#import-specific-items-from-a-library-module-to-shorten-programs",
    "relUrl": "/Python_Series_Materials/part_2/05-libraries.html#import-specific-items-from-a-library-module-to-shorten-programs"
  },"205": {
    "doc": "Libraries",
    "title": "Create an alias for a library module when importing it to shorten programs.",
    "content": ". | Use import ... as ... to give a library a short alias while importing it. | Then refer to items in the library using that shortened name. | . import math as m print('cos(pi) is', m.cos(m.pi)) . cos(pi) is -1.0 . | Commonly used for libraries that are frequently used or have long names. | E.g., the matplotlib plotting library is often aliased as mpl. | . | But can make programs harder to understand, since readers must learn your program’s aliases. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/05-libraries.html#create-an-alias-for-a-library-module-when-importing-it-to-shorten-programs",
    "relUrl": "/Python_Series_Materials/part_2/05-libraries.html#create-an-alias-for-a-library-module-when-importing-it-to-shorten-programs"
  },"206": {
    "doc": "Libraries",
    "title": "Exploring the Math Module",
    "content": ". | What function from the math module can you use to calculate a square root without using sqrt? | Since the library contains this function, why does sqrt exist? | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/05-libraries.html#exploring-the-math-module",
    "relUrl": "/Python_Series_Materials/part_2/05-libraries.html#exploring-the-math-module"
  },"207": {
    "doc": "Libraries",
    "title": "Solution",
    "content": ". | Using help(math) we see that we’ve got pow(x,y) in addition to sqrt(x), so we could use pow(x, 0.5) to find a square root. | The sqrt(x) function is arguably more readable than pow(x, 0.5) when implementing equations. Readability is a cornerstone of good programming, so it makes sense to provide a special function for this specific common case. Also, the design of Python’s math library has its origin in the C standard, which includes both sqrt(x) and pow(x,y), so a little bit of the history of programming is showing in Python’s function names. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/05-libraries.html#solution",
    "relUrl": "/Python_Series_Materials/part_2/05-libraries.html#solution"
  },"208": {
    "doc": "Libraries",
    "title": "Locating the Right Module",
    "content": "You want to select a random character from a string: . bases = 'ACTTGCTTGAC' . | Which standard library module could help you? | Which function would you select from that module? Are there alternatives? | Try to write a program that uses the function. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/05-libraries.html#locating-the-right-module",
    "relUrl": "/Python_Series_Materials/part_2/05-libraries.html#locating-the-right-module"
  },"209": {
    "doc": "Libraries",
    "title": "Solution",
    "content": "The random module seems like it could help. The string has 11 characters, each having a positional index from 0 to 10. You could use the random.randrange or random.randint functions to get a random integer between 0 and 10, and then select the bases character at that index: . from random import randrange random_index = randrange(len(bases)) print(bases[random_index]) . or more compactly: . from random import randrange print(bases[randrange(len(bases))]) . Perhaps you found the random.sample function? It allows for slightly less typing but might be a bit harder to understand just by reading: . from random import sample print(sample(bases, 1)[0]) . Note that this function returns a list of values. We will learn about lists in episode 11. The simplest and shortest solution is the random.choice function that does exactly what we want: . from random import choice print(choice(bases)) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/05-libraries.html#solution-1",
    "relUrl": "/Python_Series_Materials/part_2/05-libraries.html#solution-1"
  },"210": {
    "doc": "Libraries",
    "title": "Jigsaw Puzzle (Parson’s Problem) Programming Example",
    "content": "Rearrange the following statements so that a random DNA base is printed and its index in the string. Not all statements may be needed. Feel free to use/add intermediate variables. bases=\"ACTTGCTTGAC\" import math import random ___ = random.randrange(n_bases) ___ = len(bases) print(\"random base \", bases[___], \"base index\", ___) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/05-libraries.html#jigsaw-puzzle-parsons-problem-programming-example",
    "relUrl": "/Python_Series_Materials/part_2/05-libraries.html#jigsaw-puzzle-parsons-problem-programming-example"
  },"211": {
    "doc": "Libraries",
    "title": "Solution",
    "content": "import math import random bases = \"ACTTGCTTGAC\" n_bases = len(bases) idx = random.randrange(n_bases) print(\"random base\", bases[idx], \"base index\", idx) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/05-libraries.html#solution-2",
    "relUrl": "/Python_Series_Materials/part_2/05-libraries.html#solution-2"
  },"212": {
    "doc": "Libraries",
    "title": "When Is Help Available?",
    "content": "When a colleague of yours types help(math), Python reports an error: . NameError: name 'math' is not defined . What has your colleague forgotten to do? . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/05-libraries.html#when-is-help-available",
    "relUrl": "/Python_Series_Materials/part_2/05-libraries.html#when-is-help-available"
  },"213": {
    "doc": "Libraries",
    "title": "Solution",
    "content": "Importing the math module (import math) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/05-libraries.html#solution-3",
    "relUrl": "/Python_Series_Materials/part_2/05-libraries.html#solution-3"
  },"214": {
    "doc": "Libraries",
    "title": "Importing With Aliases",
    "content": ". | Fill in the blanks so that the program below prints 90.0. | Rewrite the program so that it uses import without as. | Which form do you find easier to read? | . import math as m angle = ____.degrees(____.pi / 2) print(____) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/05-libraries.html#importing-with-aliases",
    "relUrl": "/Python_Series_Materials/part_2/05-libraries.html#importing-with-aliases"
  },"215": {
    "doc": "Libraries",
    "title": "Solution",
    "content": "import math as m angle = m.degrees(m.pi / 2) print(angle) . can be written as . import math angle = math.degrees(math.pi / 2) print(angle) . Since you just wrote the code and are familiar with it, you might actually find the first version easier to read. But when trying to read a huge piece of code written by someone else, or when getting back to your own huge piece of code after several months, non-abbreviated names are often easier, except where there are clear abbreviation conventions. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/05-libraries.html#solution-4",
    "relUrl": "/Python_Series_Materials/part_2/05-libraries.html#solution-4"
  },"216": {
    "doc": "Libraries",
    "title": "There Are Many Ways To Import Libraries!",
    "content": "Match the following print statements with the appropriate library calls. Print commands: . | print(\"sin(pi/2) =\", sin(pi/2)) | print(\"sin(pi/2) =\", m.sin(m.pi/2)) | print(\"sin(pi/2) =\", math.sin(math.pi/2)) | . Library calls: . | from math import sin, pi | import math | import math as m | from math import * | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/05-libraries.html#there-are-many-ways-to-import-libraries",
    "relUrl": "/Python_Series_Materials/part_2/05-libraries.html#there-are-many-ways-to-import-libraries"
  },"217": {
    "doc": "Libraries",
    "title": "Solution",
    "content": ". | Library calls 1 and 4. In order to directly refer to sin and pi without the library name as prefix, you need to use the from ... import ... statement. Whereas library call 1 specifically imports the two functions sin and pi, library call 4 imports all functions in the math module. | Library call 3. Here sin and pi are referred to with a shortened library name m instead of math. Library call 3 does exactly that using the import ... as ... syntax - it creates an alias for math in the form of the shortened name m. | Library call 2. Here sin and pi are referred to with the regular library name math, so the regular import ... call suffices. | . Note: although library call 4 works, importing all names from a module using a wildcard import is not recommended as it makes it unclear which names from the module are used in the code. In general it is best to make your imports as specific as possible and to only import what your code uses. In library call 1, the import statement explicitly tells us that the sin function is imported from the math module, but library call 4 does not convey this information. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/05-libraries.html#solution-5",
    "relUrl": "/Python_Series_Materials/part_2/05-libraries.html#solution-5"
  },"218": {
    "doc": "Libraries",
    "title": "Importing Specific Items",
    "content": ". | Fill in the blanks so that the program below prints 90.0. | Do you find this version easier to read than preceding ones? | Why wouldn’t programmers always use this form of import? | . ____ math import ____, ____ angle = degrees(pi / 2) print(angle) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/05-libraries.html#importing-specific-items",
    "relUrl": "/Python_Series_Materials/part_2/05-libraries.html#importing-specific-items"
  },"219": {
    "doc": "Libraries",
    "title": "Solution",
    "content": "from math import degrees, pi angle = degrees(pi / 2) print(angle) . Most likely you find this version easier to read since it’s less dense. The main reason not to use this form of import is to avoid name clashes. For instance, you wouldn’t import degrees this way if you also wanted to use the name degrees for a variable or function of your own. Or if you were to also import a function named degrees from another library. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/05-libraries.html#solution-6",
    "relUrl": "/Python_Series_Materials/part_2/05-libraries.html#solution-6"
  },"220": {
    "doc": "Libraries",
    "title": "Reading Error Messages",
    "content": ". | Read the code below and try to identify what the errors are without running it. | Run the code, and read the error message. What type of error is it? | . from math import log log(0) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/05-libraries.html#reading-error-messages",
    "relUrl": "/Python_Series_Materials/part_2/05-libraries.html#reading-error-messages"
  },"221": {
    "doc": "Libraries",
    "title": "Solution",
    "content": "--------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-1-d72e1d780bab&gt; in &lt;module&gt; 1 from math import log ----&gt; 2 log(0) ValueError: math domain error . | The logarithm of x is only defined for x &gt; 0, so 0 is outside the domain of the function. | You get an error of type ValueError, indicating that the function received an inappropriate argument value. The additional message “math domain error” makes it clearer what the problem is. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/05-libraries.html#solution-7",
    "relUrl": "/Python_Series_Materials/part_2/05-libraries.html#solution-7"
  },"222": {
    "doc": "Extracting JSON script and shutting down OpenRefine",
    "title": "Extract a JSON script to reproduce your steps with another data file",
    "content": ". | If you have a similarly structured dataset – perhaps for a different snapshot in time – and want to perform the same steps, we can extract a JSON script for future use. Click on the Undo/Redo tab and click on Extract. Choose the steps you want to repeat. Copy the code and save it in a text file to keep a copy of your steps. Later if you load up your new dataset, you could go back to the Undo/Redo tab and select Apply and paste in this code into the window to run those steps on the new dataset. | . Activity 4 . Start up a new project and load the citizen science dataset again. Apply the JSON code that we just copied by going to the Undo/Redo tab, clicking Apply and copying and pasting the code into the window. Click Perform Operations. ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt2_citizen_science/05_extract-export.html#extract-a-json-script-to-reproduce-your-steps-with-another-data-file",
    "relUrl": "/OpenRefine_Materials/pt2_citizen_science/05_extract-export.html#extract-a-json-script-to-reproduce-your-steps-with-another-data-file"
  },"223": {
    "doc": "Extracting JSON script and shutting down OpenRefine",
    "title": "Shutting down OpenRefine",
    "content": ". | To ensure that all of your steps are saved, it is important to properly shut down OpenRefine. | On a PC, hit Control-C on your keyboard. | On a Mac, go to the OpenRefine app in the doc and choose Quit. | . | . ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt2_citizen_science/05_extract-export.html#shutting-down-openrefine",
    "relUrl": "/OpenRefine_Materials/pt2_citizen_science/05_extract-export.html#shutting-down-openrefine"
  },"224": {
    "doc": "Extracting JSON script and shutting down OpenRefine",
    "title": "Extracting JSON script and shutting down OpenRefine",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt2_citizen_science/05_extract-export.html",
    "relUrl": "/OpenRefine_Materials/pt2_citizen_science/05_extract-export.html"
  },"225": {
    "doc": "Transposing data",
    "title": "Transpose the data from wide format to long format",
    "content": ". | Wide vs. Long format: The dataset is currently in “wide” format with years across as columns. We should convert it to “long” format to work with it using numeric facets. Converting to long format will put all the years into one column as a ‘Year’ variable, and all the numeric data values into a second column. | Transpose the data to long format: Remove an facets you have in place. From the 2017 column pull down menu, select Transpose -&gt; Transpose cells across columns into rows….The Transpose window appears. You are going to put the data from the 8 numeric data columns (named 2010 through 2017) into two columns, one containing the year, and one containing the numeric data value (representing an expenditure amount). For the From column, choose 2010. For the To column choose 2017 (or last column, either will work). In the Transpose into section, we will use the Two new columns option. The Key Column will be the years – call it Year. Give the Value Column the name Per_capita_expenditure. Check the Fill down in other columns option. Click Transpose. | . Note: For each state, for each expenditure type, we now have 8 separate rows, one for each year. Notice the dataset now has 9792 rows, compared to 1227 before transposing. It has fewer columns, but many more rows – this is why it is referred to as a “long” format. Long format can be useful for certain types of data analyses, where all your data measuring the same thing (e.g., per capita expenditures) need to be in one column instead of spread over many. ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt1_expenditure/05_transpose.html#transpose-the-data-from-wide-format-to-long-format",
    "relUrl": "/OpenRefine_Materials/pt1_expenditure/05_transpose.html#transpose-the-data-from-wide-format-to-long-format"
  },"226": {
    "doc": "Transposing data",
    "title": "Transposing data",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt1_expenditure/05_transpose.html",
    "relUrl": "/OpenRefine_Materials/pt1_expenditure/05_transpose.html"
  },"227": {
    "doc": "Ignoring Things",
    "title": "Ignoring Things",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/06-ignore.html",
    "relUrl": "/Git_Materials/06-ignore.html"
  },"228": {
    "doc": "Ignoring Things",
    "title": "Objectives",
    "content": ". | Configure Git to ignore specific files. | Explain why ignoring files can be useful. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/06-ignore.html#objectives",
    "relUrl": "/Git_Materials/06-ignore.html#objectives"
  },"229": {
    "doc": "Ignoring Things",
    "title": "Questions",
    "content": ". | How can I tell Git to ignore files I don’t want to track? | . What if we have files that we do not want Git to track for us, like backup files created by our editor or intermediate files created during data analysis? Let’s create a few dummy files: . $ mkdir results $ touch a.dat b.dat c.dat results/a.out results/b.out . and see what Git says: . $ git status . On branch main Untracked files: (use \"git add &lt;file&gt;...\" to include in what will be committed) a.dat b.dat c.dat results/ nothing added to commit but untracked files present (use \"git add\" to track) . Putting these files under version control would be a waste of disk space. What’s worse, having them all listed could distract us from changes that actually matter, so let’s tell Git to ignore them. We do this by creating a file in the root directory of our project called .gitignore: . $ nano .gitignore $ cat .gitignore . *.dat results/ . These patterns tell Git to ignore any file whose name ends in .dat and everything in the results directory. (If any of these files were already being tracked, Git would continue to track them.) . Once we have created this file, the output of git status is much cleaner: . $ git status . On branch main Untracked files: (use \"git add &lt;file&gt;...\" to include in what will be committed) .gitignore nothing added to commit but untracked files present (use \"git add\" to track) . The only thing Git notices now is the newly-created .gitignore file. You might think we wouldn’t want to track it, but everyone we’re sharing our repository with will probably want to ignore the same things that we’re ignoring. Let’s add and commit .gitignore: . $ git add .gitignore $ git commit -m \"Ignore data files and the results folder\" $ git status . On branch main nothing to commit, working tree clean . As a bonus, using .gitignore helps us avoid accidentally adding files to the repository that we don’t want to track: . $ git add a.dat . The following paths are ignored by one of your .gitignore files: a.dat Use -f if you really want to add them. If we really want to override our ignore settings, we can use git add -f to force Git to add something. For example, git add -f a.dat. We can also always see the status of ignored files if we want: . $ git status --ignored . On branch main Ignored files: (use \"git add -f &lt;file&gt;...\" to include in what will be committed) a.dat b.dat c.dat results/ nothing to commit, working tree clean . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/06-ignore.html#questions",
    "relUrl": "/Git_Materials/06-ignore.html#questions"
  },"230": {
    "doc": "Ignoring Things",
    "title": "Ignoring Nested Files",
    "content": "Given a directory structure that looks like: . results/data results/plots . How would you ignore only results/plots and not results/data? . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/06-ignore.html#ignoring-nested-files",
    "relUrl": "/Git_Materials/06-ignore.html#ignoring-nested-files"
  },"231": {
    "doc": "Ignoring Things",
    "title": "Solution",
    "content": "If you only want to ignore the contents of results/plots, you can change your .gitignore to ignore only the /plots/ subfolder by adding the following line to your .gitignore: . results/plots/ . This line will ensure only the contents of results/plots is ignored, and not the contents of results/data. As with most programming issues, there are a few alternative ways that one may ensure this ignore rule is followed. The “Ignoring Nested Files: Variation” exercise has a slightly different directory structure that presents an alternative solution. Further, the discussion page has more detail on ignore rules. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/06-ignore.html#solution",
    "relUrl": "/Git_Materials/06-ignore.html#solution"
  },"232": {
    "doc": "Ignoring Things",
    "title": "Including Specific Files",
    "content": "How would you ignore all .dat files in your root directory except for final.dat? Hint: Find out what ! (the exclamation point operator) does . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/06-ignore.html#including-specific-files",
    "relUrl": "/Git_Materials/06-ignore.html#including-specific-files"
  },"233": {
    "doc": "Ignoring Things",
    "title": "Solution",
    "content": "You would add the following two lines to your .gitignore: . *.dat # ignore all data files !final.dat # except final.data . The exclamation point operator will include a previously excluded entry. Note also that because you’ve previously committed .dat files in this lesson they will not be ignored with this new rule. Only future additions of .dat files added to the root directory will be ignored. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/06-ignore.html#solution-1",
    "relUrl": "/Git_Materials/06-ignore.html#solution-1"
  },"234": {
    "doc": "Ignoring Things",
    "title": "Ignoring Nested Files: Variation",
    "content": "Given a directory structure that looks similar to the earlier Nested Files exercise, but with a slightly different directory structure: . results/data results/images results/plots results/analysis . How would you ignore all of the contents in the results folder, but not results/data? . Hint: think a bit about how you created an exception with the ! operator before. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/06-ignore.html#ignoring-nested-files-variation",
    "relUrl": "/Git_Materials/06-ignore.html#ignoring-nested-files-variation"
  },"235": {
    "doc": "Ignoring Things",
    "title": "Solution",
    "content": "If you want to ignore the contents of results/ but not those of results/data/, you can change your .gitignore to ignore the contents of results folder, but create an exception for the contents of the results/data subfolder. Your .gitignore would look like this: . results/* # ignore everything in results folder !results/data/ # do not ignore results/data/ contents . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/06-ignore.html#solution-2",
    "relUrl": "/Git_Materials/06-ignore.html#solution-2"
  },"236": {
    "doc": "Ignoring Things",
    "title": "Ignoring all data Files in a Directory",
    "content": "Assuming you have an empty .gitignore file, and given a directory structure that looks like: . results/data/position/gps/a.dat results/data/position/gps/b.dat results/data/position/gps/c.dat results/data/position/gps/info.txt results/plots . What’s the shortest .gitignore rule you could write to ignore all .dat files in result/data/position/gps? Do not ignore the info.txt. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/06-ignore.html#ignoring-all-data-files-in-a-directory",
    "relUrl": "/Git_Materials/06-ignore.html#ignoring-all-data-files-in-a-directory"
  },"237": {
    "doc": "Ignoring Things",
    "title": "Solution",
    "content": "Appending results/data/position/gps/*.dat will match every file in results/data/position/gps that ends with .dat. The file results/data/position/gps/info.txt will not be ignored. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/06-ignore.html#solution-3",
    "relUrl": "/Git_Materials/06-ignore.html#solution-3"
  },"238": {
    "doc": "Ignoring Things",
    "title": "Ignoring all data Files in the repository",
    "content": "Let us assume you have many .dat files in different subdirectories of your repository. For example, you might have: . results/a.dat data/experiment_1/b.dat data/experiment_2/c.dat data/experiment_2/variation_1/d.dat . How do you ignore all the .dat files, without explicitly listing the names of the corresponding folders? . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/06-ignore.html#ignoring-all-data-files-in-the-repository",
    "relUrl": "/Git_Materials/06-ignore.html#ignoring-all-data-files-in-the-repository"
  },"239": {
    "doc": "Ignoring Things",
    "title": "Solution",
    "content": "In the .gitignore file, write: . **/*.dat . This will ignore all the .dat files, regardless of their position in the directory tree. You can still include some specific exception with the exclamation point operator. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/06-ignore.html#solution-4",
    "relUrl": "/Git_Materials/06-ignore.html#solution-4"
  },"240": {
    "doc": "Ignoring Things",
    "title": "The Order of Rules",
    "content": "Given a .gitignore file with the following contents: . *.dat !*.dat . What will be the result? . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/06-ignore.html#the-order-of-rules",
    "relUrl": "/Git_Materials/06-ignore.html#the-order-of-rules"
  },"241": {
    "doc": "Ignoring Things",
    "title": "Solution",
    "content": "The ! modifier will negate an entry from a previously defined ignore pattern. Because the !*.dat entry negates all of the previous .dat files in the .gitignore, none of them will be ignored, and all .dat files will be tracked. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/06-ignore.html#solution-5",
    "relUrl": "/Git_Materials/06-ignore.html#solution-5"
  },"242": {
    "doc": "Ignoring Things",
    "title": "Log Files",
    "content": "You wrote a script that creates many intermediate log-files of the form log_01, log_02, log_03, etc. You want to keep them but you do not want to track them through git. | Write one .gitignore entry that excludes files of the form log_01, log_02, etc. | Test your “ignore pattern” by creating some dummy files of the form log_01, etc. | You find that the file log_01 is very important after all, add it to the tracked files without changing the .gitignore again. | Discuss with your neighbor what other types of files could reside in your directory that you do not want to track and thus would exclude via .gitignore. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/06-ignore.html#log-files",
    "relUrl": "/Git_Materials/06-ignore.html#log-files"
  },"243": {
    "doc": "Ignoring Things",
    "title": "Solution",
    "content": ". | append either log_* or log* as a new entry in your .gitignore | track log_01 using git add -f log_01 | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/06-ignore.html#solution-6",
    "relUrl": "/Git_Materials/06-ignore.html#solution-6"
  },"244": {
    "doc": "Ignoring Things",
    "title": "Keypoints",
    "content": ". | The .gitignore file tells Git what files to ignore. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/06-ignore.html#keypoints",
    "relUrl": "/Git_Materials/06-ignore.html#keypoints"
  },"245": {
    "doc": "Reading Tabular Data into DataFrames",
    "title": "Reading Tabular Data into DataFrames",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/06-reading-tabular.html",
    "relUrl": "/Python_Series_Materials/part_2/06-reading-tabular.html"
  },"246": {
    "doc": "Reading Tabular Data into DataFrames",
    "title": "Use the Pandas library to do statistics on tabular data.",
    "content": ". | Pandas is a widely-used Python library for statistics, particularly on tabular data. | Borrows many features from R’s dataframes. | A 2-dimensional table whose columns have names and potentially have different data types. | . | Load it with import pandas as pd. The alias pd is commonly used for Pandas. | Read a Comma Separated Values (CSV) data file with pd.read_csv. | Argument is the name of the file to be read. | Assign result to a variable to store the data that was read. | . | . import pandas as pd data = pd.read_csv('data/gapminder_gdp_oceania.csv') print(data) . country gdpPercap_1952 gdpPercap_1957 gdpPercap_1962 \\ 0 Australia 10039.59564 10949.64959 12217.22686 1 New Zealand 10556.57566 12247.39532 13175.67800 gdpPercap_1967 gdpPercap_1972 gdpPercap_1977 gdpPercap_1982 \\ 0 14526.12465 16788.62948 18334.19751 19477.00928 1 14463.91893 16046.03728 16233.71770 17632.41040 gdpPercap_1987 gdpPercap_1992 gdpPercap_1997 gdpPercap_2002 \\ 0 21888.88903 23424.76683 26997.93657 30687.75473 1 19007.19129 18363.32494 21050.41377 23189.80135 gdpPercap_2007 0 34435.36744 1 25185.00911 . | The columns in a dataframe are the observed variables, and the rows are the observations. | Pandas uses backslash \\ to show wrapped lines when output is too wide to fit the screen. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/06-reading-tabular.html#use-the-pandas-library-to-do-statistics-on-tabular-data",
    "relUrl": "/Python_Series_Materials/part_2/06-reading-tabular.html#use-the-pandas-library-to-do-statistics-on-tabular-data"
  },"247": {
    "doc": "Reading Tabular Data into DataFrames",
    "title": "File Not Found",
    "content": "Our lessons store their data files in a data sub-directory, which is why the path to the file is data/gapminder_gdp_oceania.csv. If you forget to include data/, or if you include it but your copy of the file is somewhere else, you will get a runtime error that ends with a line like this: . FileNotFoundError: [Errno 2] No such file or directory: 'data/gapminder_gdp_oceania.csv' . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/06-reading-tabular.html#file-not-found",
    "relUrl": "/Python_Series_Materials/part_2/06-reading-tabular.html#file-not-found"
  },"248": {
    "doc": "Reading Tabular Data into DataFrames",
    "title": "Use index_col to specify that a column’s values should be used as row headings.",
    "content": ". | Row headings are numbers (0 and 1 in this case). | Really want to index by country. | Pass the name of the column to read_csv as its index_col parameter to do this. | . data = pd.read_csv('data/gapminder_gdp_oceania.csv', index_col='country') print(data) . gdpPercap_1952 gdpPercap_1957 gdpPercap_1962 gdpPercap_1967 \\ country Australia 10039.59564 10949.64959 12217.22686 14526.12465 New Zealand 10556.57566 12247.39532 13175.67800 14463.91893 gdpPercap_1972 gdpPercap_1977 gdpPercap_1982 gdpPercap_1987 \\ country Australia 16788.62948 18334.19751 19477.00928 21888.88903 New Zealand 16046.03728 16233.71770 17632.41040 19007.19129 gdpPercap_1992 gdpPercap_1997 gdpPercap_2002 gdpPercap_2007 country Australia 23424.76683 26997.93657 30687.75473 34435.36744 New Zealand 18363.32494 21050.41377 23189.80135 25185.00911 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/06-reading-tabular.html#use-index_col-to-specify-that-a-columns-values-should-be-used-as-row-headings",
    "relUrl": "/Python_Series_Materials/part_2/06-reading-tabular.html#use-index_col-to-specify-that-a-columns-values-should-be-used-as-row-headings"
  },"249": {
    "doc": "Reading Tabular Data into DataFrames",
    "title": "Use the DataFrame.info() method to find out more about a dataframe.",
    "content": "data.info() . &lt;class 'pandas.core.frame.DataFrame'&gt; Index: 2 entries, Australia to New Zealand Data columns (total 12 columns): gdpPercap_1952 2 non-null float64 gdpPercap_1957 2 non-null float64 gdpPercap_1962 2 non-null float64 gdpPercap_1967 2 non-null float64 gdpPercap_1972 2 non-null float64 gdpPercap_1977 2 non-null float64 gdpPercap_1982 2 non-null float64 gdpPercap_1987 2 non-null float64 gdpPercap_1992 2 non-null float64 gdpPercap_1997 2 non-null float64 gdpPercap_2002 2 non-null float64 gdpPercap_2007 2 non-null float64 dtypes: float64(12) memory usage: 208.0+ bytes . | This is a DataFrame | Two rows named 'Australia' and 'New Zealand' | Twelve columns, each of which has two actual 64-bit floating point values. | We will talk later about null values, which are used to represent missing observations. | . | Uses 208 bytes of memory. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/06-reading-tabular.html#use-the-dataframeinfo-method-to-find-out-more-about-a-dataframe",
    "relUrl": "/Python_Series_Materials/part_2/06-reading-tabular.html#use-the-dataframeinfo-method-to-find-out-more-about-a-dataframe"
  },"250": {
    "doc": "Reading Tabular Data into DataFrames",
    "title": "The DataFrame.columns variable stores information about the dataframe’s columns.",
    "content": ". | Note that this is data, not a method. (It doesn’t have parentheses.) . | Like math.pi. | So do not use () to try to call it. | . | Called a member variable, or just member. | . print(data.columns) . Index(['gdpPercap_1952', 'gdpPercap_1957', 'gdpPercap_1962', 'gdpPercap_1967', 'gdpPercap_1972', 'gdpPercap_1977', 'gdpPercap_1982', 'gdpPercap_1987', 'gdpPercap_1992', 'gdpPercap_1997', 'gdpPercap_2002', 'gdpPercap_2007'], dtype='object') . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/06-reading-tabular.html#the-dataframecolumns-variable-stores-information-about-the-dataframes-columns",
    "relUrl": "/Python_Series_Materials/part_2/06-reading-tabular.html#the-dataframecolumns-variable-stores-information-about-the-dataframes-columns"
  },"251": {
    "doc": "Reading Tabular Data into DataFrames",
    "title": "Use DataFrame.T to transpose a dataframe.",
    "content": ". | Sometimes want to treat columns as rows and vice versa. | Transpose (written .T) doesn’t copy the data, just changes the program’s view of it. | Like columns, it is a member variable. | . print(data.T) . country Australia New Zealand gdpPercap_1952 10039.59564 10556.57566 gdpPercap_1957 10949.64959 12247.39532 gdpPercap_1962 12217.22686 13175.67800 gdpPercap_1967 14526.12465 14463.91893 gdpPercap_1972 16788.62948 16046.03728 gdpPercap_1977 18334.19751 16233.71770 gdpPercap_1982 19477.00928 17632.41040 gdpPercap_1987 21888.88903 19007.19129 gdpPercap_1992 23424.76683 18363.32494 gdpPercap_1997 26997.93657 21050.41377 gdpPercap_2002 30687.75473 23189.80135 gdpPercap_2007 34435.36744 25185.00911 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/06-reading-tabular.html#use-dataframet-to-transpose-a-dataframe",
    "relUrl": "/Python_Series_Materials/part_2/06-reading-tabular.html#use-dataframet-to-transpose-a-dataframe"
  },"252": {
    "doc": "Reading Tabular Data into DataFrames",
    "title": "Use DataFrame.describe() to get summary statistics about data.",
    "content": "DataFrame.describe() gets the summary statistics of only the columns that have numerical data. All other columns are ignored, unless you use the argument include='all'. print(data.describe()) . gdpPercap_1952 gdpPercap_1957 gdpPercap_1962 gdpPercap_1967 \\ count 2.000000 2.000000 2.000000 2.000000 mean 10298.085650 11598.522455 12696.452430 14495.021790 std 365.560078 917.644806 677.727301 43.986086 min 10039.595640 10949.649590 12217.226860 14463.918930 25% 10168.840645 11274.086022 12456.839645 14479.470360 50% 10298.085650 11598.522455 12696.452430 14495.021790 75% 10427.330655 11922.958888 12936.065215 14510.573220 max 10556.575660 12247.395320 13175.678000 14526.124650 gdpPercap_1972 gdpPercap_1977 gdpPercap_1982 gdpPercap_1987 \\ count 2.00000 2.000000 2.000000 2.000000 mean 16417.33338 17283.957605 18554.709840 20448.040160 std 525.09198 1485.263517 1304.328377 2037.668013 min 16046.03728 16233.717700 17632.410400 19007.191290 25% 16231.68533 16758.837652 18093.560120 19727.615725 50% 16417.33338 17283.957605 18554.709840 20448.040160 75% 16602.98143 17809.077557 19015.859560 21168.464595 max 16788.62948 18334.197510 19477.009280 21888.889030 gdpPercap_1992 gdpPercap_1997 gdpPercap_2002 gdpPercap_2007 count 2.000000 2.000000 2.000000 2.000000 mean 20894.045885 24024.175170 26938.778040 29810.188275 std 3578.979883 4205.533703 5301.853680 6540.991104 min 18363.324940 21050.413770 23189.801350 25185.009110 25% 19628.685413 22537.294470 25064.289695 27497.598692 50% 20894.045885 24024.175170 26938.778040 29810.188275 75% 22159.406358 25511.055870 28813.266385 32122.777857 max 23424.766830 26997.936570 30687.754730 34435.367440 . | Not particularly useful with just two records, but very helpful when there are thousands. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/06-reading-tabular.html#use-dataframedescribe-to-get-summary-statistics-about-data",
    "relUrl": "/Python_Series_Materials/part_2/06-reading-tabular.html#use-dataframedescribe-to-get-summary-statistics-about-data"
  },"253": {
    "doc": "Reading Tabular Data into DataFrames",
    "title": "Reading Other Data",
    "content": "Read the data in gapminder_gdp_americas.csv (which should be in the same directory as gapminder_gdp_oceania.csv) into a variable called americas and display its summary statistics. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/06-reading-tabular.html#reading-other-data",
    "relUrl": "/Python_Series_Materials/part_2/06-reading-tabular.html#reading-other-data"
  },"254": {
    "doc": "Reading Tabular Data into DataFrames",
    "title": "Solution",
    "content": "To read in a CSV, we use pd.read_csv and pass the filename 'data/gapminder_gdp_americas.csv' to it. We also once again pass the column name 'country' to the parameter index_col in order to index by country. The summary statistics can be displayed with the DataFrame.describe() method. americas = pd.read_csv('data/gapminder_gdp_americas.csv', index_col='country') americas.describe() . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/06-reading-tabular.html#solution",
    "relUrl": "/Python_Series_Materials/part_2/06-reading-tabular.html#solution"
  },"255": {
    "doc": "Reading Tabular Data into DataFrames",
    "title": "Inspecting Data",
    "content": "After reading the data for the Americas, use help(americas.head) and help(americas.tail) to find out what DataFrame.head and DataFrame.tail do. | What method call will display the first three rows of this data? | What method call will display the last three columns of this data? (Hint: you may need to change your view of the data.) | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/06-reading-tabular.html#inspecting-data",
    "relUrl": "/Python_Series_Materials/part_2/06-reading-tabular.html#inspecting-data"
  },"256": {
    "doc": "Reading Tabular Data into DataFrames",
    "title": "Solution",
    "content": ". | We can check out the first five rows of americas by executing americas.head() (allowing us to view the head of the DataFrame). We can specify the number of rows we wish to see by specifying the parameter n in our call to americas.head(). To view the first three rows, execute: . americas.head(n=3) . continent gdpPercap_1952 gdpPercap_1957 gdpPercap_1962 \\ country Argentina Americas 5911.315053 6856.856212 7133.166023 Bolivia Americas 2677.326347 2127.686326 2180.972546 Brazil Americas 2108.944355 2487.365989 3336.585802 gdpPercap_1967 gdpPercap_1972 gdpPercap_1977 gdpPercap_1982 \\ country Argentina 8052.953021 9443.038526 10079.026740 8997.897412 Bolivia 2586.886053 2980.331339 3548.097832 3156.510452 Brazil 3429.864357 4985.711467 6660.118654 7030.835878 gdpPercap_1987 gdpPercap_1992 gdpPercap_1997 gdpPercap_2002 \\ country Argentina 9139.671389 9308.418710 10967.281950 8797.640716 Bolivia 2753.691490 2961.699694 3326.143191 3413.262690 Brazil 7807.095818 6950.283021 7957.980824 8131.212843 gdpPercap_2007 country Argentina 12779.379640 Bolivia 3822.137084 Brazil 9065.800825 . | To check out the last three rows of americas, we would use the command, americas.tail(n=3), analogous to head() used above. However, here we want to look at the last three columns so we need to change our view and then use tail(). To do so, we create a new DataFrame in which rows and columns are switched: . americas_flipped = americas.T . We can then view the last three columns of americas by viewing the last three rows of americas_flipped: . americas_flipped.tail(n=3) . country Argentina Bolivia Brazil Canada Chile Colombia \\ gdpPercap_1997 10967.3 3326.14 7957.98 28954.9 10118.1 6117.36 gdpPercap_2002 8797.64 3413.26 8131.21 33329 10778.8 5755.26 gdpPercap_2007 12779.4 3822.14 9065.8 36319.2 13171.6 7006.58 country Costa Rica Cuba Dominican Republic Ecuador ... \\ gdpPercap_1997 6677.05 5431.99 3614.1 7429.46 ... gdpPercap_2002 7723.45 6340.65 4563.81 5773.04 ... gdpPercap_2007 9645.06 8948.1 6025.37 6873.26 ... country Mexico Nicaragua Panama Paraguay Peru Puerto Rico \\ gdpPercap_1997 9767.3 2253.02 7113.69 4247.4 5838.35 16999.4 gdpPercap_2002 10742.4 2474.55 7356.03 3783.67 5909.02 18855.6 gdpPercap_2007 11977.6 2749.32 9809.19 4172.84 7408.91 19328.7 country Trinidad and Tobago United States Uruguay Venezuela gdpPercap_1997 8792.57 35767.4 9230.24 10165.5 gdpPercap_2002 11460.6 39097.1 7727 8605.05 gdpPercap_2007 18008.5 42951.7 10611.5 11415.8 . This shows the data that we want, but we may prefer to display three columns instead of three rows, so we can flip it back: . americas_flipped.tail(n=3).T . Note: we could have done the above in a single line of code by ‘chaining’ the commands: . americas.T.tail(n=3).T . | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/06-reading-tabular.html#solution-1",
    "relUrl": "/Python_Series_Materials/part_2/06-reading-tabular.html#solution-1"
  },"257": {
    "doc": "Reading Tabular Data into DataFrames",
    "title": "Reading Files in Other Directories",
    "content": "The data for your current project is stored in a file called microbes.csv, which is located in a folder called field_data. You are doing analysis in a notebook called analysis.ipynb in a sibling folder called thesis: . your_home_directory +-- field_data/ | +-- microbes.csv +-- thesis/ +-- analysis.ipynb . What value(s) should you pass to read_csv to read microbes.csv in analysis.ipynb? . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/06-reading-tabular.html#reading-files-in-other-directories",
    "relUrl": "/Python_Series_Materials/part_2/06-reading-tabular.html#reading-files-in-other-directories"
  },"258": {
    "doc": "Reading Tabular Data into DataFrames",
    "title": "Solution",
    "content": "We need to specify the path to the file of interest in the call to pd.read_csv. We first need to ‘jump’ out of the folder thesis using ‘../’ and then into the folder field_data using ‘field_data/’. Then we can specify the filename `microbes.csv. The result is as follows: . data_microbes = pd.read_csv('../field_data/microbes.csv') . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/06-reading-tabular.html#solution-2",
    "relUrl": "/Python_Series_Materials/part_2/06-reading-tabular.html#solution-2"
  },"259": {
    "doc": "Reading Tabular Data into DataFrames",
    "title": "Writing Data",
    "content": "As well as the read_csv function for reading data from a file, Pandas provides a to_csv function to write dataframes to files. Applying what you’ve learned about reading from files, write one of your dataframes to a file called processed.csv. You can use help to get information on how to use to_csv. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/06-reading-tabular.html#writing-data",
    "relUrl": "/Python_Series_Materials/part_2/06-reading-tabular.html#writing-data"
  },"260": {
    "doc": "Reading Tabular Data into DataFrames",
    "title": "Solution",
    "content": "In order to write the DataFrame americas to a file called processed.csv, execute the following command: . americas.to_csv('processed.csv') . For help on to_csv, you could execute, for example: . help(americas.to_csv) . Note that help(to_csv) throws an error! This is a subtlety and is due to the fact that to_csv is NOT a function in and of itself and the actual call is americas.to_csv. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/06-reading-tabular.html#solution-3",
    "relUrl": "/Python_Series_Materials/part_2/06-reading-tabular.html#solution-3"
  },"261": {
    "doc": "Advanced facets",
    "title": "Explore more advanced uses of facets",
    "content": ". | Work with numeric facets: From the new Per_capita_expenditure column pull down menu, choose Facet -&gt; Numeric facet. Numeric facets provide a sliding scale where you can choose which values to include. Notice the blue areas indicate where the values fall – you can see where the bulk of your values lie, and where there are some outliers. Let’s try to remove the outliers by dragging the handles so the facet includes only the largest block of blue values. This removes a number of rows from the display. | Clean up non-numeric cells: At the bottom of the numeric facet, there are options to show Non-numeric values, Blanks, or Errors in this column. There are no blanks or errors in this data column, but there are non-numeric values. Uncheck Numeric to look only at the Non-numeric values. Most of these have values of “F” in them, but some of them are actually blank! Why are they included here rather than counted as blank cells by the facet? Hover your cursor over a blank cell and click Edit. There are spaces in this cell – remove them using Edit cells -&gt; Common transforms -&gt; Trim leading and trailing white space. Notice in the facet that there are now a number of cells recognized as blank. Note: In OpenRefine, any actions you perform are only applied to the rows currently selected, i.e., the above task was only applied to the non-numeric cells that are currently selected. | Use facets to edit data in bulk: What does the “F” value mean? This was included in the information at the top of the original spreadsheet, which we removed when we loaded it into OpenRefine. If you were to go back and look at the Excel file you’ll see that “F” means the data was too unreliable to be published. If you wanted to change the value of “F” to be something more descriptive, you can use facets to edit data in bulk. However, we can’t do it from a numeric facet, we need a text facet instead. From the Per_capita_expenditure column pull down menu, select Facet -&gt; Text facet. Notice that only the non-numeric values are listed – this is because you still have only non-numeric values selected (via the numeric facet). Hover your cursor over the value F and choose edit. Change F to something more descriptive, such as Not published. Click Apply. All values of F in the dataset are automatically changed to Not published. | . In summary: filters are for free text searching; you can identify all matches of your search string in the column. Facets are for structured viewing and editing of unique values. ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt1_expenditure/06_adv-facet.html#explore-more-advanced-uses-of-facets",
    "relUrl": "/OpenRefine_Materials/pt1_expenditure/06_adv-facet.html#explore-more-advanced-uses-of-facets"
  },"262": {
    "doc": "Advanced facets",
    "title": "Advanced facets",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt1_expenditure/06_adv-facet.html",
    "relUrl": "/OpenRefine_Materials/pt1_expenditure/06_adv-facet.html"
  },"263": {
    "doc": "Pandas DataFrames",
    "title": "Pandas Dataframes",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#pandas-dataframes",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#pandas-dataframes"
  },"264": {
    "doc": "Pandas DataFrames",
    "title": "Note about Pandas DataFrames/Series",
    "content": "A DataFrame is a collection of Series; The DataFrame is the way Pandas represents a table, and Series is the data-structure Pandas use to represent a column. Pandas is built on top of the Numpy library, which in practice means that most of the methods defined for Numpy Arrays apply to Pandas Series/DataFrames. What makes Pandas so attractive is the powerful interface to access individual records of the table, proper handling of missing values, and relational-databases operations between DataFrames. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#note-about-pandas-dataframesseries",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#note-about-pandas-dataframesseries"
  },"265": {
    "doc": "Pandas DataFrames",
    "title": "Selecting values",
    "content": "To access a value at the position [i,j] of a DataFrame, we have two options, depending on what is the meaning of i in use. Remember that a DataFrame provides an index as a way to identify the rows of the table; a row, then, has a position inside the table as well as a label, which uniquely identifies its entry in the DataFrame. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#selecting-values",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#selecting-values"
  },"266": {
    "doc": "Pandas DataFrames",
    "title": "Use DataFrame.iloc[..., ...] to select values by their (entry) position",
    "content": ". | Can specify location by numerical index analogously to 2D version of character selection in strings. | . import pandas as pd data = pd.read_csv('data/gapminder_gdp_europe.csv', index_col='country') print(data.iloc[0, 0]) . 1601.056136 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#use-dataframeiloc--to-select-values-by-their-entry-position",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#use-dataframeiloc--to-select-values-by-their-entry-position"
  },"267": {
    "doc": "Pandas DataFrames",
    "title": "Use DataFrame.loc[..., ...] to select values by their (entry) label.",
    "content": ". | Can specify location by row and/or column name. | . print(data.loc[\"Albania\", \"gdpPercap_1952\"]) . 1601.056136 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#use-dataframeloc--to-select-values-by-their-entry-label",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#use-dataframeloc--to-select-values-by-their-entry-label"
  },"268": {
    "doc": "Pandas DataFrames",
    "title": "Use : on its own to mean all columns or all rows.",
    "content": ". | Just like Python’s usual slicing notation. | . print(data.loc[\"Albania\", :]) . gdpPercap_1952 1601.056136 gdpPercap_1957 1942.284244 gdpPercap_1962 2312.888958 gdpPercap_1967 2760.196931 gdpPercap_1972 3313.422188 gdpPercap_1977 3533.003910 gdpPercap_1982 3630.880722 gdpPercap_1987 3738.932735 gdpPercap_1992 2497.437901 gdpPercap_1997 3193.054604 gdpPercap_2002 4604.211737 gdpPercap_2007 5937.029526 Name: Albania, dtype: float64 . | Would get the same result printing data.loc[\"Albania\"] (without a second index). | . print(data.loc[:, \"gdpPercap_1952\"]) . country Albania 1601.056136 Austria 6137.076492 Belgium 8343.105127 ⋮ ⋮ ⋮ Switzerland 14734.232750 Turkey 1969.100980 United Kingdom 9979.508487 Name: gdpPercap_1952, dtype: float64 . | Would get the same result printing data[\"gdpPercap_1952\"] | Also get the same result printing data.gdpPercap_1952 (not recommended, because easily confused with . notation for methods) | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#use--on-its-own-to-mean-all-columns-or-all-rows",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#use--on-its-own-to-mean-all-columns-or-all-rows"
  },"269": {
    "doc": "Pandas DataFrames",
    "title": "Select multiple columns or rows using DataFrame.loc and a named slice.",
    "content": "print(data.loc['Italy':'Poland', 'gdpPercap_1962':'gdpPercap_1972']) . gdpPercap_1962 gdpPercap_1967 gdpPercap_1972 country Italy 8243.582340 10022.401310 12269.273780 Montenegro 4649.593785 5907.850937 7778.414017 Netherlands 12790.849560 15363.251360 18794.745670 Norway 13450.401510 16361.876470 18965.055510 Poland 5338.752143 6557.152776 8006.506993 . In the above code, we discover that slicing using loc is inclusive at both ends, which differs from slicing using iloc, where slicing indicates everything up to but not including the final index. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#select-multiple-columns-or-rows-using-dataframeloc-and-a-named-slice",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#select-multiple-columns-or-rows-using-dataframeloc-and-a-named-slice"
  },"270": {
    "doc": "Pandas DataFrames",
    "title": "Result of slicing can be used in further operations.",
    "content": ". | Usually don’t just print a slice. | All the statistical operators that work on entire dataframes work the same way on slices. | E.g., calculate max of a slice. | . print(data.loc['Italy':'Poland', 'gdpPercap_1962':'gdpPercap_1972'].max()) . gdpPercap_1962 13450.40151 gdpPercap_1967 16361.87647 gdpPercap_1972 18965.05551 dtype: float64 . print(data.loc['Italy':'Poland', 'gdpPercap_1962':'gdpPercap_1972'].min()) . gdpPercap_1962 4649.593785 gdpPercap_1967 5907.850937 gdpPercap_1972 7778.414017 dtype: float64 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#result-of-slicing-can-be-used-in-further-operations",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#result-of-slicing-can-be-used-in-further-operations"
  },"271": {
    "doc": "Pandas DataFrames",
    "title": "Use comparisons to select data based on value.",
    "content": ". | Comparison is applied element by element. | Returns a similarly-shaped dataframe of True and False. | . # Use a subset of data to keep output readable. subset = data.loc['Italy':'Poland', 'gdpPercap_1962':'gdpPercap_1972'] print('Subset of data:\\n', subset) # Which values were greater than 10000 ? print('\\nWhere are values large?\\n', subset &gt; 10000) . Subset of data: gdpPercap_1962 gdpPercap_1967 gdpPercap_1972 country Italy 8243.582340 10022.401310 12269.273780 Montenegro 4649.593785 5907.850937 7778.414017 Netherlands 12790.849560 15363.251360 18794.745670 Norway 13450.401510 16361.876470 18965.055510 Poland 5338.752143 6557.152776 8006.506993 Where are values large? gdpPercap_1962 gdpPercap_1967 gdpPercap_1972 country Italy False True True Montenegro False False False Netherlands True True True Norway True True True Poland False False False . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#use-comparisons-to-select-data-based-on-value",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#use-comparisons-to-select-data-based-on-value"
  },"272": {
    "doc": "Pandas DataFrames",
    "title": "Select values or NaN using a Boolean mask.",
    "content": ". | A frame full of Booleans is sometimes called a mask because of how it can be used. | . mask = subset &gt; 10000 print(subset[mask]) . gdpPercap_1962 gdpPercap_1967 gdpPercap_1972 country Italy NaN 10022.40131 12269.27378 Montenegro NaN NaN NaN Netherlands 12790.84956 15363.25136 18794.74567 Norway 13450.40151 16361.87647 18965.05551 Poland NaN NaN NaN . | Get the value where the mask is true, and NaN (Not a Number) where it is false. | Useful because NaNs are ignored by operations like max, min, average, etc. | . print(subset[subset &gt; 10000].describe()) . gdpPercap_1962 gdpPercap_1967 gdpPercap_1972 count 2.000000 3.000000 3.000000 mean 13120.625535 13915.843047 16676.358320 std 466.373656 3408.589070 3817.597015 min 12790.849560 10022.401310 12269.273780 25% 12955.737547 12692.826335 15532.009725 50% 13120.625535 15363.251360 18794.745670 75% 13285.513523 15862.563915 18879.900590 max 13450.401510 16361.876470 18965.055510 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#select-values-or-nan-using-a-boolean-mask",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#select-values-or-nan-using-a-boolean-mask"
  },"273": {
    "doc": "Pandas DataFrames",
    "title": "Group By: split-apply-combine",
    "content": "Pandas vectorizing methods and grouping operations are features that provide users much flexibility to analyse their data. For instance, let’s say we want to have a clearer view on how the European countries split themselves according to their GDP. | We may have a glance by splitting the countries in two groups during the years surveyed, those who presented a GDP higher than the European average and those with a lower GDP. | We then estimate a wealthy score based on the historical (from 1962 to 2007) values, where we account how many times a country has participated in the groups of lower or higher GDP | . mask_higher = data &gt; data.mean() wealth_score = mask_higher.aggregate('sum', axis=1) / len(data.columns) print(wealth_score) . country Albania 0.000000 Austria 1.000000 Belgium 1.000000 Bosnia and Herzegovina 0.000000 Bulgaria 0.000000 Croatia 0.000000 Czech Republic 0.500000 Denmark 1.000000 Finland 1.000000 France 1.000000 Germany 1.000000 Greece 0.333333 Hungary 0.000000 Iceland 1.000000 Ireland 0.333333 Italy 0.500000 Montenegro 0.000000 Netherlands 1.000000 Norway 1.000000 Poland 0.000000 Portugal 0.000000 Romania 0.000000 Serbia 0.000000 Slovak Republic 0.000000 Slovenia 0.333333 Spain 0.333333 Sweden 1.000000 Switzerland 1.000000 Turkey 0.000000 United Kingdom 1.000000 dtype: float64 . Finally, for each group in the wealth_score table, we sum their (financial) contribution across the years surveyed using chained methods: . print(data.groupby(wealth_score).sum()) . gdpPercap_1952 gdpPercap_1957 gdpPercap_1962 gdpPercap_1967 \\ 0.000000 36916.854200 46110.918793 56850.065437 71324.848786 0.333333 16790.046878 20942.456800 25744.935321 33567.667670 0.500000 11807.544405 14505.000150 18380.449470 21421.846200 1.000000 104317.277560 127332.008735 149989.154201 178000.350040 gdpPercap_1972 gdpPercap_1977 gdpPercap_1982 gdpPercap_1987 \\ 0.000000 88569.346898 104459.358438 113553.768507 119649.599409 0.333333 45277.839976 53860.456750 59679.634020 64436.912960 0.500000 25377.727380 29056.145370 31914.712050 35517.678220 1.000000 215162.343140 241143.412730 263388.781960 296825.131210 gdpPercap_1992 gdpPercap_1997 gdpPercap_2002 gdpPercap_2007 0.000000 92380.047256 103772.937598 118590.929863 149577.357928 0.333333 67918.093220 80876.051580 102086.795210 122803.729520 0.500000 36310.666080 40723.538700 45564.308390 51403.028210 1.000000   315238.235970   346930.926170   385109.939210   427850.333420 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#group-by-split-apply-combine",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#group-by-split-apply-combine"
  },"274": {
    "doc": "Pandas DataFrames",
    "title": "Selection of Individual Values",
    "content": "Assume Pandas has been imported into your notebook and the Gapminder GDP data for Europe has been loaded: . import pandas as pd df = pd.read_csv('data/gapminder_gdp_europe.csv', index_col='country') . Write an expression to find the Per Capita GDP of Serbia in 2007. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#selection-of-individual-values",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#selection-of-individual-values"
  },"275": {
    "doc": "Pandas DataFrames",
    "title": "Solution",
    "content": "The selection can be done by using the labels for both the row (“Serbia”) and the column (“gdpPercap_2007”): . print(df.loc['Serbia', 'gdpPercap_2007']) . The output is . 9786.534714 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#solution",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#solution"
  },"276": {
    "doc": "Pandas DataFrames",
    "title": "Extent of Slicing",
    "content": ". | Do the two statements below produce the same output? | Based on this, what rule governs what is included (or not) in numerical slices and named slices in Pandas? | . print(df.iloc[0:2, 0:2]) print(df.loc['Albania':'Belgium', 'gdpPercap_1952':'gdpPercap_1962']) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#extent-of-slicing",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#extent-of-slicing"
  },"277": {
    "doc": "Pandas DataFrames",
    "title": "Solution",
    "content": "No, they do not produce the same output! The output of the first statement is: . gdpPercap_1952 gdpPercap_1957 country Albania 1601.056136 1942.284244 Austria 6137.076492 8842.598030 . The second statement gives: . gdpPercap_1952 gdpPercap_1957 gdpPercap_1962 country Albania 1601.056136 1942.284244 2312.888958 Austria 6137.076492 8842.598030 10750.721110 Belgium 8343.105127 9714.960623 10991.206760 . Clearly, the second statement produces an additional column and an additional row compared to the first statement. What conclusion can we draw? We see that a numerical slice, 0:2, omits the final index (i.e. index 2) in the range provided, while a named slice, ‘gdpPercap_1952’:’gdpPercap_1962’, includes the final element. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#solution-1",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#solution-1"
  },"278": {
    "doc": "Pandas DataFrames",
    "title": "Reconstructing Data",
    "content": "Explain what each line in the following short program does: what is in first, second, etc.? . first = pd.read_csv('data/gapminder_all.csv', index_col='country') second = first[first['continent'] == 'Americas'] third = second.drop('Puerto Rico') fourth = third.drop('continent', axis = 1) fourth.to_csv('result.csv') . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#reconstructing-data",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#reconstructing-data"
  },"279": {
    "doc": "Pandas DataFrames",
    "title": "Solution",
    "content": "Let’s go through this piece of code line by line. first = pd.read_csv('data/gapminder_all.csv', index_col='country') . This line loads the dataset containing the GDP data from all countries into a dataframe called first. The index_col='country' parameter selects which column to use as the row labels in the dataframe. second = first[first['continent'] == 'Americas'] . This line makes a selection: only those rows of first for which the ‘continent’ column matches ‘Americas’ are extracted. Notice how the Boolean expression inside the brackets, first['continent'] == 'Americas', is used to select only those rows where the expression is true. Try printing this expression! Can you print also its individual True/False elements? (hint: first assign the expression to a variable) . third = second.drop('Puerto Rico') . As the syntax suggests, this line drops the row from second where the label is ‘Puerto Rico’. The resulting dataframe third has one row less than the original dataframe second. fourth = third.drop('continent', axis = 1) . Again we apply the drop function, but in this case we are dropping not a row but a whole column. To accomplish this, we need to specify also the axis parameter (we want to drop the second column which has index 1). fourth.to_csv('result.csv') . The final step is to write the data that we have been working on to a csv file. Pandas makes this easy with the to_csv() function. The only required argument to the function is the filename. Note that the file will be written in the directory from which you started the Jupyter or Python session. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#solution-2",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#solution-2"
  },"280": {
    "doc": "Pandas DataFrames",
    "title": "Selecting Indices",
    "content": "Explain in simple terms what idxmin and idxmax do in the short program below. When would you use these methods? . data = pd.read_csv('data/gapminder_gdp_europe.csv', index_col='country') print(data.idxmin()) print(data.idxmax()) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#selecting-indices",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#selecting-indices"
  },"281": {
    "doc": "Pandas DataFrames",
    "title": "Solution",
    "content": "For each column in data, idxmin will return the index value corresponding to each column’s minimum; idxmax will do accordingly the same for each column’s maximum value. You can use these functions whenever you want to get the row index of the minimum/maximum value and not the actual minimum/maximum value. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#solution-3",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#solution-3"
  },"282": {
    "doc": "Pandas DataFrames",
    "title": "Practice with Selection",
    "content": "Assume Pandas has been imported and the Gapminder GDP data for Europe has been loaded. Write an expression to select each of the following: . | GDP per capita for all countries in 1982. | GDP per capita for Denmark for all years. | GDP per capita for all countries for years after 1985. | GDP per capita for each country in 2007 as a multiple of GDP per capita for that country in 1952. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#practice-with-selection",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#practice-with-selection"
  },"283": {
    "doc": "Pandas DataFrames",
    "title": "Solution",
    "content": "1: . data['gdpPercap_1982'] . 2: . data.loc['Denmark',:] . 3: . data.loc[:,'gdpPercap_1985':] . Pandas is smart enough to recognize the number at the end of the column label and does not give you an error, although no column named gdpPercap_1985 actually exists. This is useful if new columns are added to the CSV file later. 4: . data['gdpPercap_2007']/data['gdpPercap_1952'] . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#solution-4",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#solution-4"
  },"284": {
    "doc": "Pandas DataFrames",
    "title": "Many Ways of Access",
    "content": "There are at least two ways of accessing a value or slice of a DataFrame: by name or index. However, there are many others. For example, a single column or row can be accessed either as a DataFrame or a Series object. Suggest different ways of doing the following operations on a DataFrame: . | Access a single column | Access a single row | Access an individual DataFrame element | Access several columns | Access several rows | Access a subset of specific rows and columns | Access a subset of row and column ranges | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#many-ways-of-access",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#many-ways-of-access"
  },"285": {
    "doc": "Pandas DataFrames",
    "title": "Solution",
    "content": "1. Access a single column: . # by name data[\"col_name\"] # as a Series data[[\"col_name\"]] # as a DataFrame # by name using .loc data.T.loc[\"col_name\"] # as a Series data.T.loc[[\"col_name\"]].T # as a DataFrame # Dot notation (Series) data.col_name # by index (iloc) data.iloc[:, col_index] # as a Series data.iloc[:, [col_index]] # as a DataFrame # using a mask data.T[data.T.index == \"col_name\"].T . 2. Access a single row: . # by name using .loc data.loc[\"row_name\"] # as a Series data.loc[[\"row_name\"]] # as a DataFrame # by name data.T[\"row_name\"] # as a Series data.T[[\"row_name\"]].T # as a DataFrame # by index data.iloc[row_index] # as a Series data.iloc[[row_index]] # as a DataFrame # using mask data[data.index == \"row_name\"] . 3. Access an individual DataFrame element: . # by column/row names data[\"column_name\"][\"row_name\"] # as a Series data[[\"col_name\"]].loc[\"row_name\"] # as a Series data[[\"col_name\"]].loc[[\"row_name\"]] # as a DataFrame data.loc[\"row_name\"][\"col_name\"] # as a value data.loc[[\"row_name\"]][\"col_name\"] # as a Series data.loc[[\"row_name\"]][[\"col_name\"]] # as a DataFrame data.loc[\"row_name\", \"col_name\"] # as a value data.loc[[\"row_name\"], \"col_name\"] # as a Series. Preserves index. Column name is moved to `.name`. data.loc[\"row_name\", [\"col_name\"]] # as a Series. Index is moved to `.name.` Sets index to column name. data.loc[[\"row_name\"], [\"col_name\"]] # as a DataFrame (preserves original index and column name) # by column/row names: Dot notation data.col_name.row_name # by column/row indices data.iloc[row_index, col_index] # as a value data.iloc[[row_index], col_index] # as a Series. Preserves index. Column name is moved to `.name` data.iloc[row_index, [col_index]] # as a Series. Index is moved to `.name.` Sets index to column name. data.iloc[[row_index], [col_index]] # as a DataFrame (preserves original index and column name) # column name + row index data[\"col_name\"][row_index] data.col_name[row_index] data[\"col_name\"].iloc[row_index] # column index + row name data.iloc[:, [col_index]].loc[\"row_name\"] # as a Series data.iloc[:, [col_index]].loc[[\"row_name\"]] # as a DataFrame # using masks data[data.index == \"row_name\"].T[data.T.index == \"col_name\"].T . 4. Access several columns: . # by name data[[\"col1\", \"col2\", \"col3\"]] data.loc[:, [\"col1\", \"col2\", \"col3\"]] # by index data.iloc[:, [col1_index, col2_index, col3_index]] . 5. Access several rows . # by name data.loc[[\"row1\", \"row2\", \"row3\"]] # by index data.iloc[[row1_index, row2_index, row3_index]] . 6. Access a subset of specific rows and columns . # by names data.loc[[\"row1\", \"row2\", \"row3\"], [\"col1\", \"col2\", \"col3\"]] # by indices data.iloc[[row1_index, row2_index, row3_index], [col1_index, col2_index, col3_index]] # column names + row indices data[[\"col1\", \"col2\", \"col3\"]].iloc[[row1_index, row2_index, row3_index]] # column indices + row names data.iloc[:, [col1_index, col2_index, col3_index]].loc[[\"row1\", \"row2\", \"row3\"]] . 7. Access a subset of row and column ranges . # by name data.loc[\"row1\":\"row2\", \"col1\":\"col2\"] # by index data.iloc[row1_index:row2_index, col1_index:col2_index] # column names + row indices data.loc[:, \"col1_name\":\"col2_name\"].iloc[row1_index:row2_index] # column indices + row names data.iloc[:, col1_index:col2_index].loc[\"row1\":\"row2\"] . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#solution-5",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#solution-5"
  },"286": {
    "doc": "Pandas DataFrames",
    "title": "Exploring available methods using the dir() function",
    "content": "Python includes a dir() function that can be used to display all of the available methods (functions) that are built into a data object. In Episode 4, we used some methods with a string. But we can see many more are available by using dir(): . my_string = 'Hello world!' # creation of a string object dir(my_string) . This command returns: . ['__add__', ... '__subclasshook__', 'capitalize', 'casefold', 'center', ... 'upper', 'zfill'] . You can use help() or Shift+Tab to get more information about what these methods do. Assume Pandas has been imported and the Gapminder GDP data for Europe has been loaded as data. Then, use dir() to find the function that prints out the median per-capita GDP across all European countries for each year that information is available. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#exploring-available-methods-using-the-dir-function",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#exploring-available-methods-using-the-dir-function"
  },"287": {
    "doc": "Pandas DataFrames",
    "title": "Solution",
    "content": "Among many choices, dir() lists the median() function as a possibility. Thus, . data.median() . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#solution-6",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#solution-6"
  },"288": {
    "doc": "Pandas DataFrames",
    "title": "Interpretation",
    "content": "Poland’s borders have been stable since 1945, but changed several times in the years before then. How would you handle this if you were creating a table of GDP per capita for Poland . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#interpretation",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html#interpretation"
  },"289": {
    "doc": "Pandas DataFrames",
    "title": "Pandas DataFrames",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/07_Pandas_DataFrames.html",
    "relUrl": "/Python_Series_Materials/part_2/07_Pandas_DataFrames.html"
  },"290": {
    "doc": "Exporting data",
    "title": "Export data from OpenRefine",
    "content": ". | Remove any facets you have in place. In the top right-hand corner of the screen, pull down the Export menu and choose comma separated value (or Excel, or whatever format you would like to download). | Note that if you choose Export project, it will export as a zip file with the original and final versions of you data and various versions in between. You could open the project again in OpenRefine to view your process. | . | . ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt1_expenditure/07_export.html#export-data-from-openrefine",
    "relUrl": "/OpenRefine_Materials/pt1_expenditure/07_export.html#export-data-from-openrefine"
  },"291": {
    "doc": "Exporting data",
    "title": "Exporting data",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/pt1_expenditure/07_export.html",
    "relUrl": "/OpenRefine_Materials/pt1_expenditure/07_export.html"
  },"292": {
    "doc": "Plotting",
    "title": "Plotting",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/08_plotting.html",
    "relUrl": "/Python_Series_Materials/part_2/08_plotting.html"
  },"293": {
    "doc": "Plotting",
    "title": "matplotlib is the most widely used scientific plotting library in Python.",
    "content": ". | Commonly use a sub-library called matplotlib.pyplot. | The Jupyter Notebook will render plots inline by default. | . import matplotlib.pyplot as plt . | Simple plots are then (fairly) simple to create. | . time = [0, 1, 2, 3] position = [0, 100, 200, 300] plt.plot(time, position) plt.xlabel('Time (hr)') plt.ylabel('Position (km)') . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/08_plotting.html#matplotlib-is-the-most-widely-used-scientific-plotting-library-in-python",
    "relUrl": "/Python_Series_Materials/part_2/08_plotting.html#matplotlib-is-the-most-widely-used-scientific-plotting-library-in-python"
  },"294": {
    "doc": "Plotting",
    "title": "Display All Open Figures",
    "content": "In our Jupyter Notebook example, running the cell should generate the figure directly below the code. The figure is also included in the Notebook document for future viewing. However, other Python environments like an interactive Python session started from a terminal or a Python script executed via the command line require an additional command to display the figure. Instruct matplotlib to show a figure: . plt.show() . This command can also be used within a Notebook - for instance, to display multiple figures if several are created by a single cell. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/08_plotting.html#display-all-open-figures",
    "relUrl": "/Python_Series_Materials/part_2/08_plotting.html#display-all-open-figures"
  },"295": {
    "doc": "Plotting",
    "title": "Plot data directly from a Pandas dataframe.",
    "content": ". | We can also plot Pandas dataframes. | This implicitly uses matplotlib.pyplot. | Before plotting, we convert the column headings from a string to integer data type, since they represent numerical values, using str.replace() to remove the gpdPercap_ prefix and then astype(int) to convert the series of string values (['1952', '1957', ..., '2007']) to a series of integers: [1925, 1957, ..., 2007]. | . import pandas as pd data = pd.read_csv('data/gapminder_gdp_oceania.csv', index_col='country') # Extract year from last 4 characters of each column name # The current column names are structured as 'gdpPercap_(year)', # so we want to keep the (year) part only for clarity when plotting GDP vs. years # To do this we use replace(), which removes from the string the characters stated in the argument # This method works on strings, so we use replace() from Pandas Series.str vectorized string functions years = data.columns.str.replace('gdpPercap_', '') # Convert year values to integers, saving results back to dataframe data.columns = years.astype(int) data.loc['Australia'].plot() . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/08_plotting.html#plot-data-directly-from-a-pandas-dataframe",
    "relUrl": "/Python_Series_Materials/part_2/08_plotting.html#plot-data-directly-from-a-pandas-dataframe"
  },"296": {
    "doc": "Plotting",
    "title": "Select and transform data, then plot it.",
    "content": ". | By default, DataFrame.plot plots with the rows as the X axis. | We can transpose the data in order to plot multiple series. | . data.T.plot() plt.ylabel('GDP per capita') . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/08_plotting.html#select-and-transform-data-then-plot-it",
    "relUrl": "/Python_Series_Materials/part_2/08_plotting.html#select-and-transform-data-then-plot-it"
  },"297": {
    "doc": "Plotting",
    "title": "Many styles of plot are available.",
    "content": ". | For example, do a bar plot using a fancier style. | . plt.style.use('ggplot') data.T.plot(kind='bar') plt.ylabel('GDP per capita') . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/08_plotting.html#many-styles-of-plot-are-available",
    "relUrl": "/Python_Series_Materials/part_2/08_plotting.html#many-styles-of-plot-are-available"
  },"298": {
    "doc": "Plotting",
    "title": "Data can also be plotted by calling the matplotlib plot function directly.",
    "content": ". | The command is plt.plot(x, y) | The color and format of markers can also be specified as an additional optional argument e.g., b- is a blue line, g-- is a green dashed line. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/08_plotting.html#data-can-also-be-plotted-by-calling-the-matplotlib-plot-function-directly",
    "relUrl": "/Python_Series_Materials/part_2/08_plotting.html#data-can-also-be-plotted-by-calling-the-matplotlib-plot-function-directly"
  },"299": {
    "doc": "Plotting",
    "title": "Get Australia data from dataframe",
    "content": "years = data.columns gdp_australia = data.loc['Australia'] plt.plot(years, gdp_australia, 'g--') . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/08_plotting.html#get-australia-data-from-dataframe",
    "relUrl": "/Python_Series_Materials/part_2/08_plotting.html#get-australia-data-from-dataframe"
  },"300": {
    "doc": "Plotting",
    "title": "Can plot many sets of data together.",
    "content": "# Select two countries' worth of data. gdp_australia = data.loc['Australia'] gdp_nz = data.loc['New Zealand'] # Plot with differently-colored markers. plt.plot(years, gdp_australia, 'b-', label='Australia') plt.plot(years, gdp_nz, 'g-', label='New Zealand') # Create legend. plt.legend(loc='upper left') plt.xlabel('Year') plt.ylabel('GDP per capita ($)') . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/08_plotting.html#can-plot-many-sets-of-data-together",
    "relUrl": "/Python_Series_Materials/part_2/08_plotting.html#can-plot-many-sets-of-data-together"
  },"301": {
    "doc": "Plotting",
    "title": "Adding a Legend",
    "content": "Often when plotting multiple datasets on the same figure it is desirable to have a legend describing the data. This can be done in matplotlib in two stages: . | Provide a label for each dataset in the figure: | . plt.plot(years, gdp_australia, label='Australia') plt.plot(years, gdp_nz, label='New Zealand') . | Instruct matplotlib to create the legend. | . plt.legend() . By default matplotlib will attempt to place the legend in a suitable position. If you would rather specify a position this can be done with the loc= argument, e.g to place the legend in the upper left corner of the plot, specify loc='upper left' . | Plot a scatter plot correlating the GDP of Australia and New Zealand | Use either plt.scatter or DataFrame.plot.scatter | . plt.scatter(gdp_australia, gdp_nz) . data.T.plot.scatter(x = 'Australia', y = 'New Zealand') . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/08_plotting.html#adding-a-legend",
    "relUrl": "/Python_Series_Materials/part_2/08_plotting.html#adding-a-legend"
  },"302": {
    "doc": "Plotting",
    "title": "Minima and Maxima",
    "content": "Fill in the blanks below to plot the minimum GDP per capita over time for all the countries in Europe. Modify it again to plot the maximum GDP per capita over time for Europe. data_europe = pd.read_csv('data/gapminder_gdp_europe.csv', index_col='country') data_europe.____.plot(label='min') data_europe.____ plt.legend(loc='best') plt.xticks(rotation=90) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/08_plotting.html#minima-and-maxima",
    "relUrl": "/Python_Series_Materials/part_2/08_plotting.html#minima-and-maxima"
  },"303": {
    "doc": "Plotting",
    "title": "Solution",
    "content": "data_europe = pd.read_csv('data/gapminder_gdp_europe.csv', index_col='country') data_europe.min().plot(label='min') data_europe.max().plot(label='max') plt.legend(loc='best') plt.xticks(rotation=90) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/08_plotting.html#solution",
    "relUrl": "/Python_Series_Materials/part_2/08_plotting.html#solution"
  },"304": {
    "doc": "Plotting",
    "title": "Correlations",
    "content": "Modify the example in the notes to create a scatter plot showing the relationship between the minimum and maximum GDP per capita among the countries in Asia for each year in the data set. What relationship do you see (if any)? . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/08_plotting.html#correlations",
    "relUrl": "/Python_Series_Materials/part_2/08_plotting.html#correlations"
  },"305": {
    "doc": "Plotting",
    "title": "Solution",
    "content": "data_asia = pd.read_csv('data/gapminder_gdp_asia.csv', index_col='country') data_asia.describe().T.plot(kind='scatter', x='min', y='max') . No particular correlations can be seen between the minimum and maximum gdp values year on year. It seems the fortunes of asian countries do not rise and fall together. You might note that the variability in the maximum is much higher than that of the minimum. Take a look at the maximum and the max indexes: . data_asia = pd.read_csv('data/gapminder_gdp_asia.csv', index_col='country') data_asia.max().plot() print(data_asia.idxmax()) print(data_asia.idxmin()) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/08_plotting.html#solution-1",
    "relUrl": "/Python_Series_Materials/part_2/08_plotting.html#solution-1"
  },"306": {
    "doc": "Plotting",
    "title": "Solution",
    "content": ". Seems the variability in this value is due to a sharp drop after 1972. Some geopolitics at play perhaps? Given the dominance of oil producing countries, maybe the Brent crude index would make an interesting comparison? Whilst Myanmar consistently has the lowest gdp, the highest gdb nation has varied more notably. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/08_plotting.html#solution-2",
    "relUrl": "/Python_Series_Materials/part_2/08_plotting.html#solution-2"
  },"307": {
    "doc": "Plotting",
    "title": "More Correlations",
    "content": "This short program creates a plot showing the correlation between GDP and life expectancy for 2007, normalizing marker size by population: . data_all = pd.read_csv('data/gapminder_all.csv', index_col='country') data_all.plot(kind='scatter', x='gdpPercap_2007', y='lifeExp_2007', s=data_all['pop_2007']/1e6) . Using online help and other resources, explain what each argument to plot does. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/08_plotting.html#more-correlations",
    "relUrl": "/Python_Series_Materials/part_2/08_plotting.html#more-correlations"
  },"308": {
    "doc": "Plotting",
    "title": "Solution",
    "content": ". A good place to look is the documentation for the plot function - help(data_all.plot). kind - As seen already this determines the kind of plot to be drawn. x and y - A column name or index that determines what data will be placed on the x and y axes of the plot . s - Details for this can be found in the documentation of plt.scatter. A single number or one value for each data point. Determines the size of the plotted points. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/08_plotting.html#solution-3",
    "relUrl": "/Python_Series_Materials/part_2/08_plotting.html#solution-3"
  },"309": {
    "doc": "Plotting",
    "title": "Saving your plot to a file",
    "content": "If you are satisfied with the plot you see you may want to save it to a file, perhaps to include it in a publication. There is a function in the matplotlib.pyplot module that accomplishes this: savefig. Calling this function, e.g. with . plt.savefig('my_figure.png') . will save the current figure to the file my_figure.png. The file format will automatically be deduced from the file name extension (other formats are pdf, ps, eps and svg). Note that functions in plt refer to a global figure variable and after a figure has been displayed to the screen (e.g. with plt.show) matplotlib will make this variable refer to a new empty figure. Therefore, make sure you call plt.savefig before the plot is displayed to the screen, otherwise you may find a file with an empty plot. When using dataframes, data is often generated and plotted to screen in one line, and plt.savefig seems not to be a possible approach. One possibility to save the figure to file is then to . | save a reference to the current figure in a local variable (with plt.gcf) | call the savefig class method from that variable. | . data.plot(kind='bar') fig = plt.gcf() # get current figure fig.savefig('my_figure.png') . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/08_plotting.html#saving-your-plot-to-a-file",
    "relUrl": "/Python_Series_Materials/part_2/08_plotting.html#saving-your-plot-to-a-file"
  },"310": {
    "doc": "Plotting",
    "title": "Making your plots accessible",
    "content": "Whenever you are generating plots to go into a paper or a presentation, there are a few things you can do to make sure that everyone can understand your plots. | Always make sure your text is large enough to read. Use the fontsize parameter in xlabel, ylabel, title, and legend, and tick_params with labelsize to increase the text size of the numbers on your axes. | Similarly, you should make your graph elements easy to see. Use s to increase the size of your scatterplot markers and linewidth to increase the sizes of your plot lines. | Using color (and nothing else) to distinguish between different plot elements will make your plots unreadable to anyone who is colorblind, or who happens to have a black-and-white office printer. For lines, the linestyle parameter lets you use different types of lines. For scatterplots, marker lets you change the shape of your points. If you’re unsure about your colors, you can use Coblis or Color Oracle to simulate what your plots would look like to those with colorblindness. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/08_plotting.html#making-your-plots-accessible",
    "relUrl": "/Python_Series_Materials/part_2/08_plotting.html#making-your-plots-accessible"
  },"311": {
    "doc": "Lists",
    "title": "Lists",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html"
  },"312": {
    "doc": "Lists",
    "title": "A list stores many values in a single structure.",
    "content": ". | Doing calculations with a hundred variables called pressure_001, pressure_002, etc., would be at least as slow as doing them by hand. | Use a list to store many values together. | Contained within square brackets [...]. | Values separated by commas ,. | . | Use len to find out how many values are in a list. | . pressures = [0.273, 0.275, 0.277, 0.275, 0.276] print('pressures:', pressures) print('length:', len(pressures)) . pressures: [0.273, 0.275, 0.277, 0.275, 0.276] length: 5 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#a-list-stores-many-values-in-a-single-structure",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#a-list-stores-many-values-in-a-single-structure"
  },"313": {
    "doc": "Lists",
    "title": "Use an item’s index to fetch it from a list.",
    "content": ". | Just like strings. | . print('zeroth item of pressures:', pressures[0]) print('fourth item of pressures:', pressures[4]) . zeroth item of pressures: 0.273 fourth item of pressures: 0.276 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#use-an-items-index-to-fetch-it-from-a-list",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#use-an-items-index-to-fetch-it-from-a-list"
  },"314": {
    "doc": "Lists",
    "title": "Lists’ values can be replaced by assigning to them.",
    "content": ". | Use an index expression on the left of assignment to replace a value. | . pressures[0] = 0.265 print('pressures is now:', pressures) . pressures is now: [0.265, 0.275, 0.277, 0.275, 0.276] . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#lists-values-can-be-replaced-by-assigning-to-them",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#lists-values-can-be-replaced-by-assigning-to-them"
  },"315": {
    "doc": "Lists",
    "title": "Appending items to a list lengthens it.",
    "content": ". | Use list_name.append to add items to the end of a list. | . primes = [2, 3, 5] print('primes is initially:', primes) primes.append(7) print('primes has become:', primes) . primes is initially: [2, 3, 5] primes has become: [2, 3, 5, 7] . | append is a method of lists. | Like a function, but tied to a particular object. | . | Use object_name.method_name to call methods. | Deliberately resembles the way we refer to things in a library. | . | We will meet other methods of lists as we go along. | Use help(list) for a preview. | . | extend is similar to append, but it allows you to combine two lists. For example: | . teen_primes = [11, 13, 17, 19] middle_aged_primes = [37, 41, 43, 47] print('primes is currently:', primes) primes.extend(teen_primes) print('primes has now become:', primes) primes.append(middle_aged_primes) print('primes has finally become:', primes) . primes is currently: [2, 3, 5, 7] primes has now become: [2, 3, 5, 7, 11, 13, 17, 19] primes has finally become: [2, 3, 5, 7, 11, 13, 17, 19, [37, 41, 43, 47]] . Note that while extend maintains the “flat” structure of the list, appending a list to a list makes the result two-dimensional - the last element in primes is a list, not an integer. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#appending-items-to-a-list-lengthens-it",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#appending-items-to-a-list-lengthens-it"
  },"316": {
    "doc": "Lists",
    "title": "Use del to remove items from a list entirely.",
    "content": ". | We use del list_name[index] to remove an element from a list (in the example, 9 is not a prime number) and thus shorten it. | del is not a function or a method, but a statement in the language. | . primes = [2, 3, 5, 7, 9] print('primes before removing last item:', primes) del primes[4] print('primes after removing last item:', primes) . primes before removing last item: [2, 3, 5, 7, 9] primes after removing last item: [2, 3, 5, 7] . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#use-del-to-remove-items-from-a-list-entirely",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#use-del-to-remove-items-from-a-list-entirely"
  },"317": {
    "doc": "Lists",
    "title": "The empty list contains no values.",
    "content": ". | Use [] on its own to represent a list that doesn’t contain any values. | “The zero of lists.” | . | Helpful as a starting point for collecting values | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#the-empty-list-contains-no-values",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#the-empty-list-contains-no-values"
  },"318": {
    "doc": "Lists",
    "title": "Lists may contain values of different types.",
    "content": ". | A single list may contain numbers, strings, and anything else. | . goals = [1, 'Create lists.', 2, 'Extract items from lists.', 3, 'Modify lists.'] . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#lists-may-contain-values-of-different-types",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#lists-may-contain-values-of-different-types"
  },"319": {
    "doc": "Lists",
    "title": "Character strings can be indexed like lists.",
    "content": ". | Get single characters from a character string using indexes in square brackets. | . element = 'carbon' print('zeroth character:', element[0]) print('third character:', element[3]) . zeroth character: c third character: b . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#character-strings-can-be-indexed-like-lists",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#character-strings-can-be-indexed-like-lists"
  },"320": {
    "doc": "Lists",
    "title": "Character strings are immutable.",
    "content": ". | Cannot change the characters in a string after it has been created. | Immutable: can’t be changed after creation. | In contrast, lists are mutable: they can be modified in place. | . | Python considers the string to be a single value with parts, not a collection of values. | . element[0] = 'C' . TypeError: 'str' object does not support item assignment . | Lists and character strings are both collections. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#character-strings-are-immutable",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#character-strings-are-immutable"
  },"321": {
    "doc": "Lists",
    "title": "Indexing beyond the end of the collection is an error.",
    "content": ". | Python reports an IndexError if we attempt to access a value that doesn’t exist. | This is a kind of runtime error. | Cannot be detected as the code is parsed because the index might be calculated based on data. | . | . print('99th element of element is:', element[99]) . IndexError: string index out of range . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#indexing-beyond-the-end-of-the-collection-is-an-error",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#indexing-beyond-the-end-of-the-collection-is-an-error"
  },"322": {
    "doc": "Lists",
    "title": "Fill in the Blanks",
    "content": "Fill in the blanks so that the program below produces the output shown. values = ____ values.____(1) values.____(3) values.____(5) print('first time:', values) values = values[____] print('second time:', values) . first time: [1, 3, 5] second time: [3, 5] . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#fill-in-the-blanks",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#fill-in-the-blanks"
  },"323": {
    "doc": "Lists",
    "title": "Solution",
    "content": "values = [] values.append(1) values.append(3) values.append(5) print('first time:', values) values = values[1:] print('second time:', values) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#solution",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#solution"
  },"324": {
    "doc": "Lists",
    "title": "How Large is a Slice?",
    "content": "If start and stop are both non-negative integers, how long is the list values[start:stop]? . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#how-large-is-a-slice",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#how-large-is-a-slice"
  },"325": {
    "doc": "Lists",
    "title": "Solution",
    "content": "The list values[start:stop] has up to stop - start elements. For example, values[1:4] has the 3 elements values[1], values[2], and values[3]. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#solution-1",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#solution-1"
  },"326": {
    "doc": "Lists",
    "title": "From Strings to Lists and Back",
    "content": "Given this: . print('string to list:', list('tin')) print('list to string:', ''.join(['g', 'o', 'l', 'd'])) . string to list: ['t', 'i', 'n'] list to string: gold . | What does list('some string') do? | What does '-'.join(['x', 'y', 'z']) generate? | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#from-strings-to-lists-and-back",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#from-strings-to-lists-and-back"
  },"327": {
    "doc": "Lists",
    "title": "Solution",
    "content": ". | list('some string') converts a string into a list containing all of its characters. | join returns a string that is the concatenation of each string element in the list and adds the separator between each element in the list. This results in x-y-z. The separator between the elements is the string that provides this method. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#solution-2",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#solution-2"
  },"328": {
    "doc": "Lists",
    "title": "Working With the End",
    "content": "What does the following program print? . element = 'helium' print(element[-1]) . | How does Python interpret a negative index? | If a list or string has N elements, what is the most negative index that can safely be used with it, and what location does that index represent? | If values is a list, what does del values[-1] do? | How can you display all elements but the last one without changing values? (Hint: you will need to combine slicing and negative indexing.) | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#working-with-the-end",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#working-with-the-end"
  },"329": {
    "doc": "Lists",
    "title": "Solution",
    "content": "The program prints m. | Python interprets a negative index as starting from the end (as opposed to starting from the beginning). The last element is -1. | The last index that can safely be used with a list of N elements is element -N, which represents the first element. | del values[-1] removes the last element from the list. | values[:-1] | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#solution-3",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#solution-3"
  },"330": {
    "doc": "Lists",
    "title": "Stepping Through a List",
    "content": "What does the following program print? . element = 'fluorine' print(element[::2]) print(element[::-1]) . | If we write a slice as low:high:stride, what does stride do? | What expression would select all of the even-numbered items from a collection? | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#stepping-through-a-list",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#stepping-through-a-list"
  },"331": {
    "doc": "Lists",
    "title": "Solution",
    "content": "The program prints . furn eniroulf . | stride is the step size of the slice. | The slice 1::2 selects all even-numbered items from a collection: it starts with element 1 (which is the second element, since indexing starts at 0), goes on until the end (since no end is given), and uses a step size of 2 (i.e., selects every second element). | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#solution-4",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#solution-4"
  },"332": {
    "doc": "Lists",
    "title": "Slice Bounds",
    "content": "What does the following program print? . element = 'lithium' print(element[0:20]) print(element[-1:3]) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#slice-bounds",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#slice-bounds"
  },"333": {
    "doc": "Lists",
    "title": "Solution",
    "content": "lithium . The first statement prints the whole string, since the slice goes beyond the total length of the string. The second statement returns an empty string, because the slice goes “out of bounds” of the string. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#solution-5",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#solution-5"
  },"334": {
    "doc": "Lists",
    "title": "Sort and Sorted",
    "content": "What do these two programs print? In simple terms, explain the difference between sorted(letters) and letters.sort(). # Program A letters = list('gold') result = sorted(letters) print('letters is', letters, 'and result is', result) . # Program B letters = list('gold') result = letters.sort() print('letters is', letters, 'and result is', result) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#sort-and-sorted",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#sort-and-sorted"
  },"335": {
    "doc": "Lists",
    "title": "Solution",
    "content": "Program A prints . letters is ['g', 'o', 'l', 'd'] and result is ['d', 'g', 'l', 'o'] . Program B prints . letters is ['d', 'g', 'l', 'o'] and result is None . sorted(letters) returns a sorted copy of the list letters (the original list letters remains unchanged), while letters.sort() sorts the list letters in-place and does not return anything. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#solution-6",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#solution-6"
  },"336": {
    "doc": "Lists",
    "title": "Copying (or Not)",
    "content": "What do these two programs print? In simple terms, explain the difference between new = old and new = old[:]. # Program A old = list('gold') new = old # simple assignment new[0] = 'D' print('new is', new, 'and old is', old) . # Program B old = list('gold') new = old[:] # assigning a slice new[0] = 'D' print('new is', new, 'and old is', old) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#copying-or-not",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#copying-or-not"
  },"337": {
    "doc": "Lists",
    "title": "Solution",
    "content": "Program A prints . new is ['D', 'o', 'l', 'd'] and old is ['D', 'o', 'l', 'd'] . Program B prints . new is ['D', 'o', 'l', 'd'] and old is ['g', 'o', 'l', 'd'] . new = old makes new a reference to the list old; new and old point towards the same object. new = old[:] however creates a new list object new containing all elements from the list old; new and old are different objects. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html#solution-7",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html#solution-7"
  },"338": {
    "doc": "Lists",
    "title": " Python reports a runtime error when something goes wrong while a program is executing.",
    "content": "age = 53 remaining = 100 - aege # mis-spelled 'age' . NameError Traceback (most recent call last) &lt;ipython-input-59-1214fb6c55fc&gt; in &lt;module&gt; 1 age = 53 ----&gt; 2 remaining = 100 - aege # mis-spelled 'age' NameError: name 'aege' is not defined . | Fix syntax errors by reading the source and runtime errors by tracing execution. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/09_Lists.html",
    "relUrl": "/Python_Series_Materials/part_3/09_Lists.html"
  },"339": {
    "doc": "For Loops",
    "title": "For Loops",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html"
  },"340": {
    "doc": "For Loops",
    "title": "A for loop executes commands once for each value in a collection.",
    "content": ". | Doing calculations on the values in a list one by one is as painful as working with pressure_001, pressure_002, etc. | A for loop tells Python to execute some statements once for each value in a list, a character string, or some other collection. | “for each thing in this group, do these operations” | . for number in [2, 3, 5]: print(number) . | This for loop is equivalent to: | . print(2) print(3) print(5) . | And the for loop’s output is: | . 2 3 5 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html#a-for-loop-executes-commands-once-for-each-value-in-a-collection",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html#a-for-loop-executes-commands-once-for-each-value-in-a-collection"
  },"341": {
    "doc": "For Loops",
    "title": "A for loop is made up of a collection, a loop variable, and a body.",
    "content": "for number in [2, 3, 5]: print(number) . | The collection, [2, 3, 5], is what the loop is being run on. | The body, print(number), specifies what to do for each value in the collection. | The loop variable, number, is what changes for each iteration of the loop. | The “current thing”. | . | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html#a-for-loop-is-made-up-of-a-collection-a-loop-variable-and-a-body",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html#a-for-loop-is-made-up-of-a-collection-a-loop-variable-and-a-body"
  },"342": {
    "doc": "For Loops",
    "title": "The first line of the for loop must end with a colon, and the body must be indented.",
    "content": ". | The colon at the end of the first line signals the start of a block of statements. | Python uses indentation rather than {} or begin/end to show nesting. | Any consistent indentation is legal, but almost everyone uses four spaces. | . | . for number in [2, 3, 5]: print(number) . IndentationError: expected an indented block . | Indentation is always meaningful in Python. | . firstName = \"Jon\" lastName = \"Smith\" . File \"&lt;ipython-input-7-f65f2962bf9c&gt;\", line 2 lastName = \"Smith\" ^ IndentationError: unexpected indent . | This error can be fixed by removing the extra spaces at the beginning of the second line. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html#the-first-line-of-the-for-loop-must-end-with-a-colon-and-the-body-must-be-indented",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html#the-first-line-of-the-for-loop-must-end-with-a-colon-and-the-body-must-be-indented"
  },"343": {
    "doc": "For Loops",
    "title": "Loop variables can be called anything.",
    "content": ". | As with all variables, loop variables are: . | Created on demand. | Meaningless: their names can be anything at all. | . | . for kitten in [2, 3, 5]: print(kitten) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html#loop-variables-can-be-called-anything",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html#loop-variables-can-be-called-anything"
  },"344": {
    "doc": "For Loops",
    "title": "The body of a loop can contain many statements.",
    "content": ". | But no loop should be more than a few lines long. | Hard for human beings to keep larger chunks of code in mind. | . primes = [2, 3, 5] for p in primes: squared = p ** 2 cubed = p ** 3 print(p, squared, cubed) . 2 4 8 3 9 27 5 25 125 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html#the-body-of-a-loop-can-contain-many-statements",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html#the-body-of-a-loop-can-contain-many-statements"
  },"345": {
    "doc": "For Loops",
    "title": "Use range to iterate over a sequence of numbers.",
    "content": ". | The built-in function range produces a sequence of numbers. | Not a list: the numbers are produced on demand to make looping over large ranges more efficient. | . | range(N) is the numbers 0..N-1 . | Exactly the legal indices of a list or character string of length N | . | . print('a range is not a list: range(0, 3)') for number in range(0, 3): print(number) . a range is not a list: range(0, 3) 0 1 2 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html#use-range-to-iterate-over-a-sequence-of-numbers",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html#use-range-to-iterate-over-a-sequence-of-numbers"
  },"346": {
    "doc": "For Loops",
    "title": "The Accumulator pattern turns many values into one.",
    "content": ". | A common pattern in programs is to: . | Initialize an accumulator variable to zero, the empty string, or the empty list. | Update the variable with values from a collection. | . | . # Sum the first 10 integers. total = 0 for number in range(10): total = total + (number + 1) print(total) . 55 . | Read total = total + (number + 1) as: . | Add 1 to the current value of the loop variable number. | Add that to the current value of the accumulator variable total. | Assign that to total, replacing the current value. | . | We have to add number + 1 because range produces 0..9, not 1..10. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html#the-accumulator-pattern-turns-many-values-into-one",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html#the-accumulator-pattern-turns-many-values-into-one"
  },"347": {
    "doc": "For Loops",
    "title": "Classifying Errors",
    "content": "Is an indentation error a syntax error or a runtime error? . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html#classifying-errors",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html#classifying-errors"
  },"348": {
    "doc": "For Loops",
    "title": "Solution",
    "content": "An IndentationError is a syntax error. Programs with syntax errors cannot be started. A program with a runtime error will start but an error will be thrown under certain conditions. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html#solution",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html#solution"
  },"349": {
    "doc": "For Loops",
    "title": "Tracing Execution",
    "content": "Create a table showing the numbers of the lines that are executed when this program runs, and the values of the variables after each line is executed. total = 0 for char in \"tin\": total = total + 1 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html#tracing-execution",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html#tracing-execution"
  },"350": {
    "doc": "For Loops",
    "title": "Solution",
    "content": "| Line no | Variables | . | 1 | total = 0 | . | 2 | total = 0 char = ‘t’ | . | 3 | total = 1 char = ‘t’ | . | 2 | total = 1 char = ‘i’ | . | 3 | total = 2 char = ‘i’ | . | 2 | total = 2 char = ‘n’ | . | 3 | total = 3 char = ‘n’ | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html#solution-1",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html#solution-1"
  },"351": {
    "doc": "For Loops",
    "title": "Reversing a String",
    "content": "Fill in the blanks in the program below so that it prints “nit” (the reverse of the original character string “tin”). original = \"tin\" result = ____ for char in original: result = ____ print(result) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html#reversing-a-string",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html#reversing-a-string"
  },"352": {
    "doc": "For Loops",
    "title": "Solution",
    "content": "original = \"tin\" result = \"\" for char in original: result = char + result print(result) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html#solution-2",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html#solution-2"
  },"353": {
    "doc": "For Loops",
    "title": "Practice Accumulating",
    "content": "Fill in the blanks in each of the programs below to produce the indicated result. # Total length of the strings in the list: [\"red\", \"green\", \"blue\"] =&gt; 12 total = 0 for word in [\"red\", \"green\", \"blue\"]: ____ = ____ + len(word) print(total) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html#practice-accumulating",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html#practice-accumulating"
  },"354": {
    "doc": "For Loops",
    "title": "Solution",
    "content": "total = 0 for word in [\"red\", \"green\", \"blue\"]: total = total + len(word) print(total) . # List of word lengths: [\"red\", \"green\", \"blue\"] =&gt; [3, 5, 4] lengths = ____ for word in [\"red\", \"green\", \"blue\"]: lengths.____(____) print(lengths) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html#solution-3",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html#solution-3"
  },"355": {
    "doc": "For Loops",
    "title": "Solution",
    "content": "lengths = [] for word in [\"red\", \"green\", \"blue\"]: lengths.append(len(word)) print(lengths) . # Concatenate all words: [\"red\", \"green\", \"blue\"] =&gt; \"redgreenblue\" words = [\"red\", \"green\", \"blue\"] result = ____ for ____ in ____: ____ print(result) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html#solution-4",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html#solution-4"
  },"356": {
    "doc": "For Loops",
    "title": "Solution",
    "content": "words = [\"red\", \"green\", \"blue\"] result = \"\" for word in words: result = result + word print(result) . Create an acronym: Starting from the list [\"red\", \"green\", \"blue\"], create the acronym \"RGB\" using a for loop. Hint: You may need to use a string method to properly format the acronym. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html#solution-5",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html#solution-5"
  },"357": {
    "doc": "For Loops",
    "title": "Solution",
    "content": "acronym = \"\" for word in [\"red\", \"green\", \"blue\"]: acronym = acronym + word[0].upper() print(acronym) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html#solution-6",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html#solution-6"
  },"358": {
    "doc": "For Loops",
    "title": "Cumulative Sum",
    "content": "Reorder and properly indent the lines of code below so that they print a list with the cumulative sum of data. The result should be [1, 3, 5, 10]. cumulative.append(total) for number in data: cumulative = [] total = total + number total = 0 print(cumulative) data = [1,2,2,5] . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html#cumulative-sum",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html#cumulative-sum"
  },"359": {
    "doc": "For Loops",
    "title": "Solution",
    "content": "total = 0 data = [1,2,2,5] cumulative = [] for number in data: total = total + number cumulative.append(total) print(cumulative) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html#solution-7",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html#solution-7"
  },"360": {
    "doc": "For Loops",
    "title": "Identifying Variable Name Errors",
    "content": ". | Read the code below and try to identify what the errors are without running it. | Run the code and read the error message. What type of NameError do you think this is? Is it a string with no quotes, a misspelled variable, or a variable that should have been defined but was not? | Fix the error. | Repeat steps 2 and 3, until you have fixed all the errors. | . for number in range(10): # use a if the number is a multiple of 3, otherwise use b if (Number % 3) == 0: message = message + a else: message = message + \"b\" print(message) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html#identifying-variable-name-errors",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html#identifying-variable-name-errors"
  },"361": {
    "doc": "For Loops",
    "title": "Solution",
    "content": ". | Python variable names are case sensitive: number and Number refer to different variables. | The variable message needs to be initialized as an empty string. | We want to add the string \"a\" to message, not the undefined variable a. | . message = \"\" for number in range(10): # use a if the number is a multiple of 3, otherwise use b if (number % 3) == 0: message = message + \"a\" else: message = message + \"b\" print(message) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html#solution-8",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html#solution-8"
  },"362": {
    "doc": "For Loops",
    "title": "Identifying Item Errors",
    "content": ". | Read the code below and try to identify what the errors are without running it. | Run the code, and read the error message. What type of error is it? | Fix the error. | . seasons = ['Spring', 'Summer', 'Fall', 'Winter'] print('My favorite season is ', seasons[4]) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html#identifying-item-errors",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html#identifying-item-errors"
  },"363": {
    "doc": "For Loops",
    "title": "Solution",
    "content": "This list has 4 elements and the index to access the last element in the list is 3. seasons = ['Spring', 'Summer', 'Fall', 'Winter'] print('My favorite season is ', seasons[3]) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/10_For_Loops.html#solution-9",
    "relUrl": "/Python_Series_Materials/part_3/10_For_Loops.html#solution-9"
  },"364": {
    "doc": "Conditionals",
    "title": "Conditionals",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/11_Conditionals.html",
    "relUrl": "/Python_Series_Materials/part_3/11_Conditionals.html"
  },"365": {
    "doc": "Conditionals",
    "title": "Use if statements to control whether or not a block of code is executed.",
    "content": ". | An if statement (more properly called a conditional statement) controls whether some block of code is executed or not. | Structure is similar to a for statement: . | First line opens with if and ends with a colon | Body containing one or more statements is indented (usually by 4 spaces) | . | . mass = 3.54 if mass &gt; 3.0: print(mass, 'is large') mass = 2.07 if mass &gt; 3.0: print (mass, 'is large') . 3.54 is large . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/11_Conditionals.html#use-if-statements-to-control-whether-or-not-a-block-of-code-is-executed",
    "relUrl": "/Python_Series_Materials/part_3/11_Conditionals.html#use-if-statements-to-control-whether-or-not-a-block-of-code-is-executed"
  },"366": {
    "doc": "Conditionals",
    "title": "Conditionals are often used inside loops.",
    "content": ". | Not much point using a conditional when we know the value (as above). | But useful when we have a collection to process. | . masses = [3.54, 2.07, 9.22, 1.86, 1.71] for m in masses: if m &gt; 3.0: print(m, 'is large') . 3.54 is large 9.22 is large . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/11_Conditionals.html#conditionals-are-often-used-inside-loops",
    "relUrl": "/Python_Series_Materials/part_3/11_Conditionals.html#conditionals-are-often-used-inside-loops"
  },"367": {
    "doc": "Conditionals",
    "title": "Use else to execute a block of code when an if condition is not true.",
    "content": ". | else can be used following an if. | Allows us to specify an alternative to execute when the if branch isn’t taken. | . masses = [3.54, 2.07, 9.22, 1.86, 1.71] for m in masses: if m &gt; 3.0: print(m, 'is large') else: print(m, 'is small') . 3.54 is large 2.07 is small 9.22 is large 1.86 is small 1.71 is small . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/11_Conditionals.html#use-else-to-execute-a-block-of-code-when-an-if-condition-is-not-true",
    "relUrl": "/Python_Series_Materials/part_3/11_Conditionals.html#use-else-to-execute-a-block-of-code-when-an-if-condition-is-not-true"
  },"368": {
    "doc": "Conditionals",
    "title": "Use elif to specify additional tests.",
    "content": ". | May want to provide several alternative choices, each with its own test. | Use elif (short for “else if”) and a condition to specify these. | Always associated with an if. | Must come before the else (which is the “catch all”). | . masses = [3.54, 2.07, 9.22, 1.86, 1.71] for m in masses: if m &gt; 9.0: print(m, 'is HUGE') elif m &gt; 3.0: print(m, 'is large') else: print(m, 'is small') . 3.54 is large 2.07 is small 9.22 is HUGE 1.86 is small 1.71 is small . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/11_Conditionals.html#use-elif-to-specify-additional-tests",
    "relUrl": "/Python_Series_Materials/part_3/11_Conditionals.html#use-elif-to-specify-additional-tests"
  },"369": {
    "doc": "Conditionals",
    "title": "Conditions are tested once, in order.",
    "content": ". | Python steps through the branches of the conditional in order, testing each in turn. | So ordering matters. | . grade = 85 if grade &gt;= 70: print('grade is C') elif grade &gt;= 80: print('grade is B') elif grade &gt;= 90: print('grade is A') . grade is C . | Does not automatically go back and re-evaluate if values change. | . velocity = 10.0 if velocity &gt; 20.0: print('moving too fast') else: print('adjusting velocity') velocity = 50.0 . adjusting velocity . | Often use conditionals in a loop to “evolve” the values of variables. | . velocity = 10.0 for i in range(5): # execute the loop 5 times print(i, ':', velocity) if velocity &gt; 20.0: print('moving too fast') velocity = velocity - 5.0 else: print('moving too slow') velocity = velocity + 10.0 print('final velocity:', velocity) . 0 : 10.0 moving too slow 1 : 20.0 moving too slow 2 : 30.0 moving too fast 3 : 25.0 moving too fast 4 : 20.0 moving too slow final velocity: 30.0 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/11_Conditionals.html#conditions-are-tested-once-in-order",
    "relUrl": "/Python_Series_Materials/part_3/11_Conditionals.html#conditions-are-tested-once-in-order"
  },"370": {
    "doc": "Conditionals",
    "title": "Create a table showing variables’ values to trace a program’s execution.",
    "content": "| i | 0 | . | 1 | . | 2 | . | 3 | . | 4 | . | . | velocity | 10.0 | 20.0 | . | 30.0 | . | 25.0 | . | 20.0 | . | 30.0 | . | The program must have a print statement outside the body of the loop to show the final value of velocity, since its value is updated by the last iteration of the loop. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/11_Conditionals.html#create-a-table-showing-variables-values-to-trace-a-programs-execution",
    "relUrl": "/Python_Series_Materials/part_3/11_Conditionals.html#create-a-table-showing-variables-values-to-trace-a-programs-execution"
  },"371": {
    "doc": "Conditionals",
    "title": "Compound Relations Using and, or, and Parentheses",
    "content": "Often, you want some combination of things to be true. You can combine relations within a conditional using and and or. Continuing the example above, suppose you have . mass = [ 3.54, 2.07, 9.22, 1.86, 1.71] velocity = [10.00, 20.00, 30.00, 25.00, 20.00] i = 0 for i in range(5): if mass[i] &gt; 5 and velocity[i] &gt; 20: print(\"Fast heavy object. Duck!\") elif mass[i] &gt; 2 and mass[i] &lt;= 5 and velocity[i] &lt;= 20: print(\"Normal traffic\") elif mass[i] &lt;= 2 and velocity[i] &lt;= 20: print(\"Slow light object. Ignore it\") else: print(\"Whoa! Something is up with the data. Check it\") . Just like with arithmetic, you can and should use parentheses whenever there is possible ambiguity. A good general rule is to always use parentheses when mixing and and or in the same condition. That is, instead of: . if mass[i] &lt;= 2 or mass[i] &gt;= 5 and velocity[i] &gt; 20: . write one of these: . if (mass[i] &lt;= 2 or mass[i] &gt;= 5) and velocity[i] &gt; 20: if mass[i] &lt;= 2 or (mass[i] &gt;= 5 and velocity[i] &gt; 20): . so it is perfectly clear to a reader (and to Python) what you really mean. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/11_Conditionals.html#compound-relations-using-and-or-and-parentheses",
    "relUrl": "/Python_Series_Materials/part_3/11_Conditionals.html#compound-relations-using-and-or-and-parentheses"
  },"372": {
    "doc": "Conditionals",
    "title": "Tracing Execution",
    "content": "What does this program print? . pressure = 71.9 if pressure &gt; 50.0: pressure = 25.0 elif pressure &lt;= 50.0: pressure = 0.0 print(pressure) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/11_Conditionals.html#tracing-execution",
    "relUrl": "/Python_Series_Materials/part_3/11_Conditionals.html#tracing-execution"
  },"373": {
    "doc": "Conditionals",
    "title": "Solution",
    "content": "25.0 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/11_Conditionals.html#solution",
    "relUrl": "/Python_Series_Materials/part_3/11_Conditionals.html#solution"
  },"374": {
    "doc": "Conditionals",
    "title": "Trimming Values",
    "content": "Fill in the blanks so that this program creates a new list containing zeroes where the original list’s values were negative and ones where the original list’s values were positive. original = [-1.5, 0.2, 0.4, 0.0, -1.3, 0.4] result = ____ for value in original: if ____: result.append(0) else: ____ print(result) . [0, 1, 1, 1, 0, 1] . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/11_Conditionals.html#trimming-values",
    "relUrl": "/Python_Series_Materials/part_3/11_Conditionals.html#trimming-values"
  },"375": {
    "doc": "Conditionals",
    "title": "Solution",
    "content": "original = [-1.5, 0.2, 0.4, 0.0, -1.3, 0.4] result = [] for value in original: if value &lt; 0.0: result.append(0) else: result.append(1) print(result) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/11_Conditionals.html#solution-1",
    "relUrl": "/Python_Series_Materials/part_3/11_Conditionals.html#solution-1"
  },"376": {
    "doc": "Conditionals",
    "title": "Processing Small Files",
    "content": "Modify this program so that it only processes files with fewer than 50 records. import glob import pandas as pd for filename in glob.glob('data/*.csv'): contents = pd.read_csv(filename) ____: print(filename, len(contents)) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/11_Conditionals.html#processing-small-files",
    "relUrl": "/Python_Series_Materials/part_3/11_Conditionals.html#processing-small-files"
  },"377": {
    "doc": "Conditionals",
    "title": "Solution",
    "content": "import glob import pandas as pd for filename in glob.glob('data/*.csv'): contents = pd.read_csv(filename) if len(contents) &lt; 50: print(filename, len(contents)) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/11_Conditionals.html#solution-2",
    "relUrl": "/Python_Series_Materials/part_3/11_Conditionals.html#solution-2"
  },"378": {
    "doc": "Conditionals",
    "title": "Initializing",
    "content": "Modify this program so that it finds the largest and smallest values in the list no matter what the range of values originally is. values = [...some test data...] smallest, largest = None, None for v in values: if ____: smallest, largest = v, v ____: smallest = min(____, v) largest = max(____, v) print(smallest, largest) . What are the advantages and disadvantages of using this method to find the range of the data? . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/11_Conditionals.html#initializing",
    "relUrl": "/Python_Series_Materials/part_3/11_Conditionals.html#initializing"
  },"379": {
    "doc": "Conditionals",
    "title": "Solution",
    "content": "values = [-2,1,65,78,-54,-24,100] smallest, largest = None, None for v in values: if smallest is None and largest is None: smallest, largest = v, v else: smallest = min(smallest, v) largest = max(largest, v) print(smallest, largest) . If you wrote == None instead of is None, that works too, but Python programmers always write is None because of the special way None works in the language. It can be argued that an advantage of using this method would be to make the code more readable. However, a disadvantage is that this code is not efficient because within each iteration of the for loop statement, there are two more loops that run over two numbers each (the min and max functions). It would be more efficient to iterate over each number just once: . values = [-2,1,65,78,-54,-24,100] smallest, largest = None, None for v in values: if smallest is None or v &lt; smallest: smallest = v if largest is None or v &gt; largest: largest = v print(smallest, largest) . Now we have one loop, but four comparison tests. There are two ways we could improve it further: either use fewer comparisons in each iteration, or use two loops that each contain only one comparison test. The simplest solution is often the best: . values = [-2,1,65,78,-54,-24,100] smallest = min(values) largest = max(values) print(smallest, largest) . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/11_Conditionals.html#solution-3",
    "relUrl": "/Python_Series_Materials/part_3/11_Conditionals.html#solution-3"
  },"380": {
    "doc": "Looping over Datasets",
    "title": "Looping over Datasets",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/12_Looping_over_Datasets.html",
    "relUrl": "/Python_Series_Materials/part_3/12_Looping_over_Datasets.html"
  },"381": {
    "doc": "Looping over Datasets",
    "title": "Use a for loop to process files given a list of their names.",
    "content": ". | A filename is a character string. | And lists can contain character strings. | . import pandas as pd for filename in ['data/gapminder_gdp_africa.csv', 'data/gapminder_gdp_asia.csv']: data = pd.read_csv(filename, index_col='country') print(filename, data.min()) . data/gapminder_gdp_africa.csv gdpPercap_1952 298.846212 gdpPercap_1957 335.997115 gdpPercap_1962 355.203227 gdpPercap_1967 412.977514 ⋮ ⋮ ⋮ gdpPercap_1997 312.188423 gdpPercap_2002 241.165877 gdpPercap_2007 277.551859 dtype: float64 data/gapminder_gdp_asia.csv gdpPercap_1952 331 gdpPercap_1957 350 gdpPercap_1962 388 gdpPercap_1967 349 ⋮ ⋮ ⋮ gdpPercap_1997 415 gdpPercap_2002 611 gdpPercap_2007 944 dtype: float64 . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/12_Looping_over_Datasets.html#use-a-for-loop-to-process-files-given-a-list-of-their-names",
    "relUrl": "/Python_Series_Materials/part_3/12_Looping_over_Datasets.html#use-a-for-loop-to-process-files-given-a-list-of-their-names"
  },"382": {
    "doc": "Looping over Datasets",
    "title": "Use glob.glob to find sets of files whose names match a pattern.",
    "content": ". | In Unix, the term “globbing” means “matching a set of files with a pattern”. | The most common patterns are: . | * meaning “match zero or more characters” | ? meaning “match exactly one character” | . | Python’s standard library contains the glob module to provide pattern matching functionality | The glob module contains a function also called glob to match file patterns | E.g., glob.glob('*.txt') matches all files in the current directory whose names end with .txt. | Result is a (possibly empty) list of character strings. | . import glob print('all csv files in data directory:', glob.glob('data/*.csv')) . all csv files in data directory: ['data/gapminder_all.csv', 'data/gapminder_gdp_africa.csv', \\ 'data/gapminder_gdp_americas.csv', 'data/gapminder_gdp_asia.csv', 'data/gapminder_gdp_europe.csv', \\ 'data/gapminder_gdp_oceania.csv'] . print('all PDB files:', glob.glob('*.pdb')) . all PDB files: [] . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/12_Looping_over_Datasets.html#use-globglob-to-find-sets-of-files-whose-names-match-a-pattern",
    "relUrl": "/Python_Series_Materials/part_3/12_Looping_over_Datasets.html#use-globglob-to-find-sets-of-files-whose-names-match-a-pattern"
  },"383": {
    "doc": "Looping over Datasets",
    "title": "Use glob and for to process batches of files.",
    "content": ". | Helps a lot if the files are named and stored systematically and consistently so that simple patterns will find the right data. | . for filename in glob.glob('data/gapminder_*.csv'): data = pd.read_csv(filename) print(filename, data['gdpPercap_1952'].min()) . data/gapminder_all.csv 298.8462121 data/gapminder_gdp_africa.csv 298.8462121 data/gapminder_gdp_americas.csv 1397.717137 data/gapminder_gdp_asia.csv 331.0 data/gapminder_gdp_europe.csv 973.5331948 data/gapminder_gdp_oceania.csv 10039.59564 . | This includes all data, as well as per-region data. | Use a more specific pattern in the exercises to exclude the whole data set. | But note that the minimum of the entire data set is also the minimum of one of the data sets, which is a nice check on correctness. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/12_Looping_over_Datasets.html#use-glob-and-for-to-process-batches-of-files",
    "relUrl": "/Python_Series_Materials/part_3/12_Looping_over_Datasets.html#use-glob-and-for-to-process-batches-of-files"
  },"384": {
    "doc": "Looping over Datasets",
    "title": "Determining Matches",
    "content": "Which of these files is not matched by the expression glob.glob('data/*as*.csv')? . | data/gapminder_gdp_africa.csv | data/gapminder_gdp_americas.csv | data/gapminder_gdp_asia.csv | . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/12_Looping_over_Datasets.html#determining-matches",
    "relUrl": "/Python_Series_Materials/part_3/12_Looping_over_Datasets.html#determining-matches"
  },"385": {
    "doc": "Looping over Datasets",
    "title": "Solution",
    "content": "1 is not matched by the glob. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/12_Looping_over_Datasets.html#solution",
    "relUrl": "/Python_Series_Materials/part_3/12_Looping_over_Datasets.html#solution"
  },"386": {
    "doc": "Looping over Datasets",
    "title": "Minimum File Size",
    "content": "Modify this program so that it prints the number of records in the file that has the fewest records. import glob import pandas as pd fewest = ____ for filename in glob.glob('data/*.csv'): dataframe = pd.____(filename) fewest = min(____, dataframe.shape[0]) print('smallest file has', fewest, 'records') . Note that the DataFrame.shape() method returns a tuple with the number of rows and columns of the data frame. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/12_Looping_over_Datasets.html#minimum-file-size",
    "relUrl": "/Python_Series_Materials/part_3/12_Looping_over_Datasets.html#minimum-file-size"
  },"387": {
    "doc": "Looping over Datasets",
    "title": "Solution",
    "content": "import glob import pandas as pd fewest = float('Inf') for filename in glob.glob('data/*.csv'): dataframe = pd.read_csv(filename) fewest = min(fewest, dataframe.shape[0]) print('smallest file has', fewest, 'records') . You might have chosen to initialize the fewest variable with a number greater than the numbers you’re dealing with, but that could lead to trouble if you reuse the code with bigger numbers. Python lets you use positive infinity, which will work no matter how big your numbers are. What other special strings does the float function recognize? . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/12_Looping_over_Datasets.html#solution-1",
    "relUrl": "/Python_Series_Materials/part_3/12_Looping_over_Datasets.html#solution-1"
  },"388": {
    "doc": "Looping over Datasets",
    "title": "Comparing Data",
    "content": "Write a program that reads in the regional data sets and plots the average GDP per capita for each region over time in a single chart. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/12_Looping_over_Datasets.html#comparing-data",
    "relUrl": "/Python_Series_Materials/part_3/12_Looping_over_Datasets.html#comparing-data"
  },"389": {
    "doc": "Looping over Datasets",
    "title": "Solution",
    "content": "This solution builds a useful legend by using the string split method to extract the region from the path ‘data/gapminder_gdp_a_specific_region.csv’. import glob import pandas as pd import matplotlib.pyplot as plt fig, ax = plt.subplots(1,1) for filename in glob.glob('data/gapminder_gdp*.csv'): dataframe = pd.read_csv(filename) # extract &lt;region&gt; from the filename, expected to be in the format 'data/gapminder_gdp_&lt;region&gt;.csv'. # we will split the string using the split method and `_` as our separator, # retrieve the last string in the list that split returns (`&lt;region&gt;.csv`), # and then remove the `.csv` extension from that string. region = filename.split('_')[-1][:-4] dataframe.mean().plot(ax=ax, label=region) plt.legend() plt.show() . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/12_Looping_over_Datasets.html#solution-2",
    "relUrl": "/Python_Series_Materials/part_3/12_Looping_over_Datasets.html#solution-2"
  },"390": {
    "doc": "Looping over Datasets",
    "title": "Dealing with File Paths",
    "content": "The pathlib module provides useful abstractions for file and path manipulation like returning the name of a file without the file extension. This is very useful when looping over files and directories. In the example below, we create a Path object and inspect its attributes. from pathlib import Path p = Path(\"data/gapminder_gdp_africa.csv\") print(p.parent), print(p.stem), print(p.suffix) . data gapminder_gdp_africa .csv . Hint: It is possible to check all available attributes and methods on the Path object with the dir() function! . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/12_Looping_over_Datasets.html#dealing-with-file-paths",
    "relUrl": "/Python_Series_Materials/part_3/12_Looping_over_Datasets.html#dealing-with-file-paths"
  },"391": {
    "doc": "3. Advanced",
    "title": "So you want to get fancy?",
    "content": "I get it! . ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Pages_Materials/GH-Pages-Advanced.html#so-you-want-to-get-fancy",
    "relUrl": "/GH_Pages_Materials/GH-Pages-Advanced.html#so-you-want-to-get-fancy"
  },"392": {
    "doc": "3. Advanced",
    "title": "Recommended Workflow:",
    "content": "First, install Ruby and Jekyll. | See these great instructions for Mac and Windows. | Also recommended: Bundler. If you’ve installed Ruby and Jekyll following the instructions linked above, you should be able to install bundler with the following command: gem install jekyll bundler . | You’ll also want a good text editor, such as Atom. (Note: Atom is being sunsetted, so you will have to install an earlier version) . | Now, find a theme you like, go to it’s GitHub repository then… | . Step 1 . Clone the repo down to your local machine. From your terminal: . git clone https://github.com/pages-themes/hacker.git . Step 2 . Since you’ve installed Ruby, Jekyll, and Bundler, you can spin up your site locally with the following command: . bundle exec jekyll serve . Now you’re serving your site on your own computer! My default server address is http://127.0.0.1:4000, but check your prompt and it should tell you. Just open up your browser and go to that address. Step 3 . Now do whatever you want! . | Rather than the simple site we used in the hands-on example, this site has everything, including all of the styling. | The styling is found in the _sass and assests/css folder. | But note that this is not your standard CSS style sheet, most of the styling is managed by SASS. | Open it up in your favorite text editor and don’t forget to Have Fun! | . ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Pages_Materials/GH-Pages-Advanced.html#recommended-workflow",
    "relUrl": "/GH_Pages_Materials/GH-Pages-Advanced.html#recommended-workflow"
  },"393": {
    "doc": "3. Advanced",
    "title": "Publish your site!",
    "content": "Once you’ve finished going to town on your snappy website (and added and committed the changes to your repo), you can put it in a remote repository on GitHub. Step 1 . Create a new remote repository on GitHub . Step 2 . Copy the url of your new remote repository . Step 3 . In your terminal, navigate to the folder containing your site directory/repo. Reset the remote origin to your newly created GitHub repository: . git remote set-url origin https://github.com/your-user-name/your-repo.git . Step 4 . Now push your changes up to the remote repository: . git push origin main . *might also be master instead of main . Step 5 . Publish your site in the repository settings as shown in previous exercise. ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Pages_Materials/GH-Pages-Advanced.html#publish-your-site",
    "relUrl": "/GH_Pages_Materials/GH-Pages-Advanced.html#publish-your-site"
  },"394": {
    "doc": "3. Advanced",
    "title": "3. Advanced",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Pages_Materials/GH-Pages-Advanced.html",
    "relUrl": "/GH_Pages_Materials/GH-Pages-Advanced.html"
  },"395": {
    "doc": "1. Background Info",
    "title": "Background information",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Pages_Materials/GH-Pages-Background-Info.html#background-information",
    "relUrl": "/GH_Pages_Materials/GH-Pages-Background-Info.html#background-information"
  },"396": {
    "doc": "1. Background Info",
    "title": "Git &amp; GitHub",
    "content": "First of all, if you’re new to Git and GitHub, here are a few helpful resources. | What is Git (in a nutshell) . | If you’re totally new to Git, then I recommend reading over this. | Contains a lot of the basic concepts and terminology. | . | Introduction to the Command Line . | For folks new to the command line, this is a great introduction. | Includes fundamentals like navigating your file system through the command line interacting with files, plus a handy command reference guide. | . | What is GitHub? . | A quick guide to the basics of GitHub. | Creating a repository, commits, branches, pull requests. | . | Hands-On Git Tutorial . | If you want further practice, we have provided a brief Git Tutorial. | Includes a cheat sheet of commands and a hands-on example. | . | . ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Pages_Materials/GH-Pages-Background-Info.html#git--github",
    "relUrl": "/GH_Pages_Materials/GH-Pages-Background-Info.html#git--github"
  },"397": {
    "doc": "1. Background Info",
    "title": "GitHub Pages &amp; Jekyll",
    "content": ". | What is GitHub Pages? . | Walks through setting up a user/organizational site. | . | Jekyll Home &amp; Documentation . | GitHub Pages Supported Themes . | This is helpful if you need to get into the details of a theme or to troubleshoot problems if you’ve switched themes. | . | Remote Themes . | Even more themes for your pages site… | But your mileage may vary when using remote themes. You may want to clone the whole repo rather than adding using the remote_theme option in your _comfig.yml file. | . | Markdown Cheatsheet . | . ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Pages_Materials/GH-Pages-Background-Info.html#github-pages--jekyll",
    "relUrl": "/GH_Pages_Materials/GH-Pages-Background-Info.html#github-pages--jekyll"
  },"398": {
    "doc": "1. Background Info",
    "title": "Just a great tutorial",
    "content": ". | Building a static website with Jekyll and Github Pages . | This guide has a lot of great background info for beginners, particularly some of the tools you might want as you get more comfortable. | These are very good instructions for getting Ruby and Jekyll up and running locally for both Windows and Mac users. | . | . ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Pages_Materials/GH-Pages-Background-Info.html#just-a-great-tutorial",
    "relUrl": "/GH_Pages_Materials/GH-Pages-Background-Info.html#just-a-great-tutorial"
  },"399": {
    "doc": "1. Background Info",
    "title": "A few tech recommendations",
    "content": ". | Git . | Well, obviously. For the hands on portion of this exercise, you don’t need it… but you should install Git anyway if you don’t have it. | Windows users: Git comes with Git Bash, a Linux-style command prompt (aka “shell” aka “terminal”), which will make life easier. | . | Atom text editor . | If you don’t have a decent text editor, Atom is great and it’s free and open source. | . | . ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Pages_Materials/GH-Pages-Background-Info.html#a-few-tech-recommendations",
    "relUrl": "/GH_Pages_Materials/GH-Pages-Background-Info.html#a-few-tech-recommendations"
  },"400": {
    "doc": "1. Background Info",
    "title": "1. Background Info",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Pages_Materials/GH-Pages-Background-Info.html",
    "relUrl": "/GH_Pages_Materials/GH-Pages-Background-Info.html"
  },"401": {
    "doc": "2. Hands On",
    "title": "Time to press some buttons!",
    "content": "Overview . During this hands-on portion, you will fork a repository over to your own GitHub account, activate it as a website tied to your GitHub username, and work on adding new content and customizations. ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Pages_Materials/GH-Pages-Hands-On.html#time-to-press-some-buttons",
    "relUrl": "/GH_Pages_Materials/GH-Pages-Hands-On.html#time-to-press-some-buttons"
  },"402": {
    "doc": "2. Hands On",
    "title": "Fork the sample template repository",
    "content": "Step 1 . Go to our sample portfolio repository . Step 2 . Click the Fork button to make a copy of this repository on your own GitHub account: . Head over to your account to view your fork of this repo. ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Pages_Materials/GH-Pages-Hands-On.html#fork-the-sample-template-repository",
    "relUrl": "/GH_Pages_Materials/GH-Pages-Hands-On.html#fork-the-sample-template-repository"
  },"403": {
    "doc": "2. Hands On",
    "title": "Edit your _config.yml file",
    "content": "Step 1 . Click on the _config.yml file to open it. Step 2 . Click the edit button. Step 3 . Change the url field to match your username. On line 28, change: https://cmu-lib.github.io to https://your-user-name.github.io . Step 4 . Scroll down, add a commit message, and click Commit to save the changes: . ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Pages_Materials/GH-Pages-Hands-On.html#edit-your-_configyml-file",
    "relUrl": "/GH_Pages_Materials/GH-Pages-Hands-On.html#edit-your-_configyml-file"
  },"404": {
    "doc": "2. Hands On",
    "title": "“Spin up” your site!",
    "content": "Step 1 . Go to your repository Settings: . Step 2 . Click the Pages tab at bottom left: . Step 3 . Under source, switch the branch to main and click save: . Your site is building! This can take up to a few minutes. Head over to: [your-user-name].github.io/pages-sample in a new browser tab to see the result. ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Pages_Materials/GH-Pages-Hands-On.html#spin-up-your-site",
    "relUrl": "/GH_Pages_Materials/GH-Pages-Hands-On.html#spin-up-your-site"
  },"405": {
    "doc": "2. Hands On",
    "title": "Playtime! Now let’s work through some basic customizations",
    "content": "First, open up your _config.yml file and modify the contact info, title, and description: . Let’s make some changes to the homepage: . Now let’s make some changes to the content of the home page. Step 1 . Open index.md and click Edit. Step 2 . Take a minute to modify the content of the homepage. Add some dummy text and perhaps a link. Links look like this: . [dummy text](http://fillerama.io/) . Now let’s talk about Layouts: . You’ve figured out by now that your content pages are saved as Markdown (.md) files. Information like the layout type, title, and navigation (if applicable) are set in the front matter of the page’s markdown file. It looks like this: . --- layout: default title: Home --- . The layouts available will depend on which theme you are using. For this example, we are using the default Jekyll theme, called Minima. When GitHub builds your site, it references the theme indicated in the _config.yml file, which indicates which theme you are using (we will discuss themes more in a minute). Take a look now at the repo that contains the Minima theme. Open the _layouts folder and you can see you have a few different layouts to choose from. Change the layout of your index.md file to home . Tread lightly here… not all themes support different layouts. Many only have one page layout: default . Open your index page in the editor and change the front matter to this: . --- layout: home title: Home --- . Enter a commit message and click Commit. Let your site reload and view the results… . It’s changed! What is all this “Posts” stuff? . Let’s talk about Posts! . Jekyll is a popular platform for blogging, and the “post” layout is fairly common across different Jekyll themes. In your repository, open the _posts folder and you can see that I’ve provided several example posts. Posts must be saved in the _posts folder, and they must always be formatted as yyyy-mm-dd-title-of-post.md. This is how they show up properly in the feed. You must also set the layout as ‘post’ and provide a category in the front matter, the value of which can be whatever you want. Date is also good: . --- layout: post title: Something smart and academic date: 2021-08-03 categories: science --- . Adjusting Themes . GitHub Pages supports several Standard Themes . Try changing the theme of your site to one of these standard themes. Open your _config.yml file, got to line 33 and change: theme: minima to theme: jekyll-theme-architect . Commit the change and see what happens upon build… . What went wrong? . When switching themes, pay particular attention to the layouts! You may need to check the theme repo to see if it uses the same layouts your pages or posts use (see _layouts folder). If not, you may need to change layouts of your markdown files. Fix it Change the layout of your index.md file to default. 2 Remote Themes . In addition to the standard themes, you can also use “Remote Themes”, of which there are hundreds. GitHub Pages Remote Themes . If you’re relying on remote themes, your mileage may vary here! Be prepared to troubleshoot. Truth: If you want to use themes beyond the standard GH Pages themes, it is best to clone a theme’s repository, work on it locally, and push it to a new remote repository on your GitHub account. This will give you further control over the look and feel of your site and a lot of flexibility… . See Advanced . ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Pages_Materials/GH-Pages-Hands-On.html#playtime-now-lets-work-through-some-basic-customizations",
    "relUrl": "/GH_Pages_Materials/GH-Pages-Hands-On.html#playtime-now-lets-work-through-some-basic-customizations"
  },"406": {
    "doc": "2. Hands On",
    "title": "2. Hands On",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Pages_Materials/GH-Pages-Hands-On.html",
    "relUrl": "/GH_Pages_Materials/GH-Pages-Hands-On.html"
  },"407": {
    "doc": "Websites and Portfolios with GitPages",
    "title": "Creating Websites and Portfolios with GitPages",
    "content": "Hosted by the Carnegie Mellon University (CMU) Libraries . ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Pages_Materials/GH-Pages-Index.html#creating-websites-and-portfolios-with-gitpages",
    "relUrl": "/GH_Pages_Materials/GH-Pages-Index.html#creating-websites-and-portfolios-with-gitpages"
  },"408": {
    "doc": "Websites and Portfolios with GitPages",
    "title": "GitHub Pages",
    "content": "Welcome to this Introductory workshop on GitHub Pages. During the workshop, we will walk through the information and tasks detailed on these pages. Use the table of contents to navigate through the workshop. Presenters . Sarah Young Principal Librarian Office: 109G, Hunt Library sarahy@andrew.cmu.edu . Chasz Griego Open Science Postdoctoral Associate Office: 4416, Sorrells Library cgriego@andrew.cmu.edu . | Please create a GitHub account right now if you have yet to do so. | . Goal of this Workshop . The goal of this workshop is to get you started on GitHub Pages. This is not a workshop on Git. We will discuss Git some, but mainly we will focus on GitHub and getting you comfortable with GitHub Pages so you can set up a great looking, free, easy website for your projects or portfolio. Learning Objectives . Workshop attendees will be able to: . | Create a website or portfolio with GitPages. | Define GitHub-related terminology like ‘repository’, ‘fork’, and ‘version control’. | Describe the types of content that can be added to a GitPage. | Fork a template from a GitHub repository. | Edit and commit a file on GitHub. | Launch a GitPage. | Find resources to customize a GitPage. | . Setup . To be best prepared for this workshop, please create a GitHub account prior to attending. Pre-Workshop Survey . Before the start of the workshop, please complete this survey. Thank you!! . ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Pages_Materials/GH-Pages-Index.html#github-pages",
    "relUrl": "/GH_Pages_Materials/GH-Pages-Index.html#github-pages"
  },"409": {
    "doc": "Websites and Portfolios with GitPages",
    "title": "Schedule",
    "content": "| Time | Content | . | 12:00 to 12:05 | Welcome and Introduction | . | 12:05 to 12:25 | Overview to Git, GitHub, and GitPages | . | 12:25 to 1:15 | Pages Hands-On | . | 1:15 to 1:30 | Advanced Pages and Wrap-Up | . Actual schedule may vary depending on group needs; all times refer to Eastern Standard Time (EST) . Slides . Click on the slides then press CTRL+Shift+F for full screen . Post-Workshop Survey . Please complete this survey after attending the workshop. Thank you in advance!!! . ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Pages_Materials/GH-Pages-Index.html#schedule",
    "relUrl": "/GH_Pages_Materials/GH-Pages-Index.html#schedule"
  },"410": {
    "doc": "Websites and Portfolios with GitPages",
    "title": "Websites and Portfolios with GitPages",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Pages_Materials/GH-Pages-Index.html",
    "relUrl": "/GH_Pages_Materials/GH-Pages-Index.html"
  },"411": {
    "doc": "Git Glossary",
    "title": "Glossary",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Pages_Materials/GH-glossary.html#glossary",
    "relUrl": "/GH_Pages_Materials/GH-glossary.html#glossary"
  },"412": {
    "doc": "Git Glossary",
    "title": "General:",
    "content": "Command line – (or Terminal) An interface for entering textual commands on your computer. On Mac OS, this is known as the Terminal and is found in the Applications/Utilities directory. On Windows, this is known as the Command Prompt and can be found under Start&gt;Windows System. Git Bash is also a popular command line interface. Git – Git is a version control software. Many people use Git from the command line, but there is also a desktop GUI interface. Git Repository – A Git repository is essentially an instance of Git version control running in a file directory on your computer. You create a Git repository on your computer by either cloning a repository from GitHub, or by initializing a new repository in a directory (folder) on your computer. On your own computer, this is called a “local repository.” On GitHub, this is referred to as a “remote repository.” See Git Basics. GitHub – (or GitHub.com) GitHub is a free(mium) website for hosting remote Git repositories. It is primarily used for code. GitHub facilitates collaboration by providing access control, task management, bug tracking, and more for all of it’s project repositories. GitHub Pages – GitHub Pages is a built-in function of GitHub that converts a repository into a website. Pages is a very simple method for creating static webpages. Main/Master – The primary repository for a project on GitHub. Formerly named “master”, this was updated to “main” October 1 2020. (Many repositories will still use “master” until updated by their owners.) . Fork – A fork is a remote copy of a GitHub repository. Forking a repository permits others to make changes to a project without modifying the main/master branch of the project. Once forked and modified, changes can be merged with the main/master by way of a Pull Request. Pull Request – A method for suggesting changes to content stored in a GitHub repository. Someone wishing to make a change to a repository can fork the main repository, modify a file(s), and submit a pull request that will be reviewed by the main repository’s owner. If accepted, the changes will be merged with the main repository. Jekyll – Jekyll is a static site generator used for creating a variety of online content. GitHub Pages relies on Jekyll behind the scenes. The site you’re looking at right now was created using Jekyll. Markdown – Markdown is a super-simple markup language. Markdown is popular for creating documentation and readme files. When used in tandem with Jekyll templates, it can be used to generate static web pages. This page was created in Markdown. Ruby – Ruby is an open-source programming language, and is used as a framework for Jekyll. ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Pages_Materials/GH-glossary.html#general",
    "relUrl": "/GH_Pages_Materials/GH-glossary.html#general"
  },"413": {
    "doc": "Git Glossary",
    "title": "Git Commands:",
    "content": "Use these on your local terminal. Note that these are just a few of the most common basic commands. See Git documentation. Init (command) - git init. Use init to initiate a new repository within a directory (folder) on your computer. Add (command) – git add myfile.txt. Add is the first step in adding a new file or a modified file into a Git repository. The Add command adds new/modified files to a staging area. Commit (command) – git commit -m \"I made some edits\". Commit is the second step in adding a new/modified file to the Git repository. Commit moves new/modified files from the staging area to the repository. You must include a message following the -m flag. Be sure to make your commit message descriptive in case you need it later. Clone (command) – git clone https://github.com/user/repo-name Make a copy of a remote repository from GitHub.com on your local computer. This is one method of creating a connection between a local and remote repository that you can use to push or pull changes. Pull (command) – git pull origin main Use this to pull updates from the remote repository down to your local copy. Push (command) – git push origin main Use this to push updates made to your local repository to the remote repository. Status (command) – git status Check if you have any un-added/committed changes to your local repository. Log (command) – git log See past commit history including comments and hash ID of each commit. q to exit Log interface. Use git log --oneline for a condensed log. Revert (command) – git revert [hash id] Use this to revert to an earlier commit. Use the Log command to find previous commits’ hash IDs. ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Pages_Materials/GH-glossary.html#git-commands",
    "relUrl": "/GH_Pages_Materials/GH-glossary.html#git-commands"
  },"414": {
    "doc": "Git Glossary",
    "title": "Git Glossary",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Pages_Materials/GH-glossary.html",
    "relUrl": "/GH_Pages_Materials/GH-glossary.html"
  },"415": {
    "doc": "About",
    "title": "About",
    "content": "This is the base Jekyll theme. You can find out more info about customizing your Jekyll theme, as well as basic Jekyll usage documentation at jekyllrb.com . You can find the source code for Minima at GitHub: jekyll / minima . You can find the source code for Jekyll at GitHub: jekyll / jekyll . ",
    "url": "http://localhost:4000/portfolio_workshop/about/",
    "relUrl": "/about/"
  },"416": {
    "doc": "Acknowledgements",
    "title": "Acknowledgements",
    "content": "This website was built by adapting a template that Evan Thornberry (UBC) and Phil White (CU Boulder) developed and presented at a workshop for the Western Association of Map Libraries. Their template was heavily influenced by the University of British Columbia Library Research Commons, and several UBC affiliates contributed to the template’s styling and example pages–particularly Evan Thornberry. The template uses the Just The Docs Jekyll theme. The repository containing Phil and Evan’s template is available here and you can view the rendered version here. Many thanks to Phil and Evan for making this resource available to the community of librarians and educators! . ",
    "url": "http://localhost:4000/portfolio_workshop/content/acknowledgements.html",
    "relUrl": "/content/acknowledgements.html"
  },"417": {
    "doc": "Introduction to Command Line Interface",
    "title": "Introduction to Command Line Interface",
    "content": "This is a hands-on introduction to using the command line interface. This workshop is designed for those who are beginning their exploration into command line programming and anyone seeking to refresh their skills. Command line interface (CLI) is a quick and efficient way to perform computing tasks. A few of the topics that will be introduced include navigating the directory structure, commonly used commands, working with files and directories, and more. For this workshop you’ll need access to Bash Shell. If you use MacOS or Linux then you should have Bash already installed. For those on Windows OS you may need to install a bash shell. Git Bash installation is one option for installing Bash Shell. Date: March 14, 2023 Time: 10:00 am - 12:00 pm Location: Virtual Workshop - This is a virtual event. A URL to participate will be sent via a reminder email 24 hours before the event. Presenters . Lencia Beltran Open Science Program Coordinator Office: 4416, Sorrells Library lbeltran@andrew.cmu.edu . Goals of this Workshop . The goal of this workshop is to introduce beginner users of the command line interface to basic concepts and commands for navigating and working with files and directories. Learners will understand how to move around their directories using commands like pwd, cd, and ls; work with directories to create new directories, and access the text editor, including moving, making copies, and removing files; use pipe and filters to view word counts, filter files using sort and cat and combine commands. Setup . To be best prepared for this workshop, please follow the setup instructions prior to attending. | Section | Time | . | Setup |   | . | Exploring Files and Directories | 10:00 | . | Working with Files and Directories | 10:40 | . | Pipes &amp; Filters | 11:20 | . | Survey | 11:50 | . | Wrap-up | 12:00 | . Post-Workshop Survey . Please complete this survey after attending the workshop. Thank you in advance!!! . ",
    "url": "http://localhost:4000/portfolio_workshop/cli/cli_main.html",
    "relUrl": "/cli/cli_main.html"
  },"418": {
    "doc": "Encapsulating Reproducible Computational Research with Code Ocean",
    "title": "Encapsulating Reproducible Computational Research with Code Ocean",
    "content": "Hosted by the Carnegie Mellon University (CMU) Libraries . ",
    "url": "http://localhost:4000/portfolio_workshop/content/code_ocean.html",
    "relUrl": "/content/code_ocean.html"
  },"419": {
    "doc": "Encapsulating Reproducible Computational Research with Code Ocean",
    "title": "About this workshop",
    "content": "Code Ocean is a cloud-based platform for creating, organizing, and sharing reproducible computational research environments. In this workshop, we will show you how to create a “Capsule” for a computational research project. We will demonstrate how to organize data, code, and results in a Capsule, create a reproducible snapshot of a software environment for a variety of programming languages and libraries (including Python, R, MATLAB, and Julia), and create metadata to prepare your project for publication and enhanced discoverability. This workshop is open to anyway that is interested in computational reproducibility. No prior experience with a programming language is required, but we encourage participants to attend with a project in mind, so that they are able to immediately utilize this platform. Presenters . Chasz Griego Science and Engineering Librarian cgriego@andrew.cmu.edu . Slides . Click on the slides then press CTRL+Shift+F for full screen . ",
    "url": "http://localhost:4000/portfolio_workshop/content/code_ocean.html#about-this-workshop",
    "relUrl": "/content/code_ocean.html#about-this-workshop"
  },"420": {
    "doc": "Command Line Crash Course",
    "title": "Command Line Crash Course for Beginners",
    "content": "Presenters . Lencia Beltran Open Science Project Coordinator Office: 4416, Sorrells Library lbeltran@andrew.cmu.edu . Table of Contents: . | Opening the command line | Navigating through files | Creating files and directories | Nano Text Editor | Accessing command history | Examine Content | Copying and moving files | Removing files and directories | . Opening Command Line/Terminal . | Windows: . | Click the Windows icon to bring up your start menu. Type cmd into the search box. | Select the command prompt entry and click open. | Occasionally, you must select the run as administrator option to use higher-level system commands. | . | Mac: . | click command and space bar then type terminal | click spotlight search icon (magnifying glass), then type terminal | . | . Navigating Through Files . | pwd AKA print working directory | ls AKA print a list of items in your working directory (including different options); . | ls -a (show all) | ls -F(add trailing /) / means it’s a directory and * means it’s a program | ls -l | ls -Fa | ls -laF | . | Navigating up files . | cd | . | Navigating down files . | cd.. (move back a directory) . | To view files in higher level directories can also do ls ../ which will go back 2 levels and show your root/home directory (lbeltran) or go back 1 level ls ../../ to see files in your Desktop directory | . | cd ~ takes you straight to your root/home directory . | Question! What is the different between cd.. and cd~ ? | . | . | Relative and absolute paths . | A relative path always starts with / and gives the full address from the home directory (think of this as getting GPS coordinates, no matter where you are it will tell you where something is and how to get there) | An abosolute path will only give the address from the working directory, and does not start with a / (analogous to getting directions from someone on the street in real time) | . | . Creating Files &amp; Directories . | Navigate to their desktop &amp; create 3 new directories. The first directory will be on your desktop. | mkdir name1 | . | Navigate into doing cd name1 and then make 2 directories. We can do this quickly by listing both names as shown below. Note, be careful you dont add a space in a name because that will make two directories!! . | mkdir name2 name3 | . | Navitgate into name2 directory . | and create a nano text file | . | . Nano Editor . | Open up the nano text editor or your favorite text editor. Note, this may be different for . | nano | . | Copy and paste text . | access help in nano by . | (control G) | . | . | Save the text (control C) and name the file practicetext_1 | Exit the editor (control X) | . Accessing Command History . | To repeat the most recent/recently command run, use the up arrow | The down arrow will take you forward in your in the command history . | Ctrl+C will cancel the command you are writing, and give you a fresh prompt. | Ctrl+R will do a reverse-search through your command history. This is very useful. | Ctrl+L or the clear command will clear your screen. | . | To review recent command history . | history | . | To rerun a specific command in your command history . | add a ! in front of the number . | e.g., !22 | . | . | . Examining Files . | To examine content in a file you can use less . | less practicetext1 . | Space to go forward | b to go backward | g to go to the beginning | G to go to the end | q to quit | . | head practicetext_1 | tail practicetext_1 . | use -n option after head/tail to print only the first or last line | . | wc practicetext_1 . | to view the number of lines, words and characters in the file | . | wc -l practicetext_1 . | to view only the number of lines | . | . | . Copying and moving . | Make a copy of the text file . | cp practicetext_1 practicetext_1_copy | check that a copy of our text data was made ls -F | . | Make a backup directory to store the copy of the text data and any copies . | mkdir backup | Note: make sure you are creating directories in the correct working directory (i.e., make sure you are in the right working directory) | . | Move your copy of the text data into the backup directory . | mv practicetext_1_copy backup | . | You can either navigate to backup and type ls OR type ls backup | Rename the copy of the text . | mv also let’s you rename files . | mv practicetext_1_copy practicetext_1_backup | . | . | . Removing Files &amp; Directories . | Remove the backup copy of the text file . | rm practicetext_1_backup | . | Remove all of the directories under name1 . | rm -r name1 . | A recursive flag -r will need to be added to tell rm to remove a directory | . | Note, remove will permanently delete a file but also any content in a directory (i.e., not only the directory name1 but will also remove everything in the directory) | . | . That’s all folks! . ",
    "url": "http://localhost:4000/portfolio_workshop/cli/commandlinecrashcourse.html#command-line-crash-course-for-beginners",
    "relUrl": "/cli/commandlinecrashcourse.html#command-line-crash-course-for-beginners"
  },"421": {
    "doc": "Command Line Crash Course",
    "title": "Command Line Crash Course",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/cli/commandlinecrashcourse.html",
    "relUrl": "/cli/commandlinecrashcourse.html"
  },"422": {
    "doc": "Collaboration for Community Engagement",
    "title": "Introduction to Successful Collaboration for Community Engagement",
    "content": "Hosted by the Carnegie Mellon University (CMU) Libraries . ",
    "url": "http://localhost:4000/portfolio_workshop/content/community_engagement.html#introduction-to-successful-collaboration-for-community-engagement",
    "relUrl": "/content/community_engagement.html#introduction-to-successful-collaboration-for-community-engagement"
  },"423": {
    "doc": "Collaboration for Community Engagement",
    "title": "About this workshop",
    "content": "This workshop exposes the importance of successful collaboration and the role it plays in community relationships. It explains some critical foundation factors that drives successful collaborations and sheds lights on step by step approaches that can help diverse sectors flourish in their unique ways part of a single or multiple collaborative projects(s). Also see this guide for more information. __ . Presenters . Taiwo Lasisi (she/her/hers) CLIR Postdoctoral Fellow in Community Data Literacy Office: 4418, Sorrells Library tlasisi@andrew.cmu.edu . Workshop Handout . ",
    "url": "http://localhost:4000/portfolio_workshop/content/community_engagement.html#about-this-workshop",
    "relUrl": "/content/community_engagement.html#about-this-workshop"
  },"424": {
    "doc": "Collaboration for Community Engagement",
    "title": "Collaboration for Community Engagement",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/content/community_engagement.html",
    "relUrl": "/content/community_engagement.html"
  },"425": {
    "doc": "Discussion",
    "title": "Frequently Asked Questions",
    "content": "People often have questions about Git beyond the scope of the core material. Students who have completed the rest of the lessons might find value in looking through the following topics. Note that since this material isn’t essential for basic Git usage, it won’t be covered by the instructor. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/discuss.html#frequently-asked-questions",
    "relUrl": "/Git_Materials/discuss.html#frequently-asked-questions"
  },"426": {
    "doc": "Discussion",
    "title": "More Advanced Git Configuration",
    "content": "In Setting Up Git, we used git config --global to set some default options for Git. It turns out that these configuration options get stored in your home directory in a plain text file called .gitconfig. $ cat ~/.gitconfig . [user] name = Vlad Dracula email = vlad@tran.sylvan.ia [color] ui = true [core] editor = nano . This file can be opened in your preferred text editor. (Note that it is recommended to continue using the git config command, as this helps avoid introducing syntax errors.) . Eventually, you will want to start customizing Git’s behaviour. This can be done by adding more entries to your .gitconfig. The available options are described in the manual: . $ git config --help . In particular, you might find it useful to add aliases. These are like shortcuts for longer Git commands. For example, if you get sick of typing git checkout all the time, you could run the command: . $ git config --global alias.co checkout . Now if we return to the example from Exploring History where we ran: . $ git checkout f22b25e mars.txt . we could now instead type: . $ git co f22b25e mars.txt . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/discuss.html#more-advanced-git-configuration",
    "relUrl": "/Git_Materials/discuss.html#more-advanced-git-configuration"
  },"427": {
    "doc": "Discussion",
    "title": "Styling Git’s Log",
    "content": "A good target for customization is output from the log. The default log is quite verbose but gives no graphical hints such as information about which commits were done locally and which were pulled from remotes. You can use git log --help and git config --help to look for different ways to change the log output. Try the following commands and see what effect they have: . $ git config --global alias.lg \"log --graph\" $ git config --global log.abbrevCommit true $ git config --global format.pretty oneline $ git lg . If you don’t like the effects, you can undo them with: . $ git config --global --unset alias.lg $ git config --global --unset log.abbrevCommit $ git config --global --unset format.pretty . ::::::::::::::::::::::::::::::::::::::::: callout . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/discuss.html#styling-gits-log",
    "relUrl": "/Git_Materials/discuss.html#styling-gits-log"
  },"428": {
    "doc": "Discussion",
    "title": "Undoing Git Configuration Changes",
    "content": "You can use the --unset flag to delete unwanted options from .gitconfig. Another way to roll back changes is to store your .gitconfig using Git. For hints on what you might want to configure, go to GitHub and search for “gitconfig”. You will find hundreds of repositories in which people have stored their own Git configuration files. Sort them by the number of stars and have a look at the top few. If you find some you like, please check that they’re covered by an open source license before you clone them. :::::::::::::::::::::::::::::::::::::::::::::::::: . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/discuss.html#undoing-git-configuration-changes",
    "relUrl": "/Git_Materials/discuss.html#undoing-git-configuration-changes"
  },"429": {
    "doc": "Discussion",
    "title": "Non-text Files",
    "content": "Recall when we discussed Conflicts there was a challenge that asked, “What does Git do when there is a conflict in an image or some other non-textual file that is stored in version control?” . We will now revisit this in more detail. Many people want to version control non-text files, such as images, PDFs and Microsoft Office or LibreOffice documents. It is true that Git can handle these filetypes (which fall under the banner of “binary” file types). However, just because it can be done doesn’t mean it should be done. Much of Git’s magic comes from being able to do line-by-line comparisons (“diffs”) between files. This is generally easy for programming source code and marked up text. For non-text files, a diff can usually only detect that the files have changed but can’t say how or where. This has various impacts on Git’s performance and will make it difficult to compare different versions of your project. For a basic example to show the difference it makes, we’re going to go see what would have happened if Dracula had tried using outputs from a word processor instead of plain text. Create a new directory and go into it: . $ mkdir planets-nontext $ cd planets-nontext . Use a program such as Microsoft Word or LibreOffice Writer to create a new document. Enter the same text that we began with before: . Cold and dry, but everything is my favorite color . Save the document into the planets-nontext directory with the name of mars.doc. Back in the terminal, run the usual commands for setting up a new Git repository: . $ git init $ git add mars.doc $ git commit -m \"Starting to think about Mars\" . Then make the same changes to mars.doc that we (or Vlad) previously made to mars.txt. Cold and dry, but everything is my favorite color The two moons may be a problem for Wolfman . Save and close the word processor. Now see what Git thinks of your changes: . $ git diff . diff --git a/mars.doc b/mars.doc index 53a66fd..6e988e9 100644 Binary files a/mars.doc and b/mars.doc differ . Compare this to the earlier git diff obtained when using text files: . diff --git a/mars.txt b/mars.txt index df0654a..315bf3a 100644 --- a/mars.txt +++ b/mars.txt @@ -1 +1,2 @@ Cold and dry, but everything is my favorite color +The two moons may be a problem for Wolfman . Notice how plain text files give a much more informative diff. You can see exactly which lines changed and what the changes were. An uninformative git diff is not the only consequence of using Git on binary files. However, most of the other problems boil down to whether or not a good diff is possible. This isn’t to say you should never use Git on binary files. A rule of thumb is that it’s OK if the binary file won’t change very often, and if it does change, you don’t care about merging in small differences between versions. We’ve already seen how a word processed report will fail this test. An example that passes the test is a logo for your organization or project. Even though a logo will be stored in a binary format such as jpg or png, you can expect it will remain fairly static through the lifetime of your repository. On the rare occasion that branding does change, you will probably just want to replace the logo completely rather than merge little differences in. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/discuss.html#non-text-files",
    "relUrl": "/Git_Materials/discuss.html#non-text-files"
  },"430": {
    "doc": "Discussion",
    "title": "Removing a File",
    "content": "Adding and modifying files are not the only actions one might take when working on a project. It might be required to remove a file from the repository. Create a new file for the planet Nibiru: . $ echo \"This is another name for fake planet X\" &gt; nibiru.txt . Now add to the repository like you have learned earlier: . $ git add nibiru.txt $ git commit -m 'adding info on nibiru' $ git status . On branch main nothing to commit, working tree clean . Nibiru is not a real planet. That was a silly idea. Let us remove it from the disk and let Git know about it: . $ git rm nibiru.txt $ git status . On branch main Changes to be committed: (use \"git reset HEAD &lt;file&gt;...\" to unstage) deleted: nibiru.txt . The change has been staged. Now commit the removal, and remove the file from the repository itself. Note that the file will be removed in the new commit. The previous commit will still have the file, if you were to retrieve that specific commit. $ git commit -m 'Removing info on Nibiru. It is not a real planet!' . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/discuss.html#removing-a-file",
    "relUrl": "/Git_Materials/discuss.html#removing-a-file"
  },"431": {
    "doc": "Discussion",
    "title": "Removing a File with Unix",
    "content": "Sometimes we might forget to remove the file through Git. If you removed the file with Unix rm instead of using git rm, no worries, Git is smart enough to notice the missing file. Let us recreate the file and commit it again. $ echo \"This is another name for fake planet X\" &gt; nibiru.txt $ git add nibiru.txt $ git commit -m 'adding nibiru again' . Now we remove the file with Unix rm: . $ rm nibiru.txt $ git status . On branch main Changes not staged for commit: (use \"git add/rm &lt;file&gt;...\" to update what will be committed) (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory) deleted: nibiru.txt no changes added to commit (use \"git add\" and/or \"git commit -a\") . See how Git has noticed that the file nibiru.txt has been removed from the disk. The next step is to “stage” the removal of the file from the repository. This is done with the command git rm just as before. $ git rm nibiru.txt $ git status . On branch main Changes to be committed: (use \"git reset HEAD &lt;file&gt;...\" to unstage) deleted: nibiru.txt . The change that was made in Unix has now been staged and needs to be committed. $ git commit -m 'Removing info on Nibiru, again!' . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/discuss.html#removing-a-file-with-unix",
    "relUrl": "/Git_Materials/discuss.html#removing-a-file-with-unix"
  },"432": {
    "doc": "Discussion",
    "title": "Renaming a File",
    "content": "Another common change when working on a project is to rename a file. Create a file for the planet Krypton: . $ echo \"Superman's home planet\" &gt; krypton.txt . Add it to the repository: . $ git add krypton.txt $ git commit -m 'Adding planet Krypton' . We all know that Superman moved to Earth. Not that he had much choice. Now his home planet is Earth. Rename the file krypton.txt to earth.txt with Git: . $ git mv krypton.txt earth.txt $ git status . On branch main Changes to be committed: (use \"git reset HEAD &lt;file&gt;...\" to unstage) renamed: krypton.txt -&gt; earth.txt . The final step is commit our change to the repository: . $ git commit -m 'Superman's home is now Earth' . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/discuss.html#renaming-a-file",
    "relUrl": "/Git_Materials/discuss.html#renaming-a-file"
  },"433": {
    "doc": "Discussion",
    "title": "Renaming a File with Unix",
    "content": "If you forgot to use Git and you used Unix mv instead of git mv, you will have a touch more work to do but Git will be able to deal with it. Let’s try again renaming the file, this time with Unix mv. First, we need to recreate the krypton.txt file: . $ echo \"Superman's home planet\" &gt; krypton.txt $ git add krypton.txt $ git commit -m 'Adding planet Krypton again.' . Let us rename the file and see what Git can figured out by itself: . $ mv krypton.txt earth.txt $ git status . On branch main Changes not staged for commit: (use \"git add/rm &lt;file&gt;...\" to update what will be committed) (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory) deleted: krypton.txt Untracked files: (use \"git add &lt;file&gt;...\" to include in what will be committed) earth.txt no changes added to commit (use \"git add\" and/or \"git commit -a\") . Git has noticed that the file krypton.txt has disappeared from the file system and a new file earth.txt has showed up. Add those changes to the staging area: . $ git add krypton.txt earth.txt $ git status . On branch main Changes to be committed: (use \"git reset HEAD &lt;file&gt;...\" to unstage) renamed: krypton.txt -&gt; earth.txt . Notice how Git has now figured out that the krypton.txt has not disappeared - it has simply been renamed. The final step, as before, is to commit our change to the repository: . $ git commit -m 'Superman's home is Earth, told you before.' . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/discuss.html#renaming-a-file-with-unix",
    "relUrl": "/Git_Materials/discuss.html#renaming-a-file-with-unix"
  },"434": {
    "doc": "Discussion",
    "title": "Further .gitignore concepts",
    "content": "For additional documentation on .gitignore, please reference the official git documentation. In the ignore exercise, learners were presented with two variations of ignoring nested files. Depending on the organization of your repository, one may suit your needs over another. Keep in mind that the way that Git travels along directory paths can be confusing. Sometimes the ** pattern comes in handy, too, which matches multiple directory levels. E.g. **/results/plots/* would make git ignore the results/plots directory in any root directory. ::::::::::::::::::::::::::::::::::::::: challenge . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/discuss.html#further-gitignore-concepts",
    "relUrl": "/Git_Materials/discuss.html#further-gitignore-concepts"
  },"435": {
    "doc": "Discussion",
    "title": "Ignoring Nested Files: Challenge Problem",
    "content": "Given a directory structure that looks like: . results/data results/plots results/run001.log results/run002.log . And a .gitignore that looks like: . *.dat . How would you track all of the contents of results/data/, including *.dat files, but ignore the rest of results/? . ::::::::::::::: solution . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/discuss.html#ignoring-nested-files-challenge-problem",
    "relUrl": "/Git_Materials/discuss.html#ignoring-nested-files-challenge-problem"
  },"436": {
    "doc": "Discussion",
    "title": "Solution",
    "content": "To do this, your .gitignore would look like this: . *.dat # ignore the .dat files results/* # ignore the files in the results directory !results/data/ # do not ignore the files in results/data !results/data/* # do not ignore the .dat files in reults/data . ::::::::::::::::::::::::: . :::::::::::::::::::::::::::::::::::::::::::::::::: . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/discuss.html#solution",
    "relUrl": "/Git_Materials/discuss.html#solution"
  },"437": {
    "doc": "Discussion",
    "title": "Discussion",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/discuss.html",
    "relUrl": "/Git_Materials/discuss.html"
  },"438": {
    "doc": "GitHub and GitHub Pages",
    "title": "Building Your Programming Tool Box",
    "content": "Hosted by the Carnegie Mellon University (CMU) Libraries . ",
    "url": "http://localhost:4000/portfolio_workshop/content/git_github.html#building-your-programming-tool-box",
    "relUrl": "/content/git_github.html#building-your-programming-tool-box"
  },"439": {
    "doc": "GitHub and GitHub Pages",
    "title": "GitHub and GitHub Pages",
    "content": "Welcome to this introductory workshop series! This four part series covers a Command Line Crash Course, Version Control with Git, Collaboration with GitHub, and Websites and Portfolios with GitPages. Presenters . Sarah Young Principal Librarian Office: 109G, Hunt Library sarahy@andrew.cmu.edu . Chasz Griego Science and Engineering Librarian Office: 4410, Sorrells Library cgriego@andrew.cmu.edu . Lencia Beltran Open Science Project Coordinator Office: 4416, Sorrells Library lbeltran@andrew.cmu.edu . Goal of this Workshop . The goal of these workshops is to get you started with basic tools for efficient and reproducible open source programming. Series . | Part 1: Command Line Crash Course for Beginners | Part 2: Version Control with Git | Part 3: Collaborating with GitHub | Part 4: Creating Websites and Portfolios with GitPages | . ",
    "url": "http://localhost:4000/portfolio_workshop/content/git_github.html",
    "relUrl": "/content/git_github.html"
  },"440": {
    "doc": "Home",
    "title": "Open Data Science Workshops",
    "content": "Hosted by the Open Science program within the Carnegie Mellon University (CMU) Libraries . This website highlights workshops from CMU libraries that help build computational skills for Open Research and Data Science. ",
    "url": "http://localhost:4000/portfolio_workshop/#open-data-science-workshops",
    "relUrl": "/#open-data-science-workshops"
  },"441": {
    "doc": "Home",
    "title": "Workshop Calendar",
    "content": "| September 08, 2023 | 12:00 PM - 01:30 PM | Building your Programming Tool Box: Command Line Crash Course for Beginners | Register Here Content | . | September 13, 2023 | 01:00 PM - 03:00 PM | Introduction to Python for Data Science Part 1: Introduction to Basic Programming with Data | Register Here Content | . | September 15, 2023 | 12:00 PM - 01:30 PM | Building Your Programming Toolbox: Version Control with Git | Register Here Content | . | September 20, 2023 | 01:00 PM - 03:00 PM | Introduction to Python for Data Science Part 2: Plotting and Analyzing Tabular Datasets | Register Here Content | . | September 22, 2023 | 12:00 PM - 01:30 PM | Building Your Programming Toolbox: Collaborating with GitHub | Register Here Content | . | September 27, 2023 | 01:00 PM - 03:00 PM | Introduction to Python for Data Science Part 3: Analyzing Data with Logic and Iteration | Register Here Content | . | September 28, 2023 | 12:00 PM - 01:00 PM | Introduction to Research Data Management and Data Management Plans | Register Here Content | . | September 29, 2023 | 12:00 PM - 01:30 PM | Building Your Programming Toolbox: Creating Websites and Portfolios with GitPages | Register Here Content | . | October 03, 2023 | 01:00 PM - 03:00 PM | Making the Most with Jupyter Lab and Notebooks | Register Here Content | . | October 19, 2023 | 01:00 PM - 03:00 PM | Python for Harvesting Data on the Web | Register Here Content | . | October 25, 2023 | 10:00 AM - 12:00 PM | Advanced Research Note-Taking with Obsidian | Register Here Content | . | October 26, 2023 | 10:00 AM - 11:00 AM | Getting Started with Open Science Framework Workshop | Register Here Content | . | October 27, 2023 | 12:00 PM - 01:00 PM | Introduction to Successful Collaboration for Community Engagement | Register Here Content | . | October 31, 2023 | 12:00 PM - 01:00 PM | Introduction to Academic Publishing Processes and Models | Register Here Content | . | November 02, 2023 | 01:00 PM - 02:30 PM | Cleaning Untidy Data with OpenRefine | Register Here Content | . | November 07, 2023 | 10:00 AM - 11:30 AM | Introduction to R Part 1: Getting started with R and RStudio | Register Here | . | November 09, 2023 | 10:00 AM - 11:00 AM | Intro to Plotly Open Source Graphing Library | Register Here | . | November 14, 2023 | 10:00 AM - 11:30 AM | Introduction to R Part 2: Working with data in R | Register Here | . | November 15, 2023 | 09:00 AM - 12:00 PM | Data Carpentry: Introduction to R | Register Here Content | . | November 16, 2023 | 09:00 AM - 12:00 PM | Data Carpentry: Introduction to R | Register Here Content | . | November 17, 2023 | 09:00 AM - 12:00 PM | Data Carpentry: Introduction to R | Register Here Content | . | November 29, 2023 | 01:00 PM - 03:00 PM | Encapsulating Reproducible Computational Research with Code Ocean | Register Here | . ",
    "url": "http://localhost:4000/portfolio_workshop/#workshop-calendar",
    "relUrl": "/#workshop-calendar"
  },"442": {
    "doc": "Home",
    "title": "Data Office Hours",
    "content": "Schedule a Data Consultation with our library associates for support with data and research! . ",
    "url": "http://localhost:4000/portfolio_workshop/#data-office-hours",
    "relUrl": "/#data-office-hours"
  },"443": {
    "doc": "Home",
    "title": "Coordinators",
    "content": "Melanie Gainey (she/her/hers) Open Science Program Director/Librarian Office: Library 431, Mellon library mgainey@andrew.cmu.edu | Schedule a Consultation . Chasz Griego (he/him/his) Science and Engineering Librarian Office: 4410, Sorrells Library cgriego@andrew.cmu.edu | Schedule a Consultation . Lencia Beltran (she/her/hers) Open Science Project Coordinator Office: 4416, Sorrells Library lbeltran@andrew.cmu.edu | Schedule a Consultation . Emma Slayton (she/her/hers) Data Curation, Visualization, and GIS Specialist Office: 4408, Sorrells Library eslayton@andrew.cmu.edu | Schedule a Consultation . Sarah Young (she/her/hers) Principal Librarian Office: 109G, Hunt Library sarahy@andrew.cmu.edu | Schedule a Consultation . Emily Bongiovanni (she/her/hers) Psychology Librarian Liaison Office: 109D, Hunt Library ebongiov@andrew.cmu.edu | Schedule a Consultation . Taiwo Lasisi (she/her/hers) CLIR Postdoctoral Fellow in Community Data Literacy Office: 4418, Sorrells Library tlasisi@andrew.cmu.edu | Schedule a Consultation . ",
    "url": "http://localhost:4000/portfolio_workshop/#coordinators",
    "relUrl": "/#coordinators"
  },"444": {
    "doc": "Home",
    "title": "Home",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/",
    "relUrl": "/"
  },"445": {
    "doc": "Collaborating with GitHub",
    "title": "Collaborating with GitHub",
    "content": "Hosted by the Carnegie Mellon University (CMU) Libraries . ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Materials/",
    "relUrl": "/GH_Materials/"
  },"446": {
    "doc": "Collaborating with GitHub",
    "title": "About this workshop",
    "content": "If you are interested in creating and collaborating on remote repositories on GitHub, this workshop is for you if you are a beginner or just seeking to refine your skills. GitHub is a cloud-based platform for open and collaborative software development and version control using Git. Topics covered will include pushing/pulling changes to files in a local repository to GitHub, making copies of public repositories to modify, and collaboratively pushing changes to a common repository shared among workshop participants. Presenters . Sarah Young Principal Librarian Office: 109G, Hunt Library sarahy@andrew.cmu.edu . Chasz Griego Science and Engineering Librarian Office: 4416, Sorrells Library cgriego@andrew.cmu.edu . Lencia Beltran Open Science Program Coordinator Office: 4416, Sorrells Library lbeltran@andrew.cmu.edu . Learning Objectives . Workshop attendees will be able to: . | Understand the advantages of remote repositories | Create a repository on GitHub | Fork and contribute to a public repository | Add code from a computer to GitHub | . Setup . To be best prepared for this workshop, please create a GitHub account prior to attending. Interactive Notepad . During the workshop, you can ask and answer questions in this Etherpad, a notepad for live collaboration. Pre-Workshop Survey . Before the start of the workshop, please complete this survey. Thank you!! . Schedule . | Section | Time | . | Setup and Pre-Workshop Survey |   | . | Overview of GitHub | 00:00 | . | Creating a Repository and Adding Files | 00:10 | . | Updating a README | 00:30 | . | Forking and Modifying Public Repositories | 00:40 | . | Break | 01:00 | . | Hosting Jupyter Notebooks on GitHub | 01:05 | . | Post-Workshop Survey | 01:25 | . | Finish | 01:30 | . Slides . Click on the slides then press CTRL+Shift+F for full screen . Post-Workshop Survey . Please complete this survey after attending the workshop. Thank you!!! . Acknowledgment . The material for this workshop was inspired from the Version Control with Git curriculum developed by The Software Carpentry Foundation of The Carpentries licensed under CC-BY 4.0 . ",
    "url": "http://localhost:4000/portfolio_workshop/GH_Materials/#about-this-workshop",
    "relUrl": "/GH_Materials/#about-this-workshop"
  },"447": {
    "doc": "Version Control with Git",
    "title": "Version Control with Git",
    "content": "Hosted by the Carnegie Mellon University (CMU) Libraries . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/",
    "relUrl": "/Git_Materials/"
  },"448": {
    "doc": "Version Control with Git",
    "title": "About this workshop",
    "content": "This workshop is for those beginning to explore the concept of version control, as well as anyone seeking to refine their skills. Git is a version control system that lets you manage and track changes to files on your computer through the command line interface. Topics covered will include configuring a local repository on your computer, modifying files and committing changes, and exploring version histories. Presenters . Sarah Young Principal Librarian Office: 109G, Hunt Library sarahy@andrew.cmu.edu . Chasz Griego Science and Engineering Librarian Office: 4416, Sorrells Library cgriego@andrew.cmu.edu . Learning Objectives . Workshop attendees will be able to: . | Understand the benefits of an automated version control system | Configure settings in Git | Create a local Git repository | Track changes to files with commits | . Setup . To be best prepared for this workshop, please follow the setup instructions prior to attending. Interactive Notepad . During the workshop, you can ask and answer questions in this Etherpad, a notepad for live collaboration. Pre-Workshop Survey . Before the start of the workshop, please complete this survey. Thank you!! . Schedule . | Section | Time | . | Setup and Pre-Workshop Survey |   | . | Automated Version Control | 00:00 | . | Setting Up Git | 00:05 | . | Creating a Repository | 00:10 | . | Tracking Changes | 00:20 | . | Break | 00:25 | . | Exploring History | 00:45 | . | Ignoring Things | 01:10 | . | Post-Workshop Survey | 01:20 | . | Finish | 01:30 | . Spooky Space Explorers . Wolfman and Dracula have been hired by Universal Missions (a space services spinoff from Euphoric State University) to investigate if it is possible to send their next planetary lander to Mars. They want to be able to work on the plans at the same time, but they have run into problems doing this in the past. If they take turns, each one will spend a lot of time waiting for the other to finish, but if they work on their own copies and email changes back and forth things will be lost, overwritten, or duplicated. A colleague suggests using version control to manage their work. Version control is better than mailing files back and forth: . | Nothing that is committed to version control is ever lost, unless you work really, really hard at it. Since all old versions of files are saved, it’s always possible to go back in time to see exactly who wrote what on a particular day, or what version of a program was used to generate a particular set of results. | As we have this record of who made what changes when, we know who to ask if we have questions later on, and, if needed, revert to a previous version, much like the “undo” feature in an editor. | When several people collaborate in the same project, it’s possible to accidentally overlook or overwrite someone’s changes. The version control system automatically notifies users whenever there’s a conflict between one person’s work and another’s. | . Teams are not the only ones to benefit from version control: lone researchers can benefit immensely. Keeping a record of what was changed, when, and why is extremely useful for all researchers if they ever need to come back to the project later on (e.g., a year later, when memory has faded). Version control is the lab notebook of the digital world: it’s what professionals use to keep track of what they’ve done and to collaborate with other people. Every large software development project relies on it, and most programmers use it for their small jobs as well. And it isn’t just for software: books, papers, small data sets, and anything that changes over time or needs to be shared can and should be stored in a version control system. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/#about-this-workshop",
    "relUrl": "/Git_Materials/#about-this-workshop"
  },"449": {
    "doc": "Version Control with Git",
    "title": "Prerequisites",
    "content": "In this lesson we use Git from the Unix Shell. Some previous experience with the shell is expected, but isn’t mandatory. Post-Workshop Survey . Please complete this survey after attending the workshop. Thank you!!! . Acknowledgment . The material for this workshop was created from the Version Control with Git curriculum developed by The Software Carpentry Foundation of The Carpentries licensed under CC-BY 4.0 . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/#prerequisites",
    "relUrl": "/Git_Materials/#prerequisites"
  },"450": {
    "doc": "Making the Most with Jupyter Lab and Notebooks",
    "title": "Making the Most with Jupyter Lab and Notebooks",
    "content": "Are you new to using Jupyter Lab and Notebooks? Or have you used these platforms before but want to learn more about them? Then come check out this workshop! This workshop is designed to be an introduction to Jupyter Lab and Notebooks. Some of the topics that will be covered include: how to access these platforms, an overview of platform features like hotkeys and magic commands, the basics of using markdown, publishing notebooks on the web, and how to use and display interactive figures. Presenters . Chasz Griego Science and Engineering Librarian Office: 4410, Sorrells Library cgriego@andrew.cmu.edu . Lencia Beltran Open Science Project Coordinator Office: 4416, Sorrells Library lbeltran@andrew.cmu.edu . Setup . To be best prepared for this workshop, please follow the setup instructions prior to attending. At the end of the workshop, we will provide a demo on how to move Jupyter notebooks to the web. If you are interested in doing this yourself, we recommend that you create a GitHub account using a reliable email address, and download a recent version of Git to your laptop. Schedule . | Section | Time | . | Setup |   | . | Navigating JupyterLab | 01:30 | . | Markdown and Magic Commands | 01:45 | . | Displaying Media | 02:05 | . | Break | 01:55 | . | Interactive Plots | 02:30 | . | Workshop Survey | 02:45 | . | Moving Notebooks to the Web | 03:15 | . | Finish | 03:30 | . Accessing the Curriculum . See the concepts covered in this workshop as a Jupyter Notebook on nbviewer: . Or work through the course content in JupyterLab on Binder: . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/making_the_most_jupyter.html",
    "relUrl": "/Python_Series_Materials/making_the_most_jupyter.html"
  },"451": {
    "doc": "Advanced Research Note-Taking with Obsidian",
    "title": "Advanced Research Note-Taking with Obsidian",
    "content": "This workshop will introduce Obsidian, a markdown-based note-taking app that helps you organize your personal knowledge base. We will demonstrate how to create and edit markdown files to easily format your notes, then dive in to several of the functions and plug-ins in Obsidian that makes it easier for you to organize, link, and search your recorded thoughts. Finally, we will demonstrate how you can link Obsidian to Zotero to help you connect research notes to items in your bibliography. Presenters . Chasz Griego Science &amp; Engineering Librarian Office: 4410, Sorrells Library cgriego@andrew.cmu.edu . Learning Objectives . Workshop attendees will be able to: . | Create and format notes with markdown | Link and tag Obsidian notes | Install and use community plugins in Obsidian | Sync a Zotero library to Obsidian | . Setup . To be best prepared for these workshops, please download and install Obsidian, Zotero, and Better BibTeX for Zotero prior to attending. Pre-Workshop Survey . Before the start of the workshop, please complete this survey. Thank you!! . Goal of this Workshop . The goal of this workshop is to introduce users to a tool that organizes their personal notes or notes related to research. This workshop will show many of the advanced functionalities offered in Obsidian and outline a workflow to sync a Zotero library with Obsidian, so that notes can be directly linked to entries in a bibliography. Schedule . | Section | Time | . | Getting Started with Obsidian | 00:00 | . | Creating and Formatting Notes | 00:15 | . | Linking Notes and Visualizing Connections | 00:45 | . | Break | 00:55 | . | Enhancing Your Vault with Plugins | 01:00 | . | Survey | 01:20 | . | Syncing Your Zotero Collection | 01:25 | . | Finish | 02:00 | . Post-Workshop Survey . Please complete this survey after attending the workshop. Thank you in advance!!! . ",
    "url": "http://localhost:4000/portfolio_workshop/content/obsidian.html",
    "relUrl": "/content/obsidian.html"
  },"452": {
    "doc": "Cleaning Untidy Data with OpenRefine",
    "title": "Cleaning Untidy Data with OpenRefine",
    "content": "Hosted by the Carnegie Mellon University (CMU) Libraries . ",
    "url": "http://localhost:4000/portfolio_workshop/content/openrefine.html",
    "relUrl": "/content/openrefine.html"
  },"453": {
    "doc": "Cleaning Untidy Data with OpenRefine",
    "title": "About this Workshop",
    "content": "Tired of spending hours and hours cleaning messy data in Excel spreadsheets? Come learn OpenRefine, an easy-to-use, open source tool for data cleaning. OpenRefine (formerly Google Refine) helps you prepare your data for analysis. Quickly and easily transform data, split and merge columns, remove whitespace, and perform many more common data cleaning tasks. With OpenRefine, you can also easily create JSON scripts for repeating series of tasks across multiple datasets. No previous experience is required. This will be a hands-on workshop–please bring a laptop. Presenters . Sarah Young Principal Librarian Office: 109G, Hunt Library sarahy@andrew.cmu.edu . Goals of this Workshop . | Import data and perform basic cleaning steps | Use sorting, filtering and facets to clean data | Restructure columns and cells | Export JSON script for repeating steps | Save and export files and projects | . ",
    "url": "http://localhost:4000/portfolio_workshop/content/openrefine.html#about-this-workshop",
    "relUrl": "/content/openrefine.html#about-this-workshop"
  },"454": {
    "doc": "Cleaning Untidy Data with OpenRefine",
    "title": "Schedule",
    "content": "Thursday, February 15, 2023 . | Time | Content | . | 15:00 to 15:05 | Welcome and Introduction | . | 15:05 to 15:15 | Importing data and basic cleanup | . | 15:15 to 15:30 | Sorting, filtering and faceting | . | 15:30 to 15:40 | Transposing data and advanced facets | . | 15:40 to 15:50 | Clustering | . | 15:50 to 16:10 | Splitting and concatenating | . | 16:10 to 16:20 | Restructuring data | . | 16:20 to 16:25 | Exporting JSON scripts | . | 16:25 to 16:30 | Wrap-Up | . Actual schedule may vary depending on group needs; all times refer to Eastern Standard Time (EST) . Slides . Click on the slides then press CTRL+Shift+F for full screen . Acknowledgements . The lesson materials and slides for this workshop were largely adapted from an OpenRefine Workshop delivered at IASSIST 2018 in Montreal by: . Leanne Trimble, Data &amp; Statistics Librarian Kelly Schultz, Data Visualization Librarian University of Toronto Libraries . ",
    "url": "http://localhost:4000/portfolio_workshop/content/openrefine.html#schedule",
    "relUrl": "/content/openrefine.html#schedule"
  },"455": {
    "doc": "Project Management with Open Science Framework",
    "title": "About this Workshop",
    "content": "Open Science Framework (OSF) is a research reproducibility and project management platform that is free, open source, and designed to support research across the research lifecycle. OSF allows you to organize all of your research documentation, such as datasets, code, analysis, background literature, and more, into a single space shared by your collaborators. OSF also supports the pre-registration of research protocols and preprint publication. In this hands-on workshop, we’ll cover: . | Creating and collaborating on OSF projects | Using project templates | Uploading files from your desktop | Connecting external platforms like Google Drive, Mendeley, and GitHub | Understanding version control in OSF | Pre-registration of research protocols | Publishing supplementary materials | . No previous experience is required. ",
    "url": "http://localhost:4000/portfolio_workshop/content/osf.html#about-this-workshop",
    "relUrl": "/content/osf.html#about-this-workshop"
  },"456": {
    "doc": "Project Management with Open Science Framework",
    "title": "Schedule",
    "content": "Monday, February 13, 2023 . | Time | Content | . | 12:00 to 12:05 | Welcome and Introduction | . | 12:05 to 12:20 | Creating a project and collaborating | . | 12:20 to 12:30 | Working with components | . | 12:30 to 12:50 | Adding files and version control | . | 12:50 to 13:00 | Wikis | . | 13:00 to 13:10 | Add ons | . | 13:10 to 13:20 | Pre-registration | . | 13:20 to 13:25 | Pre-prints and other uses | . | 13:25 to 13:30 | Wrap-Up | . Actual schedule may vary depending on group needs; all times refer to Eastern Standard Time (EST) __ . Presenters . Katie Behrman Institutional Repository Specialist kbehrman@andrew.cmu.edu . Lencia Beltran Open Science Program Coordinator Office: 4416, Sorrells Library lbeltran@andrew.cmu.edu . Melanie Gainey Open Science Program Director and Librarian mgainey@andrew.cmu.edu . Sarah Young Principal Librarian Office: 109G, Hunt Library sarahy@andrew.cmu.edu . ",
    "url": "http://localhost:4000/portfolio_workshop/content/osf.html#schedule",
    "relUrl": "/content/osf.html#schedule"
  },"457": {
    "doc": "Project Management with Open Science Framework",
    "title": "Project Management with Open Science Framework",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/content/osf.html",
    "relUrl": "/content/osf.html"
  },"458": {
    "doc": "Introduction to Basic Programming with Data",
    "title": "Part 1: Introduction to Basic Programming with Data",
    "content": "In this first part of the 3-part workshop series, “Introduction to Python for Data Science,” we offer an introduction to Python for non-programmers with a focus on data analysis. In this workshop, we will demonstrate how to do basic Python programming in Jupyter Notebooks. Topics will include working with different data types and using built-in functions and libraries to read and manipulate data. Presenters . Chasz Griego Science and Engineering Librarian Office: 4410, Sorrells Library cgriego@andrew.cmu.edu | Schedule a Consultation . Learning Objectives . Workshop attendees will be able to: . | Run Python programs in JupyterLab | Create variables that store data | Identify different data types | Call built-in Python functions | . Setup . To be best prepared for this workshop, please follow the setup instructions prior to attending. Interactive Notepad . During the workshop, you can ask and answer questions in this Etherpad, a notepad for live collaboration. Pre-Workshop Survey . Before the start of the workshop, please complete this survey. Thank you!! . Schedule . | Section | Time | . | Setup and Pre-Workshop Survey |   | . | Running and Quitting | 00:00 | . | Variables and Assignment | 00:25 | . | Break | 00:55 | . | Data Types and Type Conversion | 01:00 | . | Built-in Functions and Help | 01:20 | . | Post-Workshop Survey | 01:50 | . | Finish | 02:00 | . Interactive Curriculum . Click the Binder badge below to work through the course content in JupyterLab. Post-Workshop Survey . Please complete this survey after attending the workshop. Thank you!!! . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/part_1.html#part-1-introduction-to-basic-programming-with-data",
    "relUrl": "/Python_Series_Materials/part_1/part_1.html#part-1-introduction-to-basic-programming-with-data"
  },"459": {
    "doc": "Introduction to Basic Programming with Data",
    "title": "Introduction to Basic Programming with Data",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_1/part_1.html",
    "relUrl": "/Python_Series_Materials/part_1/part_1.html"
  },"460": {
    "doc": "Plotting and Analyzing Tabular Datasets",
    "title": "Part 2: Plotting and Analyzing Tabular Datasets",
    "content": "In the second part of the 3-part workshop series, “Introduction to Python for Data Science,” we demonstrate beginner Python programming techniques using the Pandas library to read tabular datasets, perform simple analyses, and visualize data. The content covered in this workshop will be a continuation of the content covered in part 1, “Introduction to Basic Programming with Data”. We highly encourage attending the first part of the workshop series before this workshop, especially for learners that are new to the Python programming language. Presenters . Chasz Griego Science and Engineering Librarian Office: 4410, Sorrells Library cgriego@andrew.cmu.edu . Learning Objectives . Workshop attendees will be able to: . | Import and use modules from standard Python libraries | Read a tabular dataset into Python | Select subsets of data from a DataFrame | Create plots with data in Python | . Setup . To be best prepared for this workshop, please follow the setup instructions prior to attending. Interactive Notepad . During the workshop, you can ask and answer questions in this Etherpad, a notepad for live collaboration. Pre-Workshop Survey . Before the start of the workshop, please complete this survey. Thank you!! . Schedule . | Section | Time | . | Setup and Pre-Workshop Survey |   | . | Libraries | 00:00 | . | Reading Tabular Data into DataFrames | 00:25 | . | Break | 00:55 | . | Pandas Dataframes | 01:00 | . | Plotting | 01:30 | . | Post-Workshop Survey | 01:55 | . | Finish | 02:00 | . Interactive Curriculum . Click the Binder badge below to work through the course content in JupyterLab. Post-Workshop Survey . Please complete this survey after attending the workshop. Thank you in advance!!! . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/part_2.html#part-2-plotting-and-analyzing-tabular-datasets",
    "relUrl": "/Python_Series_Materials/part_2/part_2.html#part-2-plotting-and-analyzing-tabular-datasets"
  },"461": {
    "doc": "Plotting and Analyzing Tabular Datasets",
    "title": "Plotting and Analyzing Tabular Datasets",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_2/part_2.html",
    "relUrl": "/Python_Series_Materials/part_2/part_2.html"
  },"462": {
    "doc": "Analyzing Data with Logic and Iteration",
    "title": "Part 3: Analyzing Data with Logic and Iteration",
    "content": "In the final part of the 3-part workshop series, “Introduction to Python for Data Science,” we offer an overview of Python fundamentals for performing iterative tasks with for loops and conditional tasks using logic and if statements. We will then show how to apply these programming techniques to analyze and visualize multiple tabular datasets with Pandas. The content covered in this workshop will be a continuation of the content covered in part 1, “Introduction to Basic Programming with Data” and part 2, “Plotting and Analyzing Tabular Datasets”. We highly encourage attending both part 1 and 2 of the series before this workshop, especially for learners that are new to the Python programming language. Presenters . Chasz Griego Science and Engineering Librarian Office: 4410, Sorrells Library cgriego@andrew.cmu.edu . Learning Objectives . Workshop attendees will be able to: . | Store multiple values in Python with lists | Make Python programs do iterative tasks | Write programs that do tasks conditionally | Process many data sets with a single command | . Setup . To be best prepared for this workshop, please follow the setup instructions prior to attending. Interactive Notepad . During the workshop, you can ask and answer questions in this Etherpad, a notepad for live collaboration. Pre-Workshop Survey . Before the start of the workshop, please complete this survey. Thank you!! . Schedule . | Section | Time | . | Setup and Pre-Workshop Survey |   | . | Lists | 00:00 | . | For Loops | 00:25 | . | Break | 00:55 | . | Conditionals | 01:00 | . | Looping Over Data Sets | 01:30 | . | Post-Workshop Survey | 01:55 | . | Finish | 02:00 | . Interactive Curriculum . Click the Binder badge below to work through the course content in JupyterLab. Post-Workshop Survey . Please complete this survey after attending the workshop. Thank you in advance!!! . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/part_3.html#part-3-analyzing-data-with-logic-and-iteration",
    "relUrl": "/Python_Series_Materials/part_3/part_3.html#part-3-analyzing-data-with-logic-and-iteration"
  },"463": {
    "doc": "Analyzing Data with Logic and Iteration",
    "title": "Analyzing Data with Logic and Iteration",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/part_3/part_3.html",
    "relUrl": "/Python_Series_Materials/part_3/part_3.html"
  },"464": {
    "doc": "Academic Publishing Processes and Models",
    "title": "Introduction to Academic Publishing Processes and Models",
    "content": "Hosted by the Carnegie Mellon University (CMU) Libraries . ",
    "url": "http://localhost:4000/portfolio_workshop/content/publishing.html#introduction-to-academic-publishing-processes-and-models",
    "relUrl": "/content/publishing.html#introduction-to-academic-publishing-processes-and-models"
  },"465": {
    "doc": "Academic Publishing Processes and Models",
    "title": "About this workshop",
    "content": "This workshop will introduce academic publishing models, including Open Access models, and the publishing process of a scholarly work, including the peer-review process. Presenters . Emily Bongiovanni Open Knowledge Librarian ebongiov@andrew.cmu.edu . Slides . Click on the slides then press CTRL+Shift+F for full screen . Also see this guide for more information. ",
    "url": "http://localhost:4000/portfolio_workshop/content/publishing.html#about-this-workshop",
    "relUrl": "/content/publishing.html#about-this-workshop"
  },"466": {
    "doc": "Academic Publishing Processes and Models",
    "title": "Academic Publishing Processes and Models",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/content/publishing.html",
    "relUrl": "/content/publishing.html"
  },"467": {
    "doc": "Python for Harvesting Data on the Web",
    "title": "Python for Harvesting Data on the Web",
    "content": "This is an intermediate-to-advanced level Python workshop that describes ways to approach common data wrangling from the web for research needs. We will focus on obtaining open data sources through HTTP requests and then demonstrate how to access larger sources of data via APIs. Then we will show how to turn the retrieved data into more useful objects like data frames to do basic manipulations and analysis. This workshop is only recommended for Python users with familiarity in Pandas, Numpy, core Python objects (lists, dictionaries, strings, numbers), file types like JSON and CSV, and comfort using Jupyter Notebooks. Presenters . Chasz Griego Science and Engineering Librarian Office: 4410, Sorrells Library cgriego@andrew.cmu.edu . Lencia Beltran Open Science Program Coordinator Office: 4416, Sorrells Library lbeltran@andrew.cmu.edu . Goals of this Workshop . This workshop will provide learners the basic approaches to extract information from the web using Python. The topics covered will give learners enough ground knowledge to harvest information from a several web sources. Setup . To be best prepared for this workshop, please make sure you have Python Installed,preferably with the Anaconda distribution prior to attending. You may also install some of the libraries we will be using ahead of time: . | urllib | beautifulsoup4 | MechanicalSoup | sodapy | . Schedule . | Section | Time | . | Setup |   | . | Scrape and Parse Text from the Web | 00:00 | . | Using an HTML Parser | 00:20 | . | Interacting with HTML Forms | 00:40 | . | Interacting with Websites in Real Time | 01:00 | . | Web Requests | 01:20 | . | Simple Web API Requests | 01:40 | . | Finish | 02:00 | . Accessing the Curriculum . See the concepts covered in this workshop as a Jupyter Notebook on nbviewer: . Or work through the course content in JupyterLab on Binder: . Post-Workshop Survey . Please complete this survey after attending the workshop. Thank you in advance!!! . ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/python_harvesting/py_harvest_main.html",
    "relUrl": "/Python_Series_Materials/python_harvesting/py_harvest_main.html"
  },"468": {
    "doc": "Python for Data Science",
    "title": "Introduction to Python for Data Science",
    "content": "Welcome to this introductory workshop series on Python for data science. This is a three part series that will walk through basic Python programming with data, working in Jupyter Lab, and doing advanced analyses with tabular datasets. See the schedule or table of contents below to navigate through all the workshop material. Presenters . Chasz Griego Open Science Postdoctoral Associate Office: 4416, Sorrells Library cgriego@andrew.cmu.edu . Setup . To be best prepared for these workshops, please follow the setup instructions prior to attending. Goal of this Workshop . The goal of this workshop is to introduce Python to learners who are new to the language or new to programming. Our goal is to get you comfortable using Python for the purpose of working with data. Series . | Part 1: Introduction to Basic Programming with Data | Part 2: Plotting and Analyzing Tabular Datasets | Part 3: Analyzing Data with Logic and Iteration | . Acknowledgment . The material for this workshop series was created from the Plotting and Programming in Python curriculum developed by The Software Carpentry Foundation of The Carpentries licensed under CC-BY 4.0 . ",
    "url": "http://localhost:4000/portfolio_workshop/content/python.html#introduction-to-python-for-data-science",
    "relUrl": "/content/python.html#introduction-to-python-for-data-science"
  },"469": {
    "doc": "Python for Data Science",
    "title": "Python for Data Science",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/content/python.html",
    "relUrl": "/content/python.html"
  },"470": {
    "doc": "Research Data Management",
    "title": "Introduction to Research Data Management and Data Management Plans",
    "content": "Hosted by the Carnegie Mellon University (CMU) Libraries . ",
    "url": "http://localhost:4000/portfolio_workshop/content/rdm.html#introduction-to-research-data-management-and-data-management-plans",
    "relUrl": "/content/rdm.html#introduction-to-research-data-management-and-data-management-plans"
  },"471": {
    "doc": "Research Data Management",
    "title": "About this workshop",
    "content": "This workshop will introduce the FAIR data principles (Findable, Accessible, Interoperable, and Reusable) and research data management plans. Presenters . Emily Bongiovanni Open Knowledge Librarian ebongiov@andrew.cmu.edu . Slides . Click on the slides then press CTRL+Shift+F for full screen . Also see this guide for more information. ",
    "url": "http://localhost:4000/portfolio_workshop/content/rdm.html#about-this-workshop",
    "relUrl": "/content/rdm.html#about-this-workshop"
  },"472": {
    "doc": "Research Data Management",
    "title": "Research Data Management",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/content/rdm.html",
    "relUrl": "/content/rdm.html"
  },"473": {
    "doc": "Git Cheatsheets for Quick Reference",
    "title": "Git Cheatsheets for Quick Reference",
    "content": ". | Printable Git cheatsheets in several languages are available here (English version). More material is available from the GitHub training website. | An interactive one-page visualisation about the relationships between workspace, staging area, local repository, upstream repository, and the commands associated with each (with explanations). | Both resources are also available in other languages (e.g. Spanish, French, and more). | “Happy Git and GitHub for the useR” is an accessible, free online book by Jenny Bryan on how to setup and use Git and GitHub with specific references on the integration of Git with RStudio and working with Git in R. | Open Scientific Code using Git and GitHub - A collection of explanations and short practical exercises to help researchers learn more about version control and open source software. | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/reference.html",
    "relUrl": "/Git_Materials/reference.html"
  },"474": {
    "doc": "Git Cheatsheets for Quick Reference",
    "title": "Glossary",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/reference.html#glossary",
    "relUrl": "/Git_Materials/reference.html#glossary"
  },"475": {
    "doc": "Git Cheatsheets for Quick Reference",
    "title": "Changeset",
    "content": ": A group of changes to one or more files that are or will be added to a single commit in a version control repository. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/reference.html#changeset",
    "relUrl": "/Git_Materials/reference.html#changeset"
  },"476": {
    "doc": "Git Cheatsheets for Quick Reference",
    "title": "Commit",
    "content": ": To record the current state of a set of files (a changeset) in a version control repository. As a noun, the result of committing, i.e. a recorded changeset in a repository. If a commit contains changes to multiple files, all of the changes are recorded together. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/reference.html#commit",
    "relUrl": "/Git_Materials/reference.html#commit"
  },"477": {
    "doc": "Git Cheatsheets for Quick Reference",
    "title": "Conflict",
    "content": ": A change made by one user of a version control system that is incompatible with changes made by other users. Helping users resolve conflicts is one of version control’s major tasks. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/reference.html#conflict",
    "relUrl": "/Git_Materials/reference.html#conflict"
  },"478": {
    "doc": "Git Cheatsheets for Quick Reference",
    "title": "http",
    "content": ": The Hypertext Transfer Protocol used for sharing web pages and other data on the World Wide Web. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/reference.html#http",
    "relUrl": "/Git_Materials/reference.html#http"
  },"479": {
    "doc": "Git Cheatsheets for Quick Reference",
    "title": "Merge",
    "content": ": (a repository): To reconcile two sets of changes to a repository. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/reference.html#merge",
    "relUrl": "/Git_Materials/reference.html#merge"
  },"480": {
    "doc": "Git Cheatsheets for Quick Reference",
    "title": "Protocol",
    "content": ": A set of rules that define how one computer communicates with another. Common protocols on the Internet include HTTP and SSH. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/reference.html#protocol",
    "relUrl": "/Git_Materials/reference.html#protocol"
  },"481": {
    "doc": "Git Cheatsheets for Quick Reference",
    "title": "Remote",
    "content": ": (of a repository) A version control repository connected to another, in such way that both can be kept in sync exchanging commits. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/reference.html#remote",
    "relUrl": "/Git_Materials/reference.html#remote"
  },"482": {
    "doc": "Git Cheatsheets for Quick Reference",
    "title": "Repository",
    "content": ": A storage area where a version control system stores the full history of commits of a project and information about who changed what, when. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/reference.html#repository",
    "relUrl": "/Git_Materials/reference.html#repository"
  },"483": {
    "doc": "Git Cheatsheets for Quick Reference",
    "title": "Resolve",
    "content": ": To eliminate the conflicts between two or more incompatible changes to a file or set of files being managed by a version control system. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/reference.html#resolve",
    "relUrl": "/Git_Materials/reference.html#resolve"
  },"484": {
    "doc": "Git Cheatsheets for Quick Reference",
    "title": "Revision",
    "content": ": A synonym for commit. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/reference.html#revision",
    "relUrl": "/Git_Materials/reference.html#revision"
  },"485": {
    "doc": "Git Cheatsheets for Quick Reference",
    "title": "SHA-1",
    "content": ": SHA-1 hashes is what Git uses to compute identifiers, including for commits. To compute these, Git uses not only the actual change of a commit, but also its metadata (such as date, author, message), including the identifiers of all commits of preceding changes. This makes Git commit IDs virtually unique. I.e., the likelihood that two commits made independently, even of the same change, receive the same ID is exceedingly small. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/reference.html#sha-1",
    "relUrl": "/Git_Materials/reference.html#sha-1"
  },"486": {
    "doc": "Git Cheatsheets for Quick Reference",
    "title": "SSH",
    "content": ": The Secure Shell protocol used for secure communication between computers. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/reference.html#ssh",
    "relUrl": "/Git_Materials/reference.html#ssh"
  },"487": {
    "doc": "Git Cheatsheets for Quick Reference",
    "title": "Timestamp",
    "content": ": A record of when a particular event occurred. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/reference.html#timestamp",
    "relUrl": "/Git_Materials/reference.html#timestamp"
  },"488": {
    "doc": "Git Cheatsheets for Quick Reference",
    "title": "Version Control",
    "content": ": A tool for managing changes to a set of files. Each set of changes creates a new commit of the files; the version control system allows users to recover old commits reliably, and helps manage conflicting changes made by different users. ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/reference.html#version-control",
    "relUrl": "/Git_Materials/reference.html#version-control"
  },"489": {
    "doc": "Setup",
    "title": "Pre-workshop set up",
    "content": "Please complete the following activities prior to the workshop. 1. Download the workshop files . Download the workshop files and save them in a folder on your desktop. Make sure to extract the files from the zip file. 2. Set up an OSF account . Go to the Open Science Framework registration page. Click on Institution and choose Carnegie Mellon University from the drop down menu. Enter your CMU email address and password to log in. ",
    "url": "http://localhost:4000/portfolio_workshop/OSF_Materials/setup.html#pre-workshop-set-up",
    "relUrl": "/OSF_Materials/setup.html#pre-workshop-set-up"
  },"490": {
    "doc": "Setup",
    "title": "Workshop Slides",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/OSF_Materials/setup.html#workshop-slides",
    "relUrl": "/OSF_Materials/setup.html#workshop-slides"
  },"491": {
    "doc": "Setup",
    "title": "Setup",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/OSF_Materials/setup.html",
    "relUrl": "/OSF_Materials/setup.html"
  },"492": {
    "doc": "Setup",
    "title": "Installing Git",
    "content": "Please see this page for instructions on installing Git for various operating systems. | Git installation on Windows | Git installation on MacOS | Git installation on Linux | . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/setup.html#installing-git",
    "relUrl": "/Git_Materials/setup.html#installing-git"
  },"493": {
    "doc": "Setup",
    "title": "Preparing Your Working Directory",
    "content": "We’ll do our work in the Desktop folder so make sure you change your working directory to it with: . $ cd $ cd Desktop . ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/setup.html#preparing-your-working-directory",
    "relUrl": "/Git_Materials/setup.html#preparing-your-working-directory"
  },"494": {
    "doc": "Setup",
    "title": "Setup",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Git_Materials/setup.html",
    "relUrl": "/Git_Materials/setup.html"
  },"495": {
    "doc": "Setup",
    "title": "About this Workshop",
    "content": "Tired of spending hours and hours cleaning messy data in Excel spreadsheets? Come learn OpenRefine, an easy-to-use, open source tool for data cleaning. OpenRefine (formerly Google Refine) helps you prepare your data for analysis. Quickly and easily transform data, split and merge columns, remove whitespace, and perform many more common data cleaning tasks. With OpenRefine, you can also easily create JSON scripts for repeating series of tasks across multiple datasets. No previous experience is required. This will be a hands-on workshop–please bring a laptop. ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/setup.html#about-this-workshop",
    "relUrl": "/OpenRefine_Materials/setup.html#about-this-workshop"
  },"496": {
    "doc": "Setup",
    "title": "Pre-workshop set up",
    "content": "Please complete the following activities prior to the workshop. 1. Download the workshop files . Download the workshop files and save them in a folder on your desktop. Make sure to extract the files from the zip file. 2. Download and Install OpenRefine . You can download OpenRefine 3.4.1 from http://openrefine.org/download.html. There are versions for Windows, Mac OS X and Linux. Installing OpenRefine . For Windows and Linux, the address above will provide a zip file. Unzip the downloaded file wherever you want to install the program. For Mac, you will be downloading a ‘dmg’. Open it and then drag the OpenRefine application to an appropriate folder on you computer. You need to have a ‘Java Runtime Environment’ (JRE) installed on your computer to run OpenRefine. If you don’t already have one installed then you can download and install it from http://java.com. Click on “Free Java Download”. Running OpenRefine . On Windows: Navigate to the folder where you’ve installed OpenRefine and either double-click ’openrefine.exe’ or ‘refine.bat’. On Linux: Navigate to the folder where you’ve installed OpenRefine in a terminal window and type ‘./refine’ . On Mac: Navigate to where you installed OpenRefine and click the OpenRefine icon . The interface to OpenRefine is accessed via a web browser. When you run Refine normally this should open a window in your default web browser pointing at the address http://127.0.0.1:3333. If this doesn’t happen automatically you can open a web browser and type in this address. ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/setup.html#pre-workshop-set-up",
    "relUrl": "/OpenRefine_Materials/setup.html#pre-workshop-set-up"
  },"497": {
    "doc": "Setup",
    "title": "Workshop Slides",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/setup.html#workshop-slides",
    "relUrl": "/OpenRefine_Materials/setup.html#workshop-slides"
  },"498": {
    "doc": "Setup",
    "title": "Setup",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/OpenRefine_Materials/setup.html",
    "relUrl": "/OpenRefine_Materials/setup.html"
  },"499": {
    "doc": "Setup",
    "title": "Setup",
    "content": "Getting the Data . The data we will use is taken from the Software Carpentries. To obtain it, download the file here and unzip it. You should have a new folder on your desktop called shell-lesson-data. Install Shell Software . If you do not already have the shell software installed, you will need to download and install it. (See below) . Opening Shell . After installing the software . Open a terminal. If you’re not sure how to open a terminal on your operating system, see the instructions below. In the terminal type cd then press the Enter or Return key. This step will make sure you start with your home folder as your working directory. In the lesson, you will find out how to access the data files in this folder. Installing Bash . If you have a Mac or Linux operating system then you should have access to Bash through your terminal or command prompt. If you use . Microsoft Mac Linux . Microsoft . | Download the Git for Windows installer. | Run the installer and follow the steps below: . | Click on “Next” four times (two times if you’ve previously installed Git). You don’t need to change anything in the Information, location, components, and start menu screens. | From the dropdown menu, “Choosing the default editor used by Git”, select “Use the Nano editor by default” (NOTE: you will need to scroll up to find it) and click on “Next”. | On the page that says “Adjusting the name of the initial branch in new repositories”, ensure that “Let Git decide” is selected. This will ensure the highest level of compatibility for our lessons. | Ensure that “Git from the command line and also from 3rd-party software” is selected and click on “Next”. (If you don’t do this Git Bash will not work properly, requiring you to remove the Git Bash installation, re-run the installer and to select the “Git from the command line and also from 3rd-party software” option.) . | Select “Use bundled OpenSSH”. | Ensure that “Use the native Windows Secure Channel Library” is selected and click on “Next”. | Ensure that “Checkout Windows-style, commit Unix-style line endings” is selected and click on “Next”. | Ensure that “Use Windows’ default console window” is selected and click on “Next”. | Ensure that “Default (fast-forward or merge) is selected and click “Next” . | Ensure that “Git Credential Manager” is selected and click on “Next”. | Ensure that “Enable file system caching” is selected and click on “Next”. | Click on “Install”. | Click on “Finish” or “Next”. | . | If your “HOME” environment variable is not set (or you don’t know what this is): . | Open command prompt (Open Start Menu then type cmd and press Enter) . | Type the following line into the command prompt window exactly as shown: setx HOME \"%USERPROFILE%\" . | Press Enter, you should see SUCCESS: Specified value was saved. | Quit command prompt by typing exit then pressing Enter . | . | . This will provide you with both Git and Bash in the Git Bash program. Video Tutorial . Mac . The default shell in some versions of macOS is Bash, and Bash is available in all versions, so no need to install anything. You access Bash from the Terminal (found in /Applications/Utilities). See the Git installation video tutorial for an example on how to open the Terminal. You may want to keep Terminal in your dock for this workshop. To see if your default shell is Bash type echo $SHELL in Terminal and press the Return key. If the message printed does not end with ‘/bash’ then your default is something else and you can run Bash by typing bash . If you want to change your default shell, see this Apple Support article and follow the instructions on “How to change your default shell”. Video Tutorial . Linux . The default shell is usually Bash and there is usually no need to install anything. To see if your default shell is Bash type echo $SHELL in a terminal and press the Enter key. If the message printed does not end with ‘/bash’ then your default is something else and you can run Bash by typing bash. This course material was created from the The Unix Shell curriculum developed by The Software Carpentry Foundation of The Carpentries licensed under CC-BY 4.0 . ",
    "url": "http://localhost:4000/portfolio_workshop/cli/setup.html",
    "relUrl": "/cli/setup.html"
  },"500": {
    "doc": "Setup",
    "title": "Getting the Data",
    "content": "The data we will be using is taken from the gapminder dataset. To obtain it, download and unzip the file python-novice-gapminder-data.zip. Please save the data to a folder called data on your desktop. ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/setup.html#getting-the-data",
    "relUrl": "/Python_Series_Materials/setup.html#getting-the-data"
  },"501": {
    "doc": "Setup",
    "title": "Installing Python Using Anaconda",
    "content": "Python is a popular language for research computing, and great for general-purpose programming as well. Installing all of its research packages individually can be a bit difficult, so we recommend Anaconda, an all-in-one installer. Regardless of how you choose to install it, please make sure you install Python version 3.x (e.g., 3.6 is fine). We will teach Python using the JupyterLab, a programming environment that runs in a web browser (JupyterLab will be installed by Anaconda). For this to work you will need a reasonably up-to-date browser. The current versions of the Chrome, Safari and Firefox browsers are all supported (some older browsers, including Internet Explorer version 9 and below, are not). | Windows | MacOS | Linux | . | Open https://www.anaconda.com/products/individual#download-section with your web browser. | Download the Anaconda for Windows installer with Python 3. (If you are not sure which version to choose, you probably want the 64-bit Graphical Installer Anaconda3-...-Windows-x86_64.exe) | Install Python 3 by running the Anaconda Installer, using all of the defaults for installation except make sure to check Add Anaconda to my PATH environment variable. | . Video Tutorial . | Open https://www.anaconda.com/products/individual#download-section with your web browser. | Download the Anaconda Installer with Python 3 for macOS (you can either use the Graphical or the Command Line Installer). | Install Python 3 by running the Anaconda Installer using all of the defaults for installation. | . Video Tutorial . | Open https://www.anaconda.com/products/individual#download-section with your web browser. | Download the Anaconda Installer with Python 3 for Linux. (The installation requires using the shell. If you aren't comfortable doing the installation yourself stop here and request help at the workshop.) | Open a terminal window and navigate to the directory where the executable is downloaded (e.g., `cd ~/Downloads`). | Type bash Anaconda3- . and then press Tab to autocomplete the full file name. The name of file you just downloaded should appear. | Press Enter (or Return depending on your keyboard). You will follow the text-only prompts. To move through the text, press Spacebar. Type yes and press enter to approve the license. Press Enter (or Return) to approve the default location for the files. Type yes and press Enter (or Return) to prepend Anaconda to your PATH (this makes the Anaconda distribution the default Python). | Close the terminal window. | . In order to follow the presented material, you should launch the JupyterLab server in the root directory (see Starting JupyterLab). ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/setup.html#installing-python-using-anaconda",
    "relUrl": "/Python_Series_Materials/setup.html#installing-python-using-anaconda"
  },"502": {
    "doc": "Setup",
    "title": "Setup",
    "content": " ",
    "url": "http://localhost:4000/portfolio_workshop/Python_Series_Materials/setup.html",
    "relUrl": "/Python_Series_Materials/setup.html"
  }
}
